<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Tensorflow中的错误记录 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Tensorflow中的错误记录</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Tensorflow中的错误记录</h1><div class="post-meta">2019-08-12<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.2k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 5</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89loss%E4%B8%AD%E7%9A%84reshape%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">1. 自定义loss中的reshape问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#map_fn%E6%88%96%E8%80%85while_loop%E9%80%9F%E5%BA%A6%E5%BE%88%E6%85%A2"><span class="toc-number">2.</span> <span class="toc-text">2.
Map_fn或者While_Loop速度很慢</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8tf.keras%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E6%97%B6tensorboard%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BAgraph"><span class="toc-number">3.</span> <span class="toc-text">3.
使用tf.keras构建模型时Tensorboard无法显示graph</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tf.keras%E4%B8%ADmodel%E5%A4%8D%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">4. tf.keras中Model复用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#error-while-reading-resource-variable-xxx-from-container-localhost.-this-could-mean-that-the-variable-was-uninitialized."><span class="toc-number">5.</span> <span class="toc-text">5.
Error while reading resource variable xxx from Container: localhost.
This could mean that the variable was uninitialized.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tf.data%E5%AF%B9%E4%BA%8E%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E6%A8%A1%E5%9E%8B%E6%97%B6%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">6.
tf.data对于多输入多输出模型时的操作</span></a></li></ol></div></div><div class="post-content"><p>以后这篇文章就来记录<code>tensorflow</code>中遇到的问题与解决方式。</p>
<span id="more"></span>
<h4 id="自定义loss中的reshape问题">1. 自定义loss中的reshape问题</h4>
<p>我想在<code>loss</code>函数中对<code>tensor</code>进行<code>reshape</code>，在<code>model.compile</code>的时候，<code>keras</code>会生成两个虚<code>placeholder</code>来进行尺寸检查，比如我的<code>yolo</code>中的<code>y_true</code>会生成为<code>(?, ?, ?, ?, ?)</code>，<code>y_pred</code>会按照<code>tf.dataset</code>来生成<code>(?, 7, 10, 5, 16)</code>。</p>
<p>这个时候我对标签<code>reshape</code>给的参数为<code>tf.TensorShape(None, 7, 10, 5, 8, 2)</code>，但是报错如下：</p>
<pre><code>ValueError: Tried to convert &#39;shape&#39; to a tensor and failed. Error: Cannot convert a partially known TensorShape to a Tensor: (?, 7, 10, 5, 5, 2)</code></pre>
<p>解决方式：</p>
<p>咋一看这个出错好像很蠢，但其实是因为在尺寸检查的时候不接受未知的尺寸<code>None</code>，所以把上面修改为：<code>tf.TensorShape(batch_size, 7, 10, 5, 8, 2)</code>即可。</p>
<h4 id="map_fn或者while_loop速度很慢">2.
Map_fn或者While_Loop速度很慢</h4>
<p>这个问题的确很蛋疼，我看了<code>github</code>的<a
target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/issues/24774">issue</a>，这两个函数都不能有效的进行<code>GPU</code>加速，但是我又需要对一个<code>batch</code>中的每个样本对进行单独处理，这就很难受。</p>
<p>解决方式：</p>
<p>还好<code>tensorflow</code>的构建可以是静态图的方式，像我这样知道<code>batch size</code>的情况下，就可以使用在构建<code>graph</code>的时候循环构建一波。如：
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masks = []</span><br><span class="line"><span class="keyword">for</span> bc <span class="keyword">in</span> <span class="built_in">range</span>(helper.batch_size):</span><br><span class="line">    vaild_xy = tf.boolean_mask(t_xy_A[bc], obj_mask[bc])</span><br><span class="line">    vaild_wh = tf.boolean_mask(t_wh_A[bc], obj_mask[bc])</span><br><span class="line">    iou_score = tf_iou(pred_xy[bc], pred_wh[bc], vaild_xy, vaild_wh)</span><br><span class="line">    best_iou = tf.reduce_max(iou_score, axis=-<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    masks.append(tf.cast(best_iou &lt; iou_thresh, tf.float32))</span><br><span class="line">tf.parallel_stack(masks)</span><br></pre></td></tr></table></figure></p>
<h4 id="使用tf.keras构建模型时tensorboard无法显示graph">3.
使用tf.keras构建模型时Tensorboard无法显示graph</h4>
<p>之前我写<code>yolo</code>的时候，使用<code>Tensorboard</code>去查看图形时，一直显示如下</p>
<pre><code>Graph visualization failed
Error: The graph is empty. This can happen when TensorFlow could not trace any graph. Please refer to https://github.com/tensorflow/tensorboard/issues/1961 for more information.</code></pre>
<p>然后我看了<code>issue</code>，全是因为<code>tf2</code>的<code>eager</code>的原因，我这里又没有用这个模式，怎么会出这个问题呢。</p>
<p>解决方式：</p>
<p>找了半天解决方式，就是没找到，我本来想按照以前的方式做，忽然发现就可以了，在<code>callback</code>之后加一句话即可，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cbs.append(TensorBoard(<span class="built_in">str</span>(log_dir), update_freq=<span class="string">&#x27;batch&#x27;</span>, profile_batch=<span class="number">3</span>))</span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="built_in">str</span>(log_dir), sess.graph)  <span class="comment"># NOTE avoid can&#x27;t write graph, I don&#x27;t now why..</span></span><br></pre></td></tr></table></figure>
<h4 id="tf.keras中model复用">4. tf.keras中Model复用</h4>
<p>这个其实不算问题，只不过我不太清楚，就做了个测试来验证一下。就是比如我们用<code>Sequential</code>构建了一个<code>body</code>部分，然后用这个<code>body</code>产生多个输出，我一开始不知道他这样使用是否是公用参数了，然后我就写了个函数测试了下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_sim = k.Input((<span class="number">113</span>))</span><br><span class="line">input_measre = k.Input((<span class="number">113</span>))</span><br><span class="line"></span><br><span class="line">bodymodel = k.Sequential([</span><br><span class="line">    kl.Dense(<span class="number">64</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    kl.Dense(<span class="number">32</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    kl.Dense(<span class="number">1</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">out_1 = bodymodel(input_sim)</span><br><span class="line">out_2 = bodymodel(input_measre)</span><br><span class="line"></span><br><span class="line">model = k.Model([input_sim, input_measre], [out_1, out_2])</span><br><span class="line">k.utils.plot_model(model, show_shapes=<span class="literal">True</span>, to_file=<span class="string">&#x27;two_in.png&#x27;</span>)</span><br><span class="line">fwriter = tf.summary.FileWriter(<span class="string">&#x27;logs&#x27;</span>, graph=sess.graph)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p>这样的复用方式是共享参数的，可以看到，两个<code>sequential</code>，一个含有<code>kernel</code>，另一个没有，或者说他们公用一个<code>kernel</code>。</p>
<p><img src="/2019/08/12/keras-loss-error/model_reuse.png" /></p>
<h4
id="error-while-reading-resource-variable-xxx-from-container-localhost.-this-could-mean-that-the-variable-was-uninitialized.">5.
Error while reading resource variable xxx from Container: localhost.
This could mean that the variable was uninitialized.</h4>
<p>我想在<code>tf.keras</code>里面使用苏神的<code>Lookahead</code>，他的代码是用于纯<code>keras</code>的，但是我现在用<code>tf.keras</code>，虽然表层使用看起来差不多，但是核心代码我发现还是很多都不一样。我的问题出现在这里:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fast_params = model._collected_trainable_weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> K.name_scope(<span class="string">&#x27;training&#x27;</span>):</span><br><span class="line">    <span class="keyword">with</span> K.name_scope(model.optimizer.__class__.__name__):</span><br><span class="line">        training_updates = model.optimizer.get_updates(</span><br><span class="line">            params=fast_params,</span><br><span class="line">            loss=model.total_loss)</span><br><span class="line">        slow_params = [K.variable(p) <span class="keyword">for</span> p <span class="keyword">in</span> fast_params]</span><br></pre></td></tr></table></figure>
<p>使用<code>K.variable</code>转换参数的时候出错了，说我的变量没有被初始化。
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensorflow.python.framework.errors_impl.FailedPreconditionError: Error <span class="keyword">while</span> reading resource variable batch_normalization/gamma <span class="keyword">from</span> Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/batch_normalization/gamma/N10tensorflow3VarE does <span class="keyword">not</span> exist.</span><br><span class="line">         [[&#123;&#123;node training/RAdam/Variable_274/Initializer/ReadVariableOp&#125;&#125;]]</span><br></pre></td></tr></table></figure></p>
<p>解决方案：</p>
<p><code>google</code>了一下也没看到有人有相同的问题，我抱着试试看的心态写了如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])</span><br><span class="line">train_model.<span class="built_in">compile</span>(optimizer, loss=losses, metrics=metrics)</span><br></pre></td></tr></table></figure>
<p>在<code>model.compile</code>之前全局初始化，然后就完事了？然后就可以用上最新的优化算法<code>RAdam</code>和<code>Lookahead</code>咯。</p>
<h4 id="tf.data对于多输入多输出模型时的操作">6.
tf.data对于多输入多输出模型时的操作</h4>
<p>我现在的模型是3输入,2输出的,<code>tf.data</code>输出的应该为( (a,b,c)
, (label_a,label_b) ),然后我原本代码如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> [a_img, p_img, n_img], [<span class="number">1.</span>, <span class="number">1.</span>]</span><br></pre></td></tr></table></figure>
<p>然后<code>dataset</code>对象就是这样: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;DatasetV1Adapter shapes: ((32, 3, 96, 96, 3), (32, 2)), types: (tf.float32, tf.float32)&gt;</span><br></pre></td></tr></table></figure></p>
<p>解决方案:</p>
<p>用元组即可,不然默认是一个张量对象,会把我们的结构破坏掉. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> (a_img, p_img, n_img), (<span class="number">1.</span>, <span class="number">1.</span>)</span><br></pre></td></tr></table></figure>
然后<code>dataset</code>对象就是这样: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;DatasetV1Adapter shapes: (((32, 96, 96, 3), (32, 96, 96, 3), (32, 96, 96, 3)), ((32,), (32,))), types: ((tf.float32, tf.float32, tf.float32), (tf.float32, tf.float32))&gt;</span><br></pre></td></tr></table></figure></p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Keras/" rel="tag">Keras</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" rel="tag">踩坑经验</a></li></ul></div><div class="post-nav"><a class="pre" href="/2019/08/18/cvae/">条件VAE</a><a class="next" href="/2019/08/01/face-recognition/">人脸识别方法总结</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>