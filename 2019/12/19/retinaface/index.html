<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>retinaface总结 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">retinaface总结</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">retinaface总结</h1><div class="post-meta">2019-12-19<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.6k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.</span> <span class="toc-text">网络设计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#anchor%E7%94%9F%E6%88%90"><span class="toc-number">2.</span> <span class="toc-text">anchor生成</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A0%87%E7%AD%BE%E5%88%B6%E4%BD%9C"><span class="toc-number">3.</span> <span class="toc-text">标签制作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97"><span class="toc-number">4.</span> <span class="toc-text">损失计算</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%A8%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">推理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="post-content"><p>  本次主要总结一下<a
target="_blank" rel="noopener" href="https://github.com/deepinsight/insightface/blob/master/RetinaFace">retinaface</a>和<a
target="_blank" rel="noopener" href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB">Ultra-Light-Fast-Generic-Face-Detector-1MB</a>。</p>
<p>  实际上<code>retinaface</code>和<code>Ultra-Light-Fast-Generic-Face-Detector-1MB</code>的思路都是基于<code>SSD</code>的，本来我做<code>yolo</code>之后准备学习一下<code>SSD</code>的，做完这两个模型也算是学习到了。由于我目前不开源基于<code>tensorflow</code>的训练代码，下面的代码大家仅供参考～</p>
<span id="more"></span>
<h1 id="网络设计">网络设计</h1>
<p>  骨干网络实际上随便来，主要就是<code>SSD</code>预测层和<code>YOLO</code>不太一样。</p>
<ul>
<li><p>YOLO的预测层</p>
<p>只使用一个<code>Conv2D 1×1</code>得到<code>anchor_num * (class_num + 5)</code>的输出。</p></li>
<li><p>SSD的预测层</p>
<p>如果只有<code>bbox</code>输出和<code>class</code>输出，那么使用两个<code>Conv2D 1×1</code>分别得到<code>anchor_num * 4</code>和<code>anchor_num * class_num</code>。不过这样卷积的参数实际上相同的，谁好谁坏得实验下才能知道了。</p></li>
</ul>
<p>  这里的标签与<code>YOLO</code>中不太一样，<code>YOLO</code>的标签制作可以看这篇<a
href="https://zhen8838.github.io/2019/07/10/yolo-error/">文章</a>。前面的图像增强啥我就不讲了，不过我之前在<code>YOLO</code>里面用了多尺度训练，但是实际上用动态图像裁剪缩放也可以得到相同的效果，所以这里我就没有再用多尺度训练了。</p>
<h1 id="anchor生成"><code>anchor</code>生成</h1>
<p>  这个<code>anchor</code>生成和<code>YOLO</code>中的<code>anchor</code>生成方式类似，只不过这里生成的<code>anchor</code>还需要加上中心点的位置，<code>grid</code>的位置加0.5然后乘上比例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cx = (j + <span class="number">0.5</span>) * steps[k] / image_size[<span class="number">1</span>]</span><br><span class="line">cy = (i + <span class="number">0.5</span>) * steps[k] / image_size[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><code>anchor</code>的宽度则是当前<code>feature map</code>指定的<code>anchor</code>宽度除以总宽度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s_kx = min_size[<span class="number">1</span>] / in_hw[<span class="number">1</span>]</span><br><span class="line">s_ky = min_size[<span class="number">0</span>] / in_hw[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>然后把几个<code>feature map</code>上生成的<code>anchor</code>全部连接起来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output = np.concatenate([</span><br><span class="line">    np.reshape(anchors[<span class="number">0</span>], (-<span class="number">1</span>, <span class="number">4</span>)),</span><br><span class="line">    np.reshape(anchors[<span class="number">1</span>], (-<span class="number">1</span>, <span class="number">4</span>)),</span><br><span class="line">    np.reshape(anchors[<span class="number">2</span>], (-<span class="number">1</span>, <span class="number">4</span>))], <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>我觉得这样比<code>YOLO</code>中的方式好，<code>YOLO</code>中计算<code>loss</code>的时候需要计算全体的<code>gt</code>，但是算的时候是分开算的，比较蛋疼。</p>
<h1 id="标签制作">标签制作</h1>
<ol type="1">
<li><p>首先计算<code>gt</code>与<code>anchor</code>的<code>iou</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">overlaps = tf_bbox_iou(bbox, self.corner_anchors)</span><br></pre></td></tr></table></figure></li>
<li><p>找到大于阈值的的<code>anchor</code>位置，这个阈值可以设置的小一点，不过太小也不好，那样<code>label</code>中的匹配<code>anchor</code>数量就会太多</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_prior_overlap = tf.reduce_max(overlaps, <span class="number">1</span>)</span><br><span class="line">best_prior_idx = tf.argmax(overlaps, <span class="number">1</span>, tf.int32)</span><br><span class="line">best_prior_idx_filter = tf.boolean_mask(best_prior_idx, valid_gt_idx, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>找到匹配的<code>anchor</code>的最优<code>gt</code>，并为每个<code>anchor</code>的位置分配给其最匹配的<code>gt</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_truth_overlap = tf.reduce_max(overlaps, <span class="number">0</span>)</span><br><span class="line">best_truth_idx = tf.argmax(overlaps, <span class="number">0</span>, tf.int32)</span><br><span class="line">best_truth_overlap = tf.tensor_scatter_nd_update(</span><br><span class="line">    best_truth_overlap, best_prior_idx_filter[:, <span class="literal">None</span>],</span><br><span class="line">    tf.ones_like(best_prior_idx_filter, tf.float32) * <span class="number">2.</span>)</span><br><span class="line">best_truth_idx = tf.tensor_scatter_nd_update(</span><br><span class="line">    best_truth_idx, best_prior_idx[:, <span class="literal">None</span>],</span><br><span class="line">    tf.<span class="built_in">range</span>(tf.size(best_prior_idx), dtype=tf.int32))</span><br><span class="line"></span><br><span class="line">matches = tf.gather(bbox, best_truth_idx)</span><br></pre></td></tr></table></figure></li>
<li><p>设置每个<code>anchor</code>位置对应的置信度，如果其<code>iou score</code>小于阈值则设置为0</p></li>
<li><p>编码生成<code>bbox label</code>，将<code>gt</code>中心坐标转换为相对<code>anchor</code>中心的偏移，且尺度除以移除以(方差*<code>gt</code>宽度)，<code>gt</code>的宽高除<code>anchor</code>宽高并进行对数化再除方差</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">label_loc = tf_encode_bbox(matches, self.anchors, self.variances)</span><br></pre></td></tr></table></figure></li>
<li><p>编码生成<code>landmark label</code>，计算<code>gt</code>中心坐标对应<code>anchor</code>的中心偏移且尺度除以移除以(方差*<code>anchor</code>宽度)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matches_landm = tf.gather(landm, best_truth_idx)</span><br><span class="line">label_landm = tf_encode_landm(matches_landm, self.anchors, self.variances)</span><br></pre></td></tr></table></figure></li>
<li><p>生成<code>calss label</code>，将无效的<code>anchor</code>位置概率设置为0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">label_conf = tf.gather(clses, best_truth_idx)</span><br><span class="line"><span class="comment"># filter gt and anchor overlap less than pos_thresh, set as background</span></span><br><span class="line">label_conf = tf.where(best_truth_overlap[:, <span class="literal">None</span>] &lt; self.pos_thresh,</span><br><span class="line">                          tf.zeros_like(label_conf), label_conf)</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="损失计算">损失计算</h1>
<ol type="1">
<li><p>直接根据<code>calss label</code>得到<code>mask</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bc_num = tf.shape(y_pred)[<span class="number">0</span>]</span><br><span class="line">loc_data, landm_data, conf_data = tf.split(y_pred, [<span class="number">4</span>, <span class="number">10</span>, <span class="number">2</span>], -<span class="number">1</span>)</span><br><span class="line">loc_t, landm_t, conf_t = tf.split(y_true, [<span class="number">4</span>, <span class="number">10</span>, <span class="number">1</span>], -<span class="number">1</span>)</span><br><span class="line"><span class="comment"># landmark loss</span></span><br><span class="line">pos_landm_mask = tf.greater(conf_t, <span class="number">0.</span>)  <span class="comment"># get valid landmark num</span></span><br></pre></td></tr></table></figure></li>
<li><p>根据<code>mask</code>得到有效的<code>landmark label</code>，直接使用<code>smooth_l1_loss</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_pos_landm = tf.maximum(tf.reduce_sum(tf.cast(pos_landm_mask, tf.float32)), <span class="number">1</span>)  <span class="comment"># sum pos landmark num</span></span><br><span class="line">pos_landm_mask = tf.tile(pos_landm_mask, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>])  <span class="comment"># 10, 16800, 10</span></span><br><span class="line"><span class="comment"># filter valid lanmark</span></span><br><span class="line">landm_p = tf.reshape(tf.boolean_mask(landm_data, pos_landm_mask), (-<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">landm_t = tf.reshape(tf.boolean_mask(landm_t, pos_landm_mask), (-<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">loss_landm = tf.reduce_sum(huber_loss(landm_t, landm_p))</span><br></pre></td></tr></table></figure></li>
<li><p>根据<code>mask</code>得到有效的<code>bbox label</code>，直接使用<code>smooth_l1_loss</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pos_loc_mask = tf.tile(pos_conf_mask, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">loc_p = tf.reshape(tf.boolean_mask(loc_data, pos_loc_mask), (-<span class="number">1</span>, <span class="number">4</span>))  <span class="comment"># 792,4</span></span><br><span class="line">loc_t = tf.reshape(tf.boolean_mask(loc_t, pos_loc_mask), (-<span class="number">1</span>, <span class="number">4</span>))</span><br><span class="line">loss_loc = tf.reduce_sum(huber_loss(loc_p, loc_t))</span><br></pre></td></tr></table></figure></li>
<li><p>利用<code>logsumexp</code>将预测出的分类概率求和，得到所有类别概率之和并<strong>减去当前这个<code>anchor</code>所负责的类别的概率</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute max conf across batch for hard negative mining</span></span><br><span class="line">batch_conf = tf.reshape(conf_data, (-<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># 10,16800,2 -&gt; 10*16800,2</span></span><br><span class="line">loss_conf = (tf.reduce_logsumexp(batch_conf, <span class="number">1</span>, <span class="literal">True</span>) -</span><br><span class="line">             tf.gather_nd(batch_conf,</span><br><span class="line">                          tf.concat([tf.<span class="built_in">range</span>(tf.shape(batch_conf)[<span class="number">0</span>])[:, <span class="literal">None</span>],</span><br><span class="line">                                     tf.reshape(conf_t, (-<span class="number">1</span>, <span class="number">1</span>))], <span class="number">1</span>))[:, <span class="literal">None</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>难例挖掘，根据<code>mask</code>得到所有的负样本概率，进行排序并选择合适的负样本数量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss_conf = loss_conf * tf.reshape(tf.cast(tf.logical_not(pos_conf_mask), tf.float32), (-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">loss_conf = tf.reshape(loss_conf, (bc_num, -<span class="number">1</span>))</span><br><span class="line">idx_rank = tf.argsort(tf.argsort(loss_conf, <span class="number">1</span>, direction=<span class="string">&#x27;DESCENDING&#x27;</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">num_pos_conf = tf.reduce_sum(tf.cast(pos_conf_mask, tf.float32), <span class="number">1</span>)</span><br><span class="line">num_neg_conf = tf.minimum(lsfn.negpos_ratio * num_pos_conf,</span><br><span class="line">                          tf.cast(tf.shape(pos_conf_mask)[<span class="number">1</span>], tf.float32) - <span class="number">1.</span>)</span><br><span class="line">neg_conf_mask = tf.less(tf.cast(idx_rank, tf.float32),</span><br><span class="line">                        tf.tile(num_neg_conf, [<span class="number">1</span>, tf.shape(pos_conf_mask)[<span class="number">1</span>]]))[..., <span class="literal">None</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>根据正样本的位置和难例挖掘负样本位置，得到需要计算概率值的位置，对这些位置计算其交叉熵。
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># calc pos , neg confidence loss</span></span><br><span class="line">pos_idx = tf.tile(pos_conf_mask, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">neg_idx = tf.tile(neg_conf_mask, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">conf_p = tf.reshape(tf.boolean_mask(</span><br><span class="line">    conf_data,</span><br><span class="line">    tf.equal(tf.logical_or(pos_idx, neg_idx), <span class="literal">True</span>)), (-<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">conf_t = tf.boolean_mask(conf_t, tf.equal(tf.logical_or(pos_conf_mask, neg_conf_mask), <span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">loss_conf = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(conf_t, conf_p))</span><br></pre></td></tr></table></figure></p></li>
</ol>
<h1 id="推理">推理</h1>
<p>推理好像没啥好说的</p>
<ol type="1">
<li><p>得到输出概率，根据概率过滤得<code>bbox</code>和<code>landmark</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; softmax class&quot;&quot;&quot;</span></span><br><span class="line">clses = softmax(clses, -<span class="number">1</span>)</span><br><span class="line">score = clses[:, <span class="number">1</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot; decode &quot;&quot;&quot;</span></span><br><span class="line">bbox = decode_bbox(bbox, h.anchors.numpy(), h.variances.numpy())</span><br><span class="line">bbox = bbox * np.tile(h.org_in_hw[::-<span class="number">1</span>], [<span class="number">2</span>])</span><br><span class="line"><span class="string">&quot;&quot;&quot; landmark &quot;&quot;&quot;</span></span><br><span class="line">landm = decode_landm(landm, h.anchors.numpy(), h.variances.numpy())</span><br><span class="line">landm = landm * np.tile(h.org_in_hw[::-<span class="number">1</span>], [<span class="number">5</span>])</span><br><span class="line"><span class="string">&quot;&quot;&quot; filter low score &quot;&quot;&quot;</span></span><br><span class="line">inds = np.where(score &gt; obj_thresh)[<span class="number">0</span>]</span><br><span class="line">bbox = bbox[inds]</span><br><span class="line">landm = landm[inds]</span><br><span class="line">score = score[inds] </span><br></pre></td></tr></table></figure></li>
<li><p>解码<code>bbox</code>和<code>landmark</code>，然后<code>nms</code>就完事了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; keep top-k before NMS &quot;&quot;&quot;</span></span><br><span class="line">order = np.argsort(score)[::-<span class="number">1</span>]</span><br><span class="line">bbox = bbox[order]</span><br><span class="line">landm = landm[order]</span><br><span class="line">score = score[order]</span><br><span class="line"><span class="string">&quot;&quot;&quot; do nms &quot;&quot;&quot;</span></span><br><span class="line">keep = nms_oneclass(bbox, score, nms_thresh)</span><br><span class="line">bbox = bbox[keep]</span><br><span class="line">landm = landm[keep]</span><br><span class="line">score = score[keep]</span><br><span class="line"><span class="string">&quot;&quot;&quot; reverse img &quot;&quot;&quot;</span></span><br><span class="line">bbox, landm = reverse_ann(bbox, landm, h.org_in_hw, np.array(orig_hw))</span><br><span class="line">results.append([bbox, landm, score])</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="总结">总结</h1>
<ol type="1">
<li><p>总的来说<code>SSD</code>和<code>YOLO</code>的思想都很好，像<code>YOLO</code>中就没有难例挖掘的东西，因为他把所有负样本都计算损失了～</p></li>
<li><p>不过我觉得<code>YOLO</code>中聚类<code>anchor</code>的方式放到<code>SSD</code>里面绝对是有效的，因为原本的<code>SSD</code>的<code>anchor</code>都是方形的，这样肯定效果没有特定比例的<code>anchor</code>效果好，并且我用聚类生成<code>anchor</code>之后，模型收敛明显加快了。</p></li>
<li><p>还有就是<code>SSD</code>的模型没有上采样部分，这样速度虽然快，但是感受野就没法共享了，现在增加<code>SSD</code>模型的感受野的方式可以在模型中添加<code>FPN</code>、<code>SSH</code>、<code>RFB</code>模块。</p></li>
<li><p>最后我最近还是对<code>DIOU</code>很感兴趣的，希望有空可以加上去试试效果。接下来一段时间得搞语音的东西发论文去了。</p></li>
</ol>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Retinaface/" rel="tag">Retinaface</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li></ul></div><div class="post-nav"><a class="pre" href="/2019/12/21/pfld/">PFLD总结</a><a class="next" href="/2019/12/13/tf-boolmask-index/">tf2.0得到子boolmask在boolmask中的索引</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/03/13/vllm/sglang_attn/">vllm/sglang_attn</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/12/vllm/trt_attn/">vllm/trt_attn</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/12/vllm/vllm_attn/">vllm/vllm_attn</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/12/vllm/tvm_attn/">vllm/tvm_attn</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/23/torch-trick/">Pytorch中遇到的一些问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>