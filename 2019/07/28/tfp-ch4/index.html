<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>概率模型第四章 ： 大数定理 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">概率模型第四章 ： 大数定理</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">概率模型第四章 ： 大数定理</h1><div class="post-meta">2019-07-28<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 5.9k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 27</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#probabilistic-programming-and-bayesian-methods-for-hackers-chapter-4"><span class="toc-number">1.</span> <span class="toc-text">Probabilistic
Programming and Bayesian Methods for Hackers Chapter 4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#kicker-careers-ranked-by-make-percentage"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">Kicker Careers Ranked
by Make Percentage</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#average-household-income-by-programming-language"><span class="toc-number">1.0.0.2.</span> <span class="toc-text">Average
household income by programming language</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#references"><span class="toc-number">1.0.1.</span> <span class="toc-text">References</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>Tensorflow
概率模型学习，代码运行于<code>Tensorflow 1.14</code>，文字半机器翻译。</p>
<span id="more"></span>
<h1
id="probabilistic-programming-and-bayesian-methods-for-hackers-chapter-4">Probabilistic
Programming and Bayesian Methods for Hackers Chapter 4</h1>
<table style="width:14%;">
<colgroup>
<col style="width: 13%" />
</colgroup>
<tbody>
<tr class="odd">
<td>### Table of Contents - Dependencies &amp; Prerequisites - The
greatest theorem never told - The Law of Large Numbers - Intuition - How
do we compute <span class="math inline">\(Var(Z)\)</span> though? -
Expected values and probabilities - What does this all have to do with
Bayesian statistics? - The Disorder of Small Numbers - Example:
Aggregated geographic data - Example: Kaggle's U.S. Census Return Rate
Challenge - Example: How to order Reddit submissions - Setting up the
Praw Reddit API - Register your Application on Reddit - Reddit API Setup
- Sorting! - But this is too slow for real-time! - Extension to Starred
rating systems - Example: Counting Github stars - Conclusion - Appendix
- Exercises - Kicker Careers Ranked by Make Percentage - Average
Household Income by Programming Language - References</td>
</tr>
<tr class="even">
<td>______</td>
</tr>
<tr class="odd">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#@title Imports and Global Variables  &#123; display-mode: &quot;form&quot; &#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">The book uses a custom matplotlibrc file, which provides the unique styles for</span></span><br><span class="line"><span class="string">matplotlib plots. If executing this book, and you wish to use the book&#x27;s</span></span><br><span class="line"><span class="string">styling, provided are two options:</span></span><br><span class="line"><span class="string">    1. Overwrite your own matplotlibrc file with the rc-file provided in the</span></span><br><span class="line"><span class="string">       book&#x27;s styles/ dir. See http://matplotlib.org/users/customizing.html</span></span><br><span class="line"><span class="string">    2. Also in the styles is  bmh_matplotlibrc.json file. This can be used to</span></span><br><span class="line"><span class="string">       update the styles in only this notebook. Try running the following code:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        import json</span></span><br><span class="line"><span class="string">        s = json.load(open(&quot;../styles/bmh_matplotlibrc.json&quot;))</span></span><br><span class="line"><span class="string">        matplotlib.rcParams.update(s)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function</span><br><span class="line"></span><br><span class="line"><span class="comment">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span></span><br><span class="line">warning_status = <span class="string">&quot;ignore&quot;</span> <span class="comment">#@param [&quot;ignore&quot;, &quot;always&quot;, &quot;module&quot;, &quot;once&quot;, &quot;default&quot;, &quot;error&quot;]</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(warning_status)</span><br><span class="line"><span class="keyword">with</span> warnings.catch_warnings():</span><br><span class="line">    warnings.filterwarnings(warning_status, category=DeprecationWarning)</span><br><span class="line">    warnings.filterwarnings(warning_status, category=UserWarning)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))</span></span><br><span class="line">matplotlib_style = <span class="string">&#x27;fivethirtyeight&#x27;</span> <span class="comment">#@param [&#x27;fivethirtyeight&#x27;, &#x27;bmh&#x27;, &#x27;ggplot&#x27;, &#x27;seaborn&#x27;, &#x27;default&#x27;, &#x27;Solarize_Light2&#x27;, &#x27;classic&#x27;, &#x27;dark_background&#x27;, &#x27;seaborn-colorblind&#x27;, &#x27;seaborn-notebook&#x27;]</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt; plt.style.use(matplotlib_style)</span><br><span class="line"><span class="keyword">import</span> matplotlib.axes <span class="keyword">as</span> axes;</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Ellipse</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> pandas_datareader.data <span class="keyword">as</span> web</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns; sns.set_context(<span class="string">&#x27;notebook&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> IPython.core.pylabtools <span class="keyword">import</span> figsize</span><br><span class="line"><span class="comment">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span></span><br><span class="line">notebook_screen_res = <span class="string">&#x27;retina&#x27;</span> <span class="comment">#@param [&#x27;retina&#x27;, &#x27;png&#x27;, &#x27;jpeg&#x27;, &#x27;svg&#x27;, &#x27;pdf&#x27;]</span></span><br><span class="line">%config InlineBackend.figure_format = notebook_screen_res</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;YaHei Consolas Hybrid&#x27;</span>]</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tfe = tf.contrib.eager</span><br><span class="line"></span><br><span class="line"><span class="comment"># Eager Execution</span></span><br><span class="line"><span class="comment">#@markdown Check the box below if you want to use [Eager Execution](https://www.tensorflow.org/guide/eager)</span></span><br><span class="line"><span class="comment">#@markdown Eager execution provides An intuitive interface, Easier debugging, and a control flow comparable to Numpy. You can read more about it on the [Google AI Blog](https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html)</span></span><br><span class="line">use_tf_eager = <span class="literal">False</span> <span class="comment">#@param &#123;type:&quot;boolean&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use try/except so we can easily re-execute the whole notebook.</span></span><br><span class="line"><span class="keyword">if</span> use_tf_eager:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tf.enable_eager_execution()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow_probability <span class="keyword">as</span> tfp</span><br><span class="line">tfd = tfp.distributions</span><br><span class="line">tfb = tfp.bijectors</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">tensors</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Evaluates Tensor or EagerTensor to Numpy `ndarray`s.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,</span></span><br><span class="line"><span class="string">      `namedtuple` or combinations thereof.</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      ndarrays: Object with same structure as `tensors` except with `Tensor` or</span></span><br><span class="line"><span class="string">        `EagerTensor`s replaced by Numpy `ndarray`s.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> tf.executing_eagerly():</span><br><span class="line">        <span class="keyword">return</span> tf.contrib.framework.nest.pack_sequence_as(</span><br><span class="line">            tensors,</span><br><span class="line">            [t.numpy() <span class="keyword">if</span> tf.contrib.framework.is_tensor(t) <span class="keyword">else</span> t</span><br><span class="line">             <span class="keyword">for</span> t <span class="keyword">in</span> tf.contrib.framework.nest.flatten(tensors)])</span><br><span class="line">    <span class="keyword">return</span> sess.run(tensors)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_TFColor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Enum of colors used in TF docs.&quot;&quot;&quot;</span></span><br><span class="line">    red = <span class="string">&#x27;#F15854&#x27;</span></span><br><span class="line">    blue = <span class="string">&#x27;#5DA5DA&#x27;</span></span><br><span class="line">    orange = <span class="string">&#x27;#FAA43A&#x27;</span></span><br><span class="line">    green = <span class="string">&#x27;#60BD68&#x27;</span></span><br><span class="line">    pink = <span class="string">&#x27;#F17CB0&#x27;</span></span><br><span class="line">    brown = <span class="string">&#x27;#B2912F&#x27;</span></span><br><span class="line">    purple = <span class="string">&#x27;#B276B2&#x27;</span></span><br><span class="line">    yellow = <span class="string">&#x27;#DECF3F&#x27;</span></span><br><span class="line">    gray = <span class="string">&#x27;#4D4D4D&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, i</span>):</span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            self.red,</span><br><span class="line">            self.orange,</span><br><span class="line">            self.green,</span><br><span class="line">            self.blue,</span><br><span class="line">            self.pink,</span><br><span class="line">            self.brown,</span><br><span class="line">            self.purple,</span><br><span class="line">            self.yellow,</span><br><span class="line">            self.gray,</span><br><span class="line">        ][i % <span class="number">9</span>]</span><br><span class="line">TFColor = _TFColor()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">session_options</span>(<span class="params">enable_gpu_ram_resizing=<span class="literal">True</span>, enable_xla=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Allowing the notebook to make use of GPUs if they&#x27;re available.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear </span></span><br><span class="line"><span class="string">    algebra that optimizes TensorFlow computations.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    config = tf.ConfigProto()</span><br><span class="line">    config.log_device_placement = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> enable_gpu_ram_resizing:</span><br><span class="line">        <span class="comment"># `allow_growth=True` makes it possible to connect multiple colabs to your</span></span><br><span class="line">        <span class="comment"># GPU. Otherwise the colab malloc&#x27;s all GPU ram.</span></span><br><span class="line">        config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> enable_xla:</span><br><span class="line">        <span class="comment"># Enable on XLA. https://www.tensorflow.org/performance/xla/.</span></span><br><span class="line">        config.graph_options.optimizer_options.global_jit_level = (tf.OptimizerOptions.ON_1)</span><br><span class="line">    <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reset_sess</span>(<span class="params">config=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Convenience function to create the TF graph &amp; session or reset them.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> config <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        config = session_options()</span><br><span class="line">    <span class="keyword">global</span> sess</span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sess.close()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    sess = tf.InteractiveSession(config=config)</span><br><span class="line"></span><br><span class="line">reset_sess()</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="even">
<td>WARNING: Logging before flag parsing goes to stderr. W0728
19:21:27.291700 139811709552448 lazy_loader.py:50] The TensorFlow
contrib module will not be included in TensorFlow 2.0. For more
information, please see: *
https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
* https://github.com/tensorflow/addons *
https://github.com/tensorflow/io (for I/O related ops) If you depend on
functionality not listed there, please file an issue.</td>
</tr>
<tr class="odd">
<td>## 最伟大的定理从未被告知过</td>
</tr>
<tr class="even">
<td>本章的重点是一个总是在我们脑海中蹦蹦跳跳的想法，但很少在专门用于统计的书籍之外明确表达。事实上，到目前为止，我们在每个例子中都使用过这个简单的想法。</td>
</tr>
<tr class="odd">
<td>### 大数定律</td>
</tr>
<tr class="even">
<td>让$ Z_i <span class="math inline">\(为\)</span> N <span
class="math inline">\(来自某些概率分布的独立样本。根据*大数定律*，只要预期值\)</span>
E[Z] $是有限的，以下成立，</td>
</tr>
<tr class="odd">
<td><span class="math display">\[\frac{1}{N} \sum_{i=1}^N Z_i
\rightarrow E[ Z ],  \;\;\; N \rightarrow \infty.\]</span></td>
</tr>
<tr class="even">
<td>文字表述:</td>
</tr>
<tr class="odd">
<td>&gt; 来自相同分布的随机变量序列的平均值收敛于该分布的期望。</td>
</tr>
<tr class="even">
<td>这似乎是一个无聊的结果，但它将是您使用的最有用的工具。他是计算机数值计算的重要手段。</td>
</tr>
<tr class="odd">
<td>### 直觉</td>
</tr>
<tr class="even">
<td>如果上述法律有些令人惊讶，可以通过研究一个简单的例子来更清楚地说明。</td>
</tr>
<tr class="odd">
<td>考虑一个随机变量$ Z <span
class="math inline">\(，它只能带两个值，\)</span> c_1 <span
class="math inline">\(和\)</span> c_2 <span
class="math inline">\(。假设我们有大量\)</span> Z <span
class="math inline">\(的样本，表示一个特定的样本\)</span> Z_i <span
class="math inline">\(。该定理规定，我们可以通过平均所有样本来估计\)</span>
Z $的预期值。考虑平均值：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ \frac{1}{N} \sum_{i=1}^N \;Z_i
\]</span></td>
</tr>
<tr class="odd">
<td>通过构造，$ Z_i <span class="math inline">\(只能接受\)</span> c_1
<span class="math inline">\(或\)</span> c_2
$，因此我们可以对这两个值进行分区： <span class="math display">\[
\begin{align}
\frac{1}{N} \sum_{i=1}^N \;Z_i &amp; =\frac{1}{N} \big(  \sum_{ Z_i =
c_1}c_1 + \sum_{Z_i=c_2}c_2 \big) \\
&amp; = c_1 \sum_{ Z_i = c_1}\frac{1}{N} + c_2 \sum_{ Z_i =
c_2}\frac{1}{N} \\
&amp; = c_1 \times \text{ (approximate frequency of $c_1$) } \\
&amp; \;\;\;\;\;\;\;\;\; + c_2 \times \text{ (approximate frequency of
$c_2$) } \\
&amp; \approx c_1 \times P(Z = c_1) + c_2 \times P(Z = c_2 ) \\
&amp; = E[Z]
\end{align}
\]</span></td>
</tr>
<tr class="even">
<td>在极限平等保持，但我们可以通过在平均值中使用越来越多的样本来越来越近。该法适用于几乎<em>任何分布</em>，减去我们稍后将遇到的一些重要案例。</td>
</tr>
<tr class="odd">
<td>### 例子 ____</td>
</tr>
<tr class="even">
<td>下面是三个不同泊松随机变量序列的大数定律图。</td>
</tr>
<tr class="odd">
<td>我们用参数$ = 4.5 <span class="math inline">\(对`sample_size =
100000`泊松随机变量进行抽样。
（回想一下泊松随机变量的期望值等于它的参数。）我们计算前\)</span> n
<span
class="math inline">\(个样本的平均值，\)</span>n=1$到<code>sample_size</code>。</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sample_size_ = <span class="number">100000</span></span><br><span class="line">expected_value_ = lambda_val_ = <span class="number">4.5</span></span><br><span class="line">N_samples = tf.<span class="built_in">range</span>(start=<span class="number">1</span>,</span><br><span class="line">                      limit=sample_size_,</span><br><span class="line">                      delta=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize(<span class="number">12.5</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    samples = tfd.Poisson(rate=lambda_val_).sample(sample_shape=(sample_size_))</span><br><span class="line">    [ samples_, N_samples_ ] = evaluate([ samples, N_samples ]) </span><br><span class="line"></span><br><span class="line">    partial_average_ = [ samples_[:i].mean() <span class="keyword">for</span> i <span class="keyword">in</span> N_samples_ ]        </span><br><span class="line"></span><br><span class="line">    plt.plot( N_samples_, partial_average_, lw=<span class="number">1.5</span>,label=<span class="string">&quot;$n$个样本的平均值 ; seq. %d&quot;</span>%k)</span><br><span class="line"></span><br><span class="line">plt.plot( N_samples_, expected_value_ * np.ones_like( partial_average_), </span><br><span class="line">    ls = <span class="string">&quot;--&quot;</span>, label = <span class="string">&quot;真实期望值&quot;</span>, c = <span class="string">&quot;k&quot;</span> )</span><br><span class="line"></span><br><span class="line">plt.ylim( <span class="number">4.35</span>, <span class="number">4.65</span>) </span><br><span class="line">plt.title( <span class="string">&quot;随机变量的平均值与其期望的收敛性&quot;</span> )</span><br><span class="line">plt.ylabel( <span class="string">&quot;average of $n$ samples&quot;</span> )</span><br><span class="line">plt.xlabel( <span class="string">&quot;# of samples, $n$&quot;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td><img src="/2019/07/28/tfp-ch4/output_6_0.png" /></td>
</tr>
<tr class="even">
<td>看一下上面的图，很明显，当样本量很小时，平均值会有较大的变化（比较<em>跳跃</em>的最初平均值，然后<em>平滑</em>）。所有三条路径<em>接近</em>值4.5，但随着$
N $变大，只是调整它。数学家和统计学家有另一个名字：收敛。</td>
</tr>
<tr class="odd">
<td>我们可以问的另一个非常相关的问题是<em>我收敛到预期值的速度有多快？</em>让我们绘制一些新的东西。对于特定的$
N <span
class="math inline">\(，让我们进行上述试验数千次，并计算出我们与真实预期值的平均距离。但等等——*平均计算*？这只是大数法则！例如，我们感兴趣的是，对于特定的\)</span>
N $，数量：</td>
</tr>
<tr class="even">
<td><span class="math display">\[D(N) = \sqrt{ \;E\left[\;\; \left(
\frac{1}{N}\sum_{i=1}^NZ_i  - 4.5 \;\right)^2 \;\;\right]
\;\;}\]</span></td>
</tr>
<tr class="odd">
<td>对于某些$ N <span
class="math inline">\(，上述公式可解释为距离真实值（平均值）的距离。
（我们取平方根，因此上述数量的维数和我们的随机变量是相同的）。由于上面是一个期望值，它可以使用大数定律近似：我们计算以下多次并平均它们，而不是平均\)</span>
Z_i $：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ Y_k = \left(
\;\frac{1}{N}\sum_{i=1}^NZ_i  - 4.5 \; \right)^2 \]</span></td>
</tr>
<tr class="odd">
<td>通过计算上面的$ N_y $次（记住，它是随机的），并对它们求平均值：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ \frac{1}{N_Y} \sum_{k=1}^{N_Y} Y_k
\rightarrow E[ Y_k ] = E\;\left[\;\; \left(
\frac{1}{N}\sum_{i=1}^NZ_i  - 4.5 \;\right)^2 \right]\]</span></td>
</tr>
<tr class="odd">
<td>最后，取平方根：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ \sqrt{\frac{1}{N_Y} \sum_{k=1}^{N_Y}
Y_k} \approx D(N) \]</span></td>
</tr>
<tr class="odd">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N_Y = tf.constant(<span class="number">250</span>)  <span class="comment"># 用这么多来近似 D(N)</span></span><br><span class="line">N_array = tf.<span class="built_in">range</span>(<span class="number">1000.</span>, <span class="number">50000.</span>, <span class="number">2500</span>) <span class="comment"># 在大约使用这么多样品。差异。</span></span><br><span class="line">D_N_results = tf.zeros(tf.shape(N_array)[<span class="number">0</span>])</span><br><span class="line">lambda_val = tf.constant(<span class="number">4.5</span>) </span><br><span class="line">expected_value = tf.constant(<span class="number">4.5</span>) <span class="comment">#for X ~ Poi(lambda) , E[ X ] = lambda</span></span><br><span class="line"></span><br><span class="line">[</span><br><span class="line">    N_Y_, </span><br><span class="line">    N_array_, </span><br><span class="line">    D_N_results_, </span><br><span class="line">    expected_value_, </span><br><span class="line">    lambda_val_,</span><br><span class="line">] = evaluate([ </span><br><span class="line">    N_Y, </span><br><span class="line">    N_array, </span><br><span class="line">    D_N_results, </span><br><span class="line">    expected_value,</span><br><span class="line">    lambda_val,</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">D_N</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function approx. D_n, the average variance of using n samples.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Z = tfd.Poisson(rate=lambda_val_).sample(sample_shape=(<span class="built_in">int</span>(n), <span class="built_in">int</span>(N_Y_)))</span><br><span class="line">    average_Z = tf.reduce_mean(Z, axis=<span class="number">0</span>)</span><br><span class="line">    average_Z_ = evaluate(average_Z)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> np.sqrt(((average_Z_ - expected_value_)**<span class="number">2</span>).mean())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,n <span class="keyword">in</span> <span class="built_in">enumerate</span>(N_array_):</span><br><span class="line">    D_N_results_[i] =  D_N(n)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize(<span class="number">12.5</span>, <span class="number">3</span>))</span><br><span class="line">plt.xlabel( <span class="string">&quot;$N$&quot;</span> )</span><br><span class="line">plt.ylabel( <span class="string">&quot;预期与真实值的平方距离&quot;</span> )</span><br><span class="line">plt.plot(N_array_, D_N_results_, lw = <span class="number">3</span>, label=<span class="string">&quot;随机变量$N$的预期值与平均值之间的预期距离。&quot;</span>)</span><br><span class="line">plt.plot( N_array_, np.sqrt(expected_value_)/np.sqrt(N_array_), lw = <span class="number">3</span>, ls = <span class="string">&quot;--&quot;</span>, label = <span class="string">r&quot;$\frac&#123;\sqrt&#123;\lambda&#125;&#125;&#123;\sqrt&#123;N&#125;&#125;$&quot;</span> )</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title( <span class="string">&quot;样本平均收敛的“快”程度如何？ &quot;</span> );</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="even">
<td><img src="/2019/07/28/tfp-ch4/output_8_0.png" /></td>
</tr>
<tr class="odd">
<td>正如预期的那样，随着$ N
$增长，我们的样本平均值与实际预期值之间的预期距离会缩小。但也注意到<em>收敛率</em>降低，也就是说，我们只需要10
000个额外样本从0.020移动到0.015，相差0.005，但是<em>20000</em>更多样本再次从0.015降低到0.010，再次只有0.005减少。</td>
</tr>
<tr class="even">
<td>事实证明，我们可以衡量这种收敛速度。上面我绘制了第二行，函数$ /
<span
class="math inline">\(。这不是任意选择的。在大多数情况下，给定一系列随机变量分布如\)</span>
Z <span class="math inline">\(，大数定律的收敛率为\)</span> E [Z] $</td>
</tr>
<tr class="odd">
<td><span class="math display">\[ \frac{ \sqrt{ \; Var(Z) \; }
}{\sqrt{N} }\]</span></td>
</tr>
<tr class="even">
<td>这有用的知识：对于给定的大$ N <span
class="math inline">\(，我们知道（平均而言）我们与估计的距离。另一方面，在贝叶斯环境中，这似乎是一个无用的结果：贝叶斯分析是不确定的，那么添加额外精确数字的*统计*点是什么？虽然绘图样本的计算成本可以很低，但*越大的*\)</span>N$也很好。</td>
</tr>
<tr class="odd">
<td>### 我们如何计算$ Var（Z）$？</td>
</tr>
<tr class="even">
<td>方差只是另一个可以近似的预期值！考虑以下情况，一旦我们得到预期值（通过使用大数定律来估计它，表示$
$），我们可以估计方差：</td>
</tr>
<tr class="odd">
<td><span class="math display">\[ \frac{1}{N}\sum_{i=1}^N \;(Z_i -
\mu)^2 \rightarrow E[ \;( Z - \mu)^2 \;] = Var( Z )\]</span></td>
</tr>
<tr class="even">
<td>### 期望值和概率</td>
</tr>
<tr class="odd">
<td>期望值与估计概率之间的关系更为明显。定义<em>指标功能</em></td>
</tr>
<tr class="even">
<td><span class="math display">\[\mathbb{1}_A(x) =
\begin{cases} 1 &amp;  x \in A \\\\
0 &amp;  else
\end{cases}
\]</span></td>
</tr>
<tr class="odd">
<td>然后，根据大数定律，如果我们有许多样本$ X_i <span
class="math inline">\(，我们可以通过以下方式估计事件\)</span> A <span
class="math inline">\(的概率，表示为\)</span> P（A）$：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ \frac{1}{N} \sum_{i=1}^N
\mathbb{1}_A(X_i) \rightarrow E[\mathbb{1}_A(X)] =  P(A) \]</span></td>
</tr>
<tr class="odd">
<td>同样，经过一段时间的观测后，这是相当明显的：如果事件发生，指标函数只有1，所以我们只将事件发生的时间相加并除以试验总数（考虑我们通常如何使用频率逼近概率）
。例如，假设我们希望估计$ Z Exp（.5）<span
class="math inline">\(大于5的概率，并且我们从\)</span>
Exp（.5）$分布中得到许多样本。</td>
</tr>
<tr class="even">
<td><span class="math display">\[ P( Z &gt; 5 )
=  \frac{1}{N}\sum_{i=1}^N \mathbb{1}_{z &gt; 5 }(Z_i) \]</span></td>
</tr>
<tr class="odd">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;概率估计: &quot;</span>, <span class="built_in">len</span>(np.where(evaluate(tfd.Exponential(rate=<span class="number">0.5</span>).sample(sample_shape=N)) &gt; <span class="number">5</span>))/N )</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="even">
<td>概率估计: 0.0001</td>
</tr>
<tr class="odd">
<td>### 这与贝叶斯统计有什么关系？</td>
</tr>
<tr class="even">
<td>使用期望值计算贝叶斯推断中将在下一章中介绍的<em>点估计</em>。在更多分析的贝叶斯推断中，我们需要评估表示为多维积分的复杂期望值。不再。如果我们可以直接从后验分布中进行采样，我们只需要评估平均值。更容易。如果准确性是一个优先事项，那么上面的图表显示你收敛速度有多快。如果需要进一步的精确度，只需从后验中采集更多样本。</td>
</tr>
<tr class="odd">
<td>什么时候够了？你何时可以停止从后方抽取样本？这是从业者的决定，也取决于样本的方差（从上面回忆高方差意味着平均值会收敛得更慢）。</td>
</tr>
<tr class="even">
<td>我们也应该理解大数定律何时失败。顾名思义，并将上面的图表与小<span
class="math inline">\(N\)</span>进行比较，该法则适用于大样本量。没有这个，渐近结果是不可靠的。了解定理失败的情况可以让我们对自己应该多么<em>不自信</em>充满信心。下一节将讨论此问题。</td>
</tr>
<tr class="odd">
<td>### 小数目的紊乱</td>
</tr>
<tr class="even">
<td>大数定律只有在$ N
$得到<em>无限大</em>时才有效：永远不可能实现。虽然定理是一个强有力的工具，但广泛地应用它是蛮干的。我们的下一个例子说明了这</td>
</tr>
<tr class="odd">
<td>### Example: 汇总的地理数据</td>
</tr>
<tr class="even">
<td>数据通常以汇总形式出现。例如，数据可以按州，县或城市级别分组。当然，人口数量因地理区域而异。如果数据是每个地理区域的某些特征的平均值，那么我们必须意识到大数定律以及它对于人口较少的区域如何<em>失败</em>。</td>
</tr>
<tr class="odd">
<td>我们将在玩具数据集上观察到这一点。假设我们的数据集中有五千个县。此外，每个州的人口数量均匀分布在100到1500之间。人口数量的生成方式与讨论无关，因此我们不能证明这一点。我们感兴趣的是测量每个县的平均身高。我们不知道，身高不会因县而异，每个人，无论他或她目前居住在哪个县，都有与他们身高相同的分布：</td>
</tr>
<tr class="even">
<td><span class="math display">\[ \text{height} \sim
\text{Normal}(\text{mu}=150, \text{sd}=15 ) \]</span></td>
</tr>
<tr class="odd">
<td>我们汇总了县级的个人，因此我们只有县内<em>平均值的数据</em>。我们的数据集可能是什么样的？</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize(<span class="number">12.5</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">std_height = <span class="number">15.</span></span><br><span class="line">mean_height = <span class="number">150.</span></span><br><span class="line">n_counties = <span class="number">500</span></span><br><span class="line">smallest_population = <span class="number">100</span></span><br><span class="line">largest_population = <span class="number">1500</span></span><br><span class="line">pop_generator = np.random.randint</span><br><span class="line">norm = np.random.normal</span><br><span class="line"></span><br><span class="line">population_ = pop_generator(smallest_population, largest_population, n_counties)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Our strategy to vectorize this problem will be to end-to-end concatenate the</span></span><br><span class="line"><span class="comment"># number of draws we need. Then we&#x27;ll loop over the pieces.</span></span><br><span class="line">d = tfp.distributions.Normal(loc=mean_height, scale= <span class="number">1.</span> / std_height)</span><br><span class="line">x = d.sample(np.<span class="built_in">sum</span>(population_))</span><br><span class="line"></span><br><span class="line">average_across_county = []</span><br><span class="line">seen = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> population_:</span><br><span class="line">    average_across_county.append(tf.reduce_mean(x[seen:seen+p]))</span><br><span class="line">    seen += p</span><br><span class="line">average_across_county_full = tf.stack(average_across_county)</span><br><span class="line"></span><br><span class="line"><span class="comment">##located the counties with the apparently most extreme average heights.</span></span><br><span class="line">[   average_across_county_,</span><br><span class="line">    i_min, </span><br><span class="line">    i_max </span><br><span class="line">] = evaluate([</span><br><span class="line">    average_across_county_full,</span><br><span class="line">    tf.argmin( average_across_county_full ), </span><br><span class="line">    tf.argmax( average_across_county_full )</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot population size vs. recorded average</span></span><br><span class="line">plt.scatter( population_, average_across_county_, alpha = <span class="number">0.5</span>, c=TFColor[<span class="number">6</span>])</span><br><span class="line">plt.scatter( [ population_[i_min], population_[i_max] ], </span><br><span class="line">           [average_across_county_[i_min], average_across_county_[i_max] ],</span><br><span class="line">           s = <span class="number">60</span>, marker = <span class="string">&quot;o&quot;</span>, facecolors = <span class="string">&quot;none&quot;</span>,</span><br><span class="line">           edgecolors = TFColor[<span class="number">0</span>], linewidths = <span class="number">1.5</span>, </span><br><span class="line">            label=<span class="string">&quot;极端的高度&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim( smallest_population, largest_population )</span><br><span class="line">plt.title( <span class="string">&quot;平均高度 vs. 县人口&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;县人口&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;县的平均身高&quot;</span>)</span><br><span class="line">plt.plot( [smallest_population, largest_population], [mean_height, mean_height], color = <span class="string">&quot;k&quot;</span>, label = <span class="string">&quot;true expected \</span></span><br><span class="line"><span class="string">height&quot;</span>, ls=<span class="string">&quot;--&quot;</span> )</span><br><span class="line">plt.legend(scatterpoints = <span class="number">1</span>);</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td><img src="/2019/07/28/tfp-ch4/output_15_0.png" /></td>
</tr>
<tr class="even">
<td>我们观察到了什么？ <em>如果不考虑人口规模</em>
我们冒着造成巨大推理错误的风险：如果我们忽略了人口规模，我们会说最短和最高个体的县已被正确圈出。但由于以下原因，这种推断是错误的。这两个县<em>不一定</em>具有最极端的高度。计算出的较小种群的平均值不能很好地反映出人口的真实预期价值（事实上应该是$
= 150 $）。样本大小/人口规模/ $ N
$，无论你想要什么，它都太小了，无法有效地调用大数定律。</td>
</tr>
<tr class="odd">
<td>我们提供了更多反对这种推论的证据。回想一下，人口数量均匀分布在100到1500之间。我们的直觉应该告诉我们，人口最高极度的县也应该统一分布在100到1500之间，当然也不依赖于该县的人口。不是这样。以下是具有最极端高度的县的人口规模。</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;10个最少县的人口规模：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(population_[ np.argsort( average_across_county_ )[:<span class="number">10</span>] ], <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;10个最高县的人口规模： &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(population_[ np.argsort( -average_across_county_ )[:<span class="number">10</span>] ])</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td>10个最少县的人口规模： [160 134 280 129 207 176 411 256 247
176]</td>
</tr>
<tr class="even">
<td>10个最高县的人口规模： [113 127 258 362 185 224 478 310 148
312]</td>
</tr>
<tr class="odd">
<td>在100到1500之间根本没有统一。这是大数定律的绝对失败。</td>
</tr>
<tr class="even">
<td>### 示例：Kaggle的<em>美国。人口普查退货率挑战</em></td>
</tr>
<tr class="odd">
<td>以下是2010年美国人口普查的数据，该数据将县以外的人口划分为街区集团（城市街区或同等城市的集合）。这个数据集来自Kaggle机器学习竞赛，一些同事和我参与了。目的是使用人口普查变量（中位数收入，女性人数）预测一组群体的人口普查信件回邮率，测量值在0到100之间。街区集团，拖车停车场数量，平均儿童人数等）。下面我们绘制人口普查邮件回复率与块组人口的关系：</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reset_sess()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> wget</span><br><span class="line">url = <span class="string">&#x27;https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/data/census_data.csv&#x27;</span></span><br><span class="line">filename = wget.download(url)</span><br><span class="line">filename</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td>'census_data.csv'</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize(<span class="number">12.5</span>, <span class="number">6.5</span>))</span><br><span class="line">data_ = np.genfromtxt( <span class="string">&quot;census_data.csv&quot;</span>, skip_header=<span class="number">1</span>, </span><br><span class="line">                        delimiter= <span class="string">&quot;,&quot;</span>)</span><br><span class="line">plt.scatter( data_[:,<span class="number">1</span>], data_[:,<span class="number">0</span>], alpha = <span class="number">0.5</span>, c=TFColor[<span class="number">6</span>])</span><br><span class="line">plt.title(<span class="string">&quot;人口普查邮寄回邮率与人口&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;邮寄回复率&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;块组人口&quot;</span>)</span><br><span class="line">plt.xlim(-<span class="number">100</span>, <span class="number">15e3</span> )</span><br><span class="line">plt.ylim( -<span class="number">5</span>, <span class="number">105</span>)</span><br><span class="line"></span><br><span class="line">i_min = tf.argmin(  data_[:,<span class="number">0</span>] )</span><br><span class="line">i_max = tf.argmax(  data_[:,<span class="number">0</span>] )</span><br><span class="line"></span><br><span class="line">[ i_min_, i_max_ ] = evaluate([ i_min, i_max ])</span><br><span class="line"> </span><br><span class="line">plt.scatter( [ data_[i_min_,<span class="number">1</span>], data_[i_max_, <span class="number">1</span>] ], </span><br><span class="line">             [ data_[i_min_,<span class="number">0</span>], data_[i_max_,<span class="number">0</span>] ],</span><br><span class="line">             s = <span class="number">60</span>, marker = <span class="string">&quot;o&quot;</span>, facecolors = <span class="string">&quot;none&quot;</span>,</span><br><span class="line">             edgecolors = TFColor[<span class="number">0</span>], linewidths = <span class="number">1.5</span>, </span><br><span class="line">             label=<span class="string">&quot;最极端的点&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(scatterpoints = <span class="number">1</span>);</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td><img src="/2019/07/28/tfp-ch4/output_20_0.png" /></td>
</tr>
<tr class="even">
<td>以上是统计学中的经典现象。我说<em>经典</em>指的是上面散点图的“形状”。它遵循经典的三角形形式，随着我们增加样本大小而紧缩（随着大数定律变得更加精确）。</td>
</tr>
<tr class="odd">
<td>我可能会过分强调这一点，也许我应该把这本书命名为“你没有大数据问题！”，但这里再次举例说明<em>小数据集</em>的问题，而不是大数据集。简单地说，使用大数定律不能处理小数据集。与对大数据集（例如大数据）毫不费力地应用定理相比较。我之前提到矛盾的是，大数据预测问题是通过相对简单的算法解决的。通过理解大数定律创建<em>稳定</em>的解决方案，即加入或减少一些数据点不会对解决方案产生太大影响，可以部分解决悖论。另一方面，向小型数据集添加或删除数据点可能会产生截然不同的结果。</td>
</tr>
<tr class="even">
<td>为了进一步阅读大数定律的隐患，我强烈推荐优秀的手稿<a
target="_blank" rel="noopener" href="http://nsm.uh.edu/~dgraur/niv/TheMostDangerousEquation.pdf">最危险的方程式</a></td>
</tr>
<tr class="odd">
<td>### Example: 计算Github星</td>
</tr>
<tr class="even">
<td>Github存储库的平均星数是多少？你怎么算这个？有超过600万个存储库，因此有足够的数据来调用大数定律。让我们开始提取一些数据。</td>
</tr>
<tr class="odd">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reset_sess()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> wget</span><br><span class="line">url = <span class="string">&#x27;https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/data/github_data.csv&#x27;</span></span><br><span class="line">filename = wget.download(url)</span><br><span class="line">filename</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="even">
<td>'github_data (1).csv'</td>
</tr>
<tr class="odd">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Github data scrapper</span></span><br><span class="line"><span class="comment"># See documentation_url: https://developer.github.com/v3/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> json <span class="keyword">import</span> loads</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> get</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">variables of interest:</span></span><br><span class="line"><span class="string">    indp. variables</span></span><br><span class="line"><span class="string">    - language, given as a binary variable. Need 4 positions for 5 langagues</span></span><br><span class="line"><span class="string">    - #number of days created ago, 1 position</span></span><br><span class="line"><span class="string">    - has wiki? Boolean, 1 position</span></span><br><span class="line"><span class="string">    - followers, 1 position</span></span><br><span class="line"><span class="string">    - following, 1 position</span></span><br><span class="line"><span class="string">    - constant</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    dep. variables</span></span><br><span class="line"><span class="string">    -stars/watchers</span></span><br><span class="line"><span class="string">    -forks</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MAX = <span class="number">8000000</span></span><br><span class="line">today =  datetime.datetime.today()</span><br><span class="line">randint = np.random.randint</span><br><span class="line">N = <span class="number">10</span> <span class="comment">#sample size. </span></span><br><span class="line">auth = (<span class="string">&quot;zhen8838&quot;</span>, <span class="string">&quot;zqh19960305&quot;</span> )</span><br><span class="line"></span><br><span class="line">language_mappings = &#123;<span class="string">&quot;Python&quot;</span>: <span class="number">0</span>, <span class="string">&quot;JavaScript&quot;</span>: <span class="number">1</span>, <span class="string">&quot;Ruby&quot;</span>: <span class="number">2</span>, <span class="string">&quot;Java&quot;</span>:<span class="number">3</span>, <span class="string">&quot;Shell&quot;</span>:<span class="number">4</span>, <span class="string">&quot;PHP&quot;</span>:<span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#define data matrix: </span></span><br><span class="line">X = np.zeros( (N , <span class="number">12</span>), dtype = <span class="built_in">int</span> )</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    is_fork = <span class="literal">True</span></span><br><span class="line">    is_valid_language = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> is_fork == <span class="literal">True</span> <span class="keyword">or</span> is_valid_language == <span class="literal">False</span>:</span><br><span class="line">        is_fork = <span class="literal">True</span></span><br><span class="line">        is_valid_language = <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        params = &#123;<span class="string">&quot;since&quot;</span>:randint(<span class="number">0</span>, MAX ) &#125;</span><br><span class="line">        r = get(<span class="string">&quot;https://api.github.com/repositories&quot;</span>, params = params, auth=auth )</span><br><span class="line">        results = loads( r.text )[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#im only interested in the first one, and if it is not a fork.</span></span><br><span class="line"><span class="comment">#         print(results)</span></span><br><span class="line">        is_fork = results[<span class="string">&quot;fork&quot;</span>]</span><br><span class="line">        </span><br><span class="line">        r = get( results[<span class="string">&quot;url&quot;</span>], auth = auth)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#check the language</span></span><br><span class="line">        repo_results = loads( r.text )</span><br><span class="line">        <span class="keyword">try</span>: </span><br><span class="line">            language_mappings[ repo_results[<span class="string">&quot;language&quot;</span> ] ]</span><br><span class="line">            is_valid_language = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#languages </span></span><br><span class="line">    X[ i, language_mappings[ repo_results[<span class="string">&quot;language&quot;</span> ] ] ] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#delta time</span></span><br><span class="line">    X[ i, <span class="number">6</span>] = ( today - datetime.datetime.strptime( repo_results[<span class="string">&quot;created_at&quot;</span>][:<span class="number">10</span>], <span class="string">&quot;%Y-%m-%d&quot;</span> ) ).days</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#haswiki</span></span><br><span class="line">    X[i, <span class="number">7</span>] = repo_results[<span class="string">&quot;has_wiki&quot;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#get user information</span></span><br><span class="line">    r = get( results[<span class="string">&quot;owner&quot;</span>][<span class="string">&quot;url&quot;</span>] , auth = auth)</span><br><span class="line">    user_results = loads( r.text )</span><br><span class="line">    X[i, <span class="number">8</span>] = user_results[<span class="string">&quot;following&quot;</span>]</span><br><span class="line">    X[i, <span class="number">9</span>] = user_results[<span class="string">&quot;followers&quot;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#get dep. data</span></span><br><span class="line">    X[i, <span class="number">10</span>] = repo_results[<span class="string">&quot;watchers_count&quot;</span>]</span><br><span class="line">    X[i, <span class="number">11</span>] = repo_results[<span class="string">&quot;forks_count&quot;</span>]</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; -------------- &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(i, <span class="string">&quot;: &quot;</span>, results[<span class="string">&quot;full_name&quot;</span>], repo_results[<span class="string">&quot;language&quot;</span> ], repo_results[<span class="string">&quot;watchers_count&quot;</span>], repo_results[<span class="string">&quot;forks_count&quot;</span>]) </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; -------------- &quot;</span>) </span><br><span class="line">    <span class="built_in">print</span>() </span><br><span class="line">    </span><br><span class="line">np.savetxt(<span class="string">&quot;github_data.csv&quot;</span>, X, delimiter=<span class="string">&quot;,&quot;</span>, fmt=<span class="string">&quot;%d&quot;</span> )</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="even">
<td>-------------- 0 : hbradlow/autograde Python 0 0 --------------</td>
</tr>
<tr class="odd">
<td>-------------- 1 : pkellett/test JavaScript 2 0 --------------</td>
</tr>
<tr class="even">
<td>-------------- 2 : sputnikus/cmdoro Python 0 0 --------------</td>
</tr>
<tr class="odd">
<td>-------------- 3 : theteam/vagrant-django-template Python 36 12
--------------</td>
</tr>
<tr class="even">
<td>-------------- 4 : contra/JMOT Java 17 9 --------------</td>
</tr>
<tr class="odd">
<td>-------------- 5 : jcDesigns99/sample_app Ruby 1 0
--------------</td>
</tr>
<tr class="even">
<td>-------------- 6 : tbarho/base_app Ruby 1 0 --------------</td>
</tr>
<tr class="odd">
<td>-------------- 7 : lvh/txscrypt Python 6 1 --------------</td>
</tr>
<tr class="even">
<td>-------------- 8 : Xand0r/Treebook JavaScript 1 0
--------------</td>
</tr>
<tr class="odd">
<td>-------------- 9 : wingertge/ThumbsApplyGroupManager Java 1 0
--------------</td>
</tr>
<tr class="even">
<td>### 结论</td>
</tr>
<tr class="odd">
<td>虽然大数定律很酷，但只有它的名字暗示它才真实：只有大样本量。我们已经看到了如何通过不考虑<em>数据的形状</em>来影响我们的推理。</td>
</tr>
<tr class="even">
<td>1.
通过（简单的）从后验分布中抽取许多样本，我们可以确保大数定律适用于我们接近期望值（我们将在下一章中进行）。</td>
</tr>
<tr class="odd">
<td>2.
贝叶斯推理理解，对于小样本，我们可以观察到野生随机性。我们的后验分布将通过更广泛而不是紧密集中来反映这一点。因此，我们的推论应该是可纠正的。</td>
</tr>
<tr class="even">
<td>3.
不考虑样本大小有重大影响，尝试对不稳定的对象进行排序会导致病态排序。上面提供的方法解决了这个问题。</td>
</tr>
<tr class="odd">
<td>##### Exercises</td>
</tr>
<tr class="even">
<td>1. How would you estimate the quantity <span
class="math inline">\(E\left[ \cos{X} \right]\)</span>, where <span
class="math inline">\(X \sim \text{Exp}(4)\)</span>? What about <span
class="math inline">\(E\left[ \cos{X} | X \lt 1\right]\)</span>, i.e.
the expected value <em>given</em> we know <span
class="math inline">\(X\)</span> is less than 1? Would you need more
samples than the original samples size to be equally accurate?</td>
</tr>
<tr class="odd">
<td>你如何估计$ E <span class="math inline">\(，其中\)</span> X
（4）<span class="math inline">\(？或者\)</span> E <span
class="math inline">\(，即预期值*给定*我们知道\)</span> X
$小于1？您是否需要比原始样本大小更多的样本才能同样准确？</td>
</tr>
<tr class="even">
<td><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Enter code here</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_probability <span class="keyword">as</span> tfp</span><br><span class="line">tfd = tf.distributions</span><br><span class="line"></span><br><span class="line">reset_sess()</span><br><span class="line"></span><br><span class="line">exp = tfd.Exponential(rate=<span class="number">4.</span>)</span><br><span class="line">N = <span class="number">10000</span></span><br><span class="line">X = exp.sample(sample_shape=<span class="built_in">int</span>(N))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">e_cos_x=evaluate(tf.reduce_sum(tf.math.cos(X)/N))</span><br><span class="line">e_cos_x_le_1=evaluate(tf.reduce_sum(tf.math.cos(X)*tf.cast(X&lt;<span class="number">1</span>,tf.float32)/N))</span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;𝐸[cos𝑋]&#x27;</span>,e_cos_x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;𝐸[cos𝑋|𝑋&lt;1]&#x27;</span>,e_cos_x_le_1)</span><br></pre></td></tr></table></figure></td>
</tr>
<tr class="odd">
<td>𝐸[cos𝑋] 0.9411032 𝐸[cos𝑋|𝑋&lt;1] 0.9354135</td>
</tr>
<tr class="even">
<td>2. The following table was located in the paper "Going for Three:
Predicting the Likelihood of Field Goal Success with Logistic
Regression" [2]. The table ranks football field-goal kickers by their
percent of non-misses. What mistake have the researchers made?</td>
</tr>
</tbody>
</table>
<h4 id="kicker-careers-ranked-by-make-percentage">Kicker Careers Ranked
by Make Percentage</h4>
<table>
<tbody>
<tr>
<th>
Rank
</th>
<th>
Kicker
</th>
<th>
Make %
</th>
<th>
Number of Kicks
</th>
</tr>
<tr>
<td>
1
</td>
<td>
Garrett Hartley
</td>
<td>
87.7
</td>
<td>
57
</td>
</tr>
<tr>
<td>
2
</td>
<td>
Matt Stover
</td>
<td>
86.8
</td>
<td>
335
</td>
</tr>
<tr>
<td>
3
</td>
<td>
Robbie Gould
</td>
<td>
86.2
</td>
<td>
224
</td>
</tr>
<tr>
<td>
4
</td>
<td>
Rob Bironas
</td>
<td>
86.1
</td>
<td>
223
</td>
</tr>
<tr>
<td>
5
</td>
<td>
Shayne Graham
</td>
<td>
85.4
</td>
<td>
254
</td>
</tr>
<tr>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
</td>
</tr>
<tr>
<td>
51
</td>
<td>
Dave Rayner
</td>
<td>
72.2
</td>
<td>
90
</td>
</tr>
<tr>
<td>
52
</td>
<td>
Nick Novak
</td>
<td>
71.9
</td>
<td>
64
</td>
</tr>
<tr>
<td>
53
</td>
<td>
Tim Seder
</td>
<td>
71.0
</td>
<td>
62
</td>
</tr>
<tr>
<td>
54
</td>
<td>
Jose Cortez
</td>
<td>
70.7
</td>
<td>
75
</td>
</tr>
<tr>
<td>
55
</td>
<td>
Wade Richey
</td>
<td>
66.1
</td>
<td>
56
</td>
</tr>
</tbody>
</table>
<p>In August 2013, <a
target="_blank" rel="noopener" href="http://bpodgursky.wordpress.com/2013/08/21/average-income-per-programming-language/">a
popular post</a> on the average income per programmer of different
languages was trending. Here's the summary chart: (reproduced without
permission, cause when you lie with stats, you gunna get the hammer).
What do you notice about the extremes?</p>
<hr />
<h4 id="average-household-income-by-programming-language">Average
household income by programming language</h4>
<table>
<tr>
<td>
Language
</td>
<td>
Average Household Income ($)
</td>
<td>
Data Points
</td>
</tr>
<tr>
<td>
Puppet
</td>
<td>
87,589.29
</td>
<td>
112
</td>
</tr>
<tr>
<td>
Haskell
</td>
<td>
89,973.82
</td>
<td>
191
</td>
</tr>
<tr>
<td>
PHP
</td>
<td>
94,031.19
</td>
<td>
978
</td>
</tr>
<tr>
<td>
CoffeeScript
</td>
<td>
94,890.80
</td>
<td>
435
</td>
</tr>
<tr>
<td>
VimL
</td>
<td>
94,967.11
</td>
<td>
532
</td>
</tr>
<tr>
<td>
Shell
</td>
<td>
96,930.54
</td>
<td>
979
</td>
</tr>
<tr>
<td>
Lua
</td>
<td>
96,930.69
</td>
<td>
101
</td>
</tr>
<tr>
<td>
Erlang
</td>
<td>
97,306.55
</td>
<td>
168
</td>
</tr>
<tr>
<td>
Clojure
</td>
<td>
97,500.00
</td>
<td>
269
</td>
</tr>
<tr>
<td>
Python
</td>
<td>
97,578.87
</td>
<td>
2314
</td>
</tr>
<tr>
<td>
JavaScript
</td>
<td>
97,598.75
</td>
<td>
3443
</td>
</tr>
<tr>
<td>
Emacs Lisp
</td>
<td>
97,774.65
</td>
<td>
355
</td>
</tr>
<tr>
<td>
C#
</td>
<td>
97,823.31
</td>
<td>
665
</td>
</tr>
<tr>
<td>
Ruby
</td>
<td>
98,238.74
</td>
<td>
3242
</td>
</tr>
<tr>
<td>
C++
</td>
<td>
99,147.93
</td>
<td>
845
</td>
</tr>
<tr>
<td>
CSS
</td>
<td>
99,881.40
</td>
<td>
527
</td>
</tr>
<tr>
<td>
Perl
</td>
<td>
100,295.45
</td>
<td>
990
</td>
</tr>
<tr>
<td>
C
</td>
<td>
100,766.51
</td>
<td>
2120
</td>
</tr>
<tr>
<td>
Go
</td>
<td>
101,158.01
</td>
<td>
231
</td>
</tr>
<tr>
<td>
Scala
</td>
<td>
101,460.91
</td>
<td>
243
</td>
</tr>
<tr>
<td>
ColdFusion
</td>
<td>
101,536.70
</td>
<td>
109
</td>
</tr>
<tr>
<td>
Objective-C
</td>
<td>
101,801.60
</td>
<td>
562
</td>
</tr>
<tr>
<td>
Groovy
</td>
<td>
102,650.86
</td>
<td>
116
</td>
</tr>
<tr>
<td>
Java
</td>
<td>
103,179.39
</td>
<td>
1402
</td>
</tr>
<tr>
<td>
XSLT
</td>
<td>
106,199.19
</td>
<td>
123
</td>
</tr>
<tr>
<td>
ActionScript
</td>
<td>
108,119.47
</td>
<td>
113
</td>
</tr>
</table>
<h3 id="references">References</h3>
<ol type="1">
<li>Wainer, Howard. <em>The Most Dangerous Equation</em>. American
Scientist, Volume 95.</li>
<li>Clarck, Torin K., Aaron W. Johnson, and Alexander J. Stimpson.
"Going for Three: Predicting the Likelihood of Field Goal Success with
Logistic Regression." (2013): n. page. <a
target="_blank" rel="noopener" href="http://www.sloansportsconference.com/wp-content/uploads/2013/Going%20for%20Three%20Predicting%20the%20Likelihood%20of%20Field%20Goal%20Success%20with%20Logistic%20Regression.pdf">Web</a>.
20 Feb. 2013.</li>
<li>http://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function</li>
</ol>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" rel="tag">概率论</a></li></ul></div><div class="post-nav"><a class="pre" href="/2019/07/29/vae2/">变分自编码器(VAE) 直观推导</a><a class="next" href="/2019/07/27/tfp-ch3/">概率模型第三章 ： MCMC</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx_en/">Explore AMX instructions: Unlock the performance of Apple Silicon</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/13/macos-bundle/">macos中bundle的使用</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>