<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>变分自编码器(VAE) 直观推导 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="https://unpkg.com/normalize.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/pure-min.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="https://unpkg.com/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="https://unpkg.com/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="https://unpkg.com/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="https://unpkg.com/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="https://unpkg.com/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">变分自编码器(VAE) 直观推导</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">变分自编码器(VAE) 直观推导</h1><div class="post-meta">2019-07-29<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">编码器网络结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E7%BB%93%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">变分自编码器结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97"><span class="toc-number">3.</span> <span class="toc-text">损失函数计算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%9E%84%E6%8D%9F%E5%A4%B1"><span class="toc-number">3.1.</span> <span class="toc-text">重构损失</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kl%E6%8D%9F%E5%A4%B1"><span class="toc-number">3.2.</span> <span class="toc-text">KL损失</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E5%8F%82%E6%95%B0%E6%8A%80%E5%B7%A7"><span class="toc-number">4.</span> <span class="toc-text">重参数技巧</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">5.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">6.</span> <span class="toc-text">结果</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E7%A9%BA%E9%97%B4%E5%9B%BE%E5%83%8F"><span class="toc-number">6.1.</span> <span class="toc-text">隐空间图像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%9E%84%E5%9B%BE%E5%83%8F"><span class="toc-number">6.2.</span> <span class="toc-text">重构图像</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">7.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="post-content"><p>最近一周系统的看下概率论的东西，把公式都看了下，这次重新对<code>VAE</code>做一个直观的推导，我这里就不说<code>VAE</code>为什么要这么做(水平不够)，只说他是怎么做的。</p>
<span id="more"></span>
<h1 id="编码器网络结构">编码器网络结构</h1>
<p>一般的编码器网络，是通过构造隐变量<span
class="math inline">\(z\)</span>，学习从<span
class="math inline">\(x\rightarrow z\)</span>的编码器，以及从<span
class="math inline">\(z\rightarrow
\tilde{x}\)</span>的解码器。但是他们的损失函数只是简单的<span
class="math inline">\((x-\tilde{x})^2\)</span>或者<span
class="math inline">\(p(x)\log
p(\tilde{x})\)</span>，最终缺乏一个生成的效果。</p>
<p><img src="/2019/07/29/vae2/encoder-decoder.png" /></p>
<h1 id="变分自编码器结构">变分自编码器结构</h1>
<p><code>VAE</code>的思想说白了就是为了得到生成的效果，给隐变量<span
class="math inline">\(z\)</span>制造不确定性，然后就使用到了概率论的方案。让<span
class="math inline">\(z\)</span>成为一种概率分布，那么训练完成之后，只要给出不同的<span
class="math inline">\(z\)</span>就可以得到不同的<span
class="math inline">\(\tilde{x}\)</span>，增加了生成性。</p>
<p>下面就是<code>VAE</code>的公式。使用神经网络拟合编码器<span
class="math inline">\(p(z|x)\)</span>和解码器<span
class="math inline">\(p(\tilde{x}|z)\)</span>，用<code>KL散度</code>使隐变量<span
class="math inline">\(z\)</span>的分布接近于标准正态分布，用交叉熵使生成样本相似与原始样本。这里其实很巧妙，如果<span
class="math inline">\(z\)</span>只有均值且为0，那也就是和以前的编码器一样，没有生成效果，但是<span
class="math inline">\(z\)</span>还有方差项，可以提供噪声来保证生成能力。
<span class="math display">\[
\begin{aligned}
    p(z)&amp;=p(z|x)p(x)\ \ \ \  \text{Encoder}\\
    p(\tilde{x})&amp;=p(\tilde{x}|z)p(z) \ \ \ \  \text{Decoder}\\
    \\
    \because \text{要使}\ \ p(z)&amp;\sim N(0,1) \\
    \therefore \mathcal{L}_{kl}&amp;=KL(p(z)\| N(0,1))  \ \ \
\  \text{KL散度}\\
    \\
    \because \text{要使}\ \ p(x)&amp;\approx p(\tilde{x}) \\
    \therefore \mathcal{L}_{re}&amp;= p(x)\log p(\tilde{x}) \ \ \
\  \text{交叉熵} \\
    \\
    \therefore \mathcal{L}&amp;=\mathcal{L}_{kl}+\mathcal{L}_{re}
\end{aligned}
\]</span></p>
<p>下面是示意图： <img src="/2019/07/29/vae2/vae.png" /></p>
<h1 id="损失函数计算">损失函数计算</h1>
<h2 id="重构损失">重构损失</h2>
<p><span
class="math inline">\(\mathcal{L}_{re}\)</span>计算很简单，直接使用<code>tf.nn.sigmoid_cross_entropy_with_logits</code>即可。</p>
<h2 id="kl损失">KL损失</h2>
<p>这个需要好好推导： <span class="math display">\[
\begin{aligned}
    &amp;KL(p({z}|x)\| N(0,1))=\int p({z}|x)\
\log\frac{p({z}|x)}{N(0,1)}\ dz \\
    &amp;=\int p({z}|x)\ \log \frac{\frac{1}{\sqrt{2\pi
\sigma^2}}e^{-\frac{(z-\mu)^2}{2\sigma^2}}}{\frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}}}\
dz \\
    &amp;=\int p({z}|x)\ [\log\frac{1}{\sqrt{\sigma^2}}+\log
e^{\frac{1}{2}(z^2-\frac{(z-\mu)^2}{\sigma^2})}]\ dz\\
    &amp;=\int p({z}|x)\ [-\frac{1}{2}\log
\sigma^2+\frac{1}{2}(z^2-\frac{(z-\mu)^2}{\sigma^2})]\ dz \\
    &amp;=\int p({z}|x)\ [-\frac{1}{2}\log
\sigma^2+\frac{1}{2}(z^2-\frac{(z-\mu)^2}{\sigma^2})]\ dz \\
    &amp;=\frac{1}{2}[-\int p({z}|x)\ \log \sigma^2 \ dz +\int p({z}|x)\
z^2\ dz-\int p({z}|x)\ \frac{(z-\mu)^2}{\sigma^2}\ dz] \\
    &amp;=\frac{1}{2}[-\log\sigma^2+E(z^2)-\frac{D(z)}{\sigma^2}] \\
    &amp;=\frac{1}{2}(-\log\sigma^2+\mu^2+\sigma^2-1)
\end{aligned}
\]</span></p>
<p><strong>注意：</strong> 上面的<span
class="math inline">\(p({z}|x)\)</span>其实就是正态分布的概率，所以<span
class="math inline">\(\int p({z}|x)\ dz=1\)</span>。后面两个就是求<span
class="math inline">\(z^2\)</span>的期望，和<span
class="math inline">\(z\)</span>的方差。</p>
<h1 id="重参数技巧">重参数技巧</h1>
<p>这个其实和算法没多大关系，就是因为随机采样的操作无法求导，只能对采样出来的值求导。所以就使用如下技巧：</p>
<p>从<span class="math inline">\(N(\mu,\sigma^2)\)</span>中采样一个<span
class="math inline">\(z\)</span>，相当于从<span
class="math inline">\(N(0,1)\)</span>中采样一个<span
class="math inline">\(\epsilon\)</span>，然后让<span
class="math inline">\(z=\mu+\epsilon\times\sigma\)</span>。</p>
<p>这样就可以直接对值求导即可,概念图如下</p>
<p><img src="/2019/07/29/vae2/reparam.png" /></p>
<h1 id="代码">代码</h1>
<p>代码运行环境为<code>Tensorflow 1.14</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.python <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python <span class="keyword">import</span> keras <span class="keyword">as</span> k</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras <span class="keyword">import</span> layers <span class="keyword">as</span> kl</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras <span class="keyword">import</span> activations <span class="keyword">as</span> ka</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"></span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">k.backend.set_session(tf.Session(config=config))</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = k.datasets.fashion_mnist.load_data()</span><br><span class="line">x_train = np.expand_dims(x_train, -<span class="number">1</span>) / <span class="number">255.</span></span><br><span class="line">x_test = np.expand_dims(x_test, -<span class="number">1</span>) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">image_size = <span class="number">28</span></span><br><span class="line">input_shape = (image_size, image_size, <span class="number">1</span>)</span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">filters = <span class="number">16</span></span><br><span class="line">latent_dim = <span class="number">2</span>  <span class="comment"># 隐变量取2维只是为了方便后面画图</span></span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line">tf.set_random_seed(<span class="number">9102</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encoder_fn</span>(<span class="params">inputs, filters</span>):</span><br><span class="line">    x = inputs</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        filters *= <span class="number">2</span></span><br><span class="line">        x = kl.Conv2D(filters=filters, kernel_size=kernel_size, activation=<span class="string">&#x27;relu&#x27;</span>, strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = kl.Flatten()(x)</span><br><span class="line">    x = kl.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    μ = kl.Dense(latent_dim)(x)</span><br><span class="line">    σ = kl.Dense(latent_dim)(x)</span><br><span class="line">    <span class="keyword">return</span> μ, σ</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sampling</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 重参数技巧 &quot;&quot;&quot;</span></span><br><span class="line">    μ, σ = args</span><br><span class="line">    ε = tf.random_normal(shape=tf.shape(μ))</span><br><span class="line">    <span class="keyword">return</span> μ + tf.exp(σ / <span class="number">2</span>) * ε</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decoder_fn</span>(<span class="params">z, filters</span>):</span><br><span class="line">    x = kl.Dense(<span class="number">7</span> * <span class="number">7</span> * <span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(z)</span><br><span class="line">    x = kl.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">32</span>))(x)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = kl.Conv2DTranspose(filters=filters, kernel_size=kernel_size, activation=<span class="string">&#x27;relu&#x27;</span>, strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">        filters //= <span class="number">2</span></span><br><span class="line">    x = kl.Conv2DTranspose(<span class="number">1</span>, kernel_size, activation=<span class="literal">None</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_fn</span>(<span class="params">inputs, outputs, μ, σ</span>):</span><br><span class="line">    <span class="comment"># 这里求和的时候先按每个样本求和，再按样本求平均</span></span><br><span class="line">    xent_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=x_in, logits=x_out), axis=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    <span class="comment"># xent_loss = tf.reduce_sum(k.backend.binary_crossentropy(x_in, x_out), axis=[1, 2, 3])</span></span><br><span class="line">    kl_loss = - <span class="number">0.5</span> * tf.reduce_sum(<span class="number">1</span> + σ - tf.square(μ) - tf.exp(σ), axis=-<span class="number">1</span>)</span><br><span class="line">    vae_loss = tf.reduce_mean(xent_loss + kl_loss)</span><br><span class="line">    <span class="keyword">return</span> vae_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_in = k.Input(shape=(image_size, image_size, <span class="number">1</span>))</span><br><span class="line">μ, σ = encoder_fn(x_in, filters)</span><br><span class="line">z = kl.Lambda(sampling, output_shape=(latent_dim,))([μ, σ])</span><br><span class="line"></span><br><span class="line">latent_inputs = k.Input(shape=(latent_dim,), dtype=tf.float32)</span><br><span class="line">outputs = decoder_fn(latent_inputs, filters)</span><br><span class="line">decoder = k.Model(latent_inputs, outputs)</span><br><span class="line">x_out = decoder(z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">encoder = k.Model(x_in, μ)</span><br><span class="line"></span><br><span class="line">vae = k.Model(x_in, x_out)</span><br><span class="line">vae.add_loss(loss_fn(x_in, x_out, μ, σ))</span><br><span class="line">vae.<span class="built_in">compile</span>(k.optimizers.Nadam(<span class="number">0.001</span>))</span><br><span class="line">vae.fit(x=x_train, batch_size=batch_size, epochs=epochs, shuffle=<span class="literal">True</span>, validation_data=(x_test, <span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_test_encoded = encoder.predict(x_test, batch_size=batch_size)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">plt.scatter(x_test_encoded[:, <span class="number">0</span>], x_test_encoded[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察隐变量的两个维度变化是如何影响输出结果的</span></span><br><span class="line">n = <span class="number">15</span>  <span class="comment"># figure with 15x15 digits</span></span><br><span class="line">figure = np.zeros((image_size * n, image_size * n))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用正态分布的分位数来构建隐变量对</span></span><br><span class="line">grid_x = norm.ppf(np.linspace(<span class="number">0.05</span>, <span class="number">0.95</span>, n))</span><br><span class="line">grid_y = norm.ppf(np.linspace(<span class="number">0.05</span>, <span class="number">0.95</span>, n))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, yi <span class="keyword">in</span> <span class="built_in">enumerate</span>(grid_x):</span><br><span class="line">    <span class="keyword">for</span> j, xi <span class="keyword">in</span> <span class="built_in">enumerate</span>(grid_y):</span><br><span class="line">        z_sample = np.array([[xi, yi]])</span><br><span class="line">        x_decoded = expit(decoder.predict(z_sample))</span><br><span class="line">        digit = x_decoded[<span class="number">0</span>].reshape(image_size, image_size)</span><br><span class="line">        figure[i * image_size: (i + <span class="number">1</span>) * image_size,</span><br><span class="line">               j * image_size: (j + <span class="number">1</span>) * image_size] = digit</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.imshow(figure, cmap=<span class="string">&#x27;Greys_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="结果">结果</h1>
<h2 id="隐空间图像">隐空间图像</h2>
<p><img src="/2019/07/29/vae2/laten_space.png" /></p>
<h2 id="重构图像">重构图像</h2>
<p><img src="/2019/07/29/vae2/restruct.png" /></p>
<h1 id="参考">参考</h1>
<p><a
target="_blank" rel="noopener" href="https://kexue.fm/archives/5343">变分自编码器（二）：从贝叶斯观点出发</a></p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" rel="tag">概率论</a></li></ul></div><div class="post-nav"><a class="pre" href="/2019/07/30/rasp-config/">树莓派修改配置使能串口登陆</a><a class="next" href="/2019/07/28/tfp-ch4/">概率模型第四章 ： 大数定理</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a> <a href="/tags/%E7%AE%97%E5%AD%90/" style="font-size: 15px;">算子</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/09/26/flashattn/">Flash Attention记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/08/28/chimera/">Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>