<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Tiramisu Compiler Internals | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="https://unpkg.com/normalize.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/pure-min.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="https://unpkg.com/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="https://unpkg.com/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="https://unpkg.com/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="https://unpkg.com/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="https://unpkg.com/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Tiramisu Compiler Internals</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Tiramisu Compiler Internals</h1><div class="post-meta">2023-09-06<span> | </span><span class="category"><a href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 8.8k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 40</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">概览</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#tiramisu-schedule-commands"><span class="toc-number">1.1.</span> <span class="toc-text">Tiramisu Schedule Commands</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tiramisu-multi-layer-ir"><span class="toc-number">1.2.</span> <span class="toc-text">Tiramisu Multi-Layer IR</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-number">2.</span> <span class="toc-text">实现细节</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">2.1.</span> <span class="toc-text">数据结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E9%83%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">内部执行流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5"><span class="toc-number">2.2.1.</span> <span class="toc-text">1. 定义输入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E8%AE%A1%E7%AE%97"><span class="toc-number">2.2.2.</span> <span class="toc-text">2. 定义计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">2.2.3.</span> <span class="toc-text">3. 调度计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90"><span class="toc-number">2.2.4.</span> <span class="toc-text">4. 代码生成</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="post-content"><p><a target="_blank" rel="noopener" href="http://tiramisu-compiler.org">Tiramisu</a>
是一个基于polyhedral的DL compiler,
通过探索他的实现细节来学习如何利用polyhedral
compilation并整合到他的dsl中的.</p>
<span id="more"></span>
<h1 id="概览">概览</h1>
<p>Tiramisu compiler的创新点如下： 1. 引入polyhedral
compiler,可以控制数据通信,同步,内存级别映射. 2.
将IR分离为四个层级,简化调度语言,增加了对于不同架构的调用可移植性 3.
支持rnn等算子优化,支持多核系统优化,同时优化后性能基本不弱于纯手写</p>
<p>以下是他和其他几个编译器的对比,其中halide是基于表达式进行推导的,好处是支持参数化的tiling,缺点是分析难写,无法支持非常灵活的调度.而Tiramisu则是基于polyhedral,除了不支持参数化tiling其他功能都可以利用polyhedral提供的强大分析来完成.</p>
<table>
<colgroup>
<col style="width: 54%" />
<col style="width: 11%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 7%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Tiramisu</th>
<th>AlphaZ</th>
<th>PENCIL</th>
<th>Pluto</th>
<th>Halide</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CPU code generation</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>GPU code generation</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Distributed CPU code generation</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Distributed GPU code generation</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Support all affine loop transformations</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td>Commands for loop transformations</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Commands for optimizing data accesses</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Commands for communication</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Commands for memory hierarchies</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Limited</td>
</tr>
<tr class="even">
<td>Expressing cyclic data-flow graphs</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Non-rectangular iteration spaces</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Limited</td>
</tr>
<tr class="even">
<td>Exact dependence analysis</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Compile-time set emptiness check</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td>Implement parametric tiling</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p>我在<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/585176512">带宽受限下的DSA后端优化</a>中就是实现了一套参数化tiling的机制来进行自动fusion和tiling.</p>
<h2 id="tiramisu-schedule-commands">Tiramisu Schedule Commands</h2>
<p>假设C和P为computation,b为buffer,i/j为迭代变量.来说明一些调度命令：</p>
<ol type="1">
<li>循环变化</li>
</ol>
<table>
<colgroup>
<col style="width: 30%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="header">
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C.tile(i,j,t1,t2, i0,j0,i1,j1)</td>
<td>使用t1 × t2来tile C的循环 (i, j)
,其中i0为最外层循环,j1为最内侧循环</td>
</tr>
<tr class="even">
<td>C.interchange(i, j)</td>
<td>交换C的循环 i ,j</td>
</tr>
<tr class="odd">
<td>C.shift(i, s)</td>
<td>偏移循环i ｜</td>
</tr>
<tr class="even">
<td>C.split(i, s, i0, i1)</td>
<td>循环分块</td>
</tr>
<tr class="odd">
<td>P.compute_at(C, j)</td>
<td>定义计算发生的位置,不合理的调度可能会引起冗余计算.</td>
</tr>
<tr class="even">
<td>C.unroll(i, v)</td>
<td>根据参数v展开循环i</td>
</tr>
<tr class="odd">
<td>C.after(B, i)</td>
<td>指定循环i中C发生在B之后</td>
</tr>
<tr class="even">
<td>C.inline()</td>
<td>inline C到他所有的消费者处</td>
</tr>
<tr class="odd">
<td>C.set_schedule()</td>
<td>直接通过isl语法指定C的 affine 关系（可以表示layer I和II）</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li>硬件映射</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C.parallelize(i)</td>
<td>在共享内存的系统中并行化执行循环i</td>
</tr>
<tr class="even">
<td>C.vectorize(i, v)</td>
<td>通过vector size v向量化循环i</td>
</tr>
<tr class="odd">
<td>C.gpu(i0, i1, i2, i3)</td>
<td>标记循环i0, i1, i2, i3 在GPU上执行</td>
</tr>
<tr class="even">
<td>C.tile_gpu(i0,i1,t1,t2)</td>
<td>Tile 循环 i0 and i1 并映射到 GPU.</td>
</tr>
<tr class="odd">
<td>C.distribute(i)</td>
<td>在分布式内存系统上并行话循环i.</td>
</tr>
</tbody>
</table>
<ol start="3" type="1">
<li>高层数据操作</li>
</ol>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="header">
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C.store_in(b,{i, j})</td>
<td>将computation C(i,j) 输出存在buffer b[i,j].</td>
</tr>
<tr class="even">
<td>C.cache_shared_at(P,i)</td>
<td>Cache (copy) C 的buffer 到 shared memory. 从 global 到 shared GPU
memory会发生在循环i的P操作中, 这个过程中的数据访问和同步会自动完成.</td>
</tr>
<tr class="odd">
<td>C.cache_local_at(P, i)</td>
<td>类似上一个但是存储在 local GPU memory.</td>
</tr>
<tr class="even">
<td>send(d, src, s, q, p)</td>
<td>构造send操作. d: 迭代位置向量; src: 源buffer; s: size; q: 目标节点;
p: 属性 (synchronous, asynchronous, blocking, ...).</td>
</tr>
<tr class="odd">
<td>receive(d,dst,s,q,p)</td>
<td>构造receive操作.</td>
</tr>
</tbody>
</table>
<ol start="4" type="1">
<li>底层数据操作</li>
</ol>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 76%" />
</colgroup>
<thead>
<tr class="header">
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Buffer b(sizes, type)</td>
<td>声明 buffer (sizes: buffer维度).</td>
</tr>
<tr class="even">
<td>b.allocate_at(p, i)</td>
<td>在循环i的计算P处添加allocate操作</td>
</tr>
<tr class="odd">
<td>C.buffer()</td>
<td>返回 C所关联的buffer.</td>
</tr>
<tr class="even">
<td>b.set_size(sizes)</td>
<td>设定buffer的维度</td>
</tr>
<tr class="odd">
<td>b.tag_gpu_global()</td>
<td>设定buffer位于global GPU memory.</td>
</tr>
<tr class="even">
<td>b.tag_gpu_shared()</td>
<td>设定buffer位于shared GPU memory.</td>
</tr>
<tr class="odd">
<td>b.tag_gpu_local()</td>
<td>设定buffer位于local GPU memory.</td>
</tr>
<tr class="even">
<td>b.tag_gpu_constant()</td>
<td>设定buffer位于constant GPU memory.</td>
</tr>
<tr class="odd">
<td>C.host_to_device()</td>
<td>copy C.buffer() 从 host 到 device.</td>
</tr>
<tr class="even">
<td>C.device_to_host()</td>
<td>copy C.buffer() 从 device 到 host.</td>
</tr>
<tr class="odd">
<td>copy_at(p, i, bs, bd)</td>
<td>在循环i的操作P中copy bs 到 bd .可以在 global, shared and
local中进行.</td>
</tr>
</tbody>
</table>
<ol start="5" type="1">
<li>同步操作</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>barrier_at(p,i)</td>
<td>在循环i的操作p处构造屏障</td>
</tr>
</tbody>
</table>
<h2 id="tiramisu-multi-layer-ir">Tiramisu Multi-Layer IR</h2>
<p>当前大多数IR都使用内存在程序语句之间进行通信.
这会在程序中创建基于内存的依赖关系,并迫使编译器在决定优化并映射到硬件之前选择数据布局.
为不同的硬件体系结构优化程序通常需要修改数据布局并消除基于内存的依赖关系,因为它们限制了优化.
因此,必须撤消在调度之前指定的任何数据布局,以允许更多的调度自由度,并且必须调整代码以使用最适合目标硬件的数据列表.
应用这些数据变换并消除基于内存的依赖性很具有挑战性.</p>
<p>举个例子, 将buffer传输到GPU上的shared和local memory. 需要复制到shared
memory以及何时执行同步的数据量都取决于代码的优化方式(例如,
代码是否具有两级tile).
同样的适用于决定生成分布式代码时要发送或接收的数据量. 因此,
buffer传输到内存层次结构以及通信管理和同步不应在调度之前决定.</p>
<p>Tiramisu通过使用架构无关算法、循环变换、数据布局、通信等完全分开的多层IR来解决代码生成中的这些复杂问题.
1. 第一层表示使用无存储位置的生产者-消费者关系描述了纯算法. 2.
第二层指定计算顺序, 以及处理器计算每个值的计算顺序,
该层适合执行大量优化, 而无需处理具体的内存布局. 3.
第三层指定在消耗中间数据之前存储中间数据的位置. 4.
第四层添加了所有必要的通信和同步操作.</p>
<p>分层的设计决定了应用优化的特定顺序,
并确保编译器在给定层中通过不必担心修改或撤消早期层中做出的决策. 例如,
指定计算顺序及其发生的阶段可以安全地假设不需要数据划分转换.
这个简单的假设使Tiramisu无需考虑调度是否会影响数据布局.</p>
<figure>
<img src="/2023/09/06/tiramisu/overview.png" alt="Overview" />
<figcaption aria-hidden="true">Overview</figcaption>
</figure>
<p>通过下面一段简单的例子来说明每层IR内部的表示形式:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tiramisu <span class="keyword">as</span> tm</span><br><span class="line">tm.init(<span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span></span><br><span class="line">M = <span class="number">200</span></span><br><span class="line">C = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = tm.<span class="built_in">input</span>(<span class="string">&quot;input&quot;</span>, [<span class="string">&quot;i&quot;</span>, <span class="string">&quot;j&quot;</span>, <span class="string">&quot;c&quot;</span>], [N, M, C], tm.primitive_t.p_float32)</span><br><span class="line"></span><br><span class="line">i, j, c = tm.var(<span class="string">&quot;i&quot;</span>, <span class="number">0</span>, N - <span class="number">2</span>), tm.var(<span class="string">&#x27;j&#x27;</span>, <span class="number">0</span>, M - <span class="number">2</span>), tm.var(<span class="string">&#x27;c&#x27;</span>, <span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">d = tm.expr(<span class="number">3</span>).cast(tm.primitive_t.p_float32)</span><br><span class="line">bx = tm.computation(<span class="string">&#x27;bx&#x27;</span>, [i, j, c], (<span class="built_in">input</span>[i, j, c] + <span class="built_in">input</span>[i, j + <span class="number">1</span>, c] + <span class="built_in">input</span>[i, j + <span class="number">2</span>, c]) / d)</span><br><span class="line">by = tm.computation(<span class="string">&#x27;by&#x27;</span>, [i, j, c], (bx[i, j, c] + bx[i + <span class="number">1</span>, j, c] + bx[i + <span class="number">2</span>, j, c]) / d)</span><br></pre></td></tr></table></figure>
<p>tiramisu内部使用presubger set来表示.</p>
<ol type="1">
<li>第一层: 算法抽象</li>
</ol>
<p>直接通过简单的表达式之间的生产消费关系来定义,比如by的表示为:</p>
<p><span class="math display">\[
\begin{align}
{by(i, j, c) : 0 ≤ i &lt; N − 2 ∧ 0 ≤ j &lt; M − 2 ∧ 0 ≤ c &lt; 3} : \\
(bx(i, j, c) + bx(i + 1, j, c) + bx(i + 2, j, c))/3
\end{align}
\]</span></p>
<p>其中第一部分指定计算的迭代域,第二部分为计算的表达式.
第一部分声明了i,j,c的循环顺序,但是循环的执行顺序却并没有指定.</p>
<ol start="2" type="1">
<li>第二层: 计算管理</li>
</ol>
<p>定义计算的顺序以及处理器编号等. 这里不指定中间变量如何存储在内存中,
这样执行优化操作的就不需要考虑如何去修改内存布局.
从第一层转到第二层只需要使用调度指令即可: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">by.gpu_tile(i, j, <span class="number">32</span>, <span class="number">32</span>, i0, j0, i1, j1)</span><br><span class="line">bx.compute_at(by, j0)</span><br><span class="line">bx.cache_shared(by, j0)</span><br></pre></td></tr></table></figure>
调度后内部的IR表示如下: <span class="math display">\[
\begin{align}
{ by(1, i0(gpuB), j0(gpuB), i1(gpuT ), j1(gpuT), c) : \\
i0 = floor(i/32)∧j0 = floor(j/32)∧i1 = i\%32∧j1 = j\%32∧0 ≤ i &lt; N
−2∧0 ≤ j &lt; M −2∧0 ≤ c &lt; 3} : \\
(bx(i0*32+i1,j0*32+j1,c)+ bx(i0*32+i1+1, j0*32+j1, c)+bx(i0*32+i1+2,
j0*32+j1, c))/3
\end{align}
\]</span></p>
<p>此时这一层中的Computations被排序以及分配到特定的处理器.
排序可以被分为时间维度和空间维度,
其中时间维度指的是当前计算相对于其他计算的执行顺序,是通过一个词典序的set来表示的;
空间维度指的是计算发生在哪一个处理器,
同时处理器位置则是通过tag表示(目前支持cpu,node,gpuB,gpuT).</p>
<ol start="3" type="1">
<li>第三层: 数据管理</li>
</ol>
<p>这一层通过指定中间变量如何存储来确定数据布局.
任何必要的buffer分配和释放都在这个级别构造,
转换到本层也是通过使用数据调度命令自动转换,
本层还可以指定数据存储的内存层级位置.</p>
<p>本层表示由第二层的IR组成, 添加buffer申请/释放语句,
以及对数组读写的access relation(其中标量也被看作单元素数组).
对于每个buffer,需要指定他们申请的大小和类型.</p>
<p>有时候数据映射可以很复杂,比如存储的时候减少循环的维度,或者可以展平,
这个时候我们也只需要提供复杂的映射函数即可, 比如将计算c(i,
j)映射到c(i%2, j%2)或者c(j, i)上.</p>
<p>比如指定bx,by的数据布局:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.store_in(&#123;c, i, j&#125;)</span><br><span class="line">by.store_in(&#123;c, i, j&#125;)</span><br></pre></td></tr></table></figure>
<p>可以得到如下的affine relation表示:</p>
<p><span class="math display">\[
\begin{align}
  {by(1, i0(gpuB), j0(gpuB), i1(gpuT ), j1(gpuT ), c) \rightarrow by[c,
i0 * 32 + i1,j0*32+j1] :\\
   i0 = floor(i/32)∧j0 = floor(j/32)∧i1 = i\%32∧j1 = j\%32 ∧ 0 ≤ i &lt;
N − 2 ∧ 0 ≤ j &lt; M − 2 ∧ 0 ≤ c &lt; 3}
\end{align}
\]</span></p>
<ol start="4" type="1">
<li>第四层: 通信管理</li>
</ol>
<p>这一层添加同步/通信操作到IR中, 并将这些操作映射到时间顺序维度,
并且在buffer分配和释放的时候实例化.
这一层也是通过调度命令来进行转换的.</p>
<h1 id="实现细节">实现细节</h1>
<p>tiramisu的具体实现大体是依照上述框架,
但是还是有需要细节值得好好学习.</p>
<h2 id="数据结构">数据结构</h2>
<p>expr的数据结构和halide类似, 主要用于表示每个statement中的运算表达式.
可以用于表示常量, 变量, 通信/运算/调用操作.</p>
<p><img src="/2023/09/06/tiramisu/datastructure.png" /></p>
<h2 id="内部执行流程">内部执行流程</h2>
<h3 id="定义输入">1. 定义输入</h3>
<p>下面就通过python执行和内部的log进行分析. 首先我们定义一个input:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N = <span class="number">100</span></span><br><span class="line">M = <span class="number">200</span></span><br><span class="line">C = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = tm.<span class="built_in">input</span>(<span class="string">&quot;input&quot;</span>, [<span class="string">&quot;i&quot;</span>, <span class="string">&quot;j&quot;</span>, <span class="string">&quot;c&quot;</span>], [N, M, C], tm.primitive_t.p_float32)</span><br></pre></td></tr></table></figure>
<p>在上面一节的数据结构定义input是继承自computation,
因此所调用的构造函数还是computation.
给到computation的迭代变量即为自动构造的<code>i,j,c</code>,
将三个迭代变量构造出对应的迭代域<code>&#123;input[i, j, c] : 0&lt;=i&lt;100 and 0&lt;=j&lt;200 and 0&lt;=c&lt;3&#125;</code>.</p>
<p>然后有一个<code>gen_identity_schedule_for_iteration_domain</code>将原始的迭代域进行扩展为<code>&#123; input[i, j, c] -&gt; input[0, 0, i' = i, 0, j' = j, 0, c' = c, 0] : 0 &lt;= i &lt;= 99 and 0 &lt;= j &lt;= 199 and 0 &lt;= c &lt;= 2 &#125;</code>的形式,
并赋值到computation的schedule.</p>
<p>其实就是<code>2d+1</code>的执行顺序表示, 其中对应关系如下:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">* Loop level               :    -1         0      1      2</span><br><span class="line">* Schedule dimension number:        0, 1   2  3   4  5   6  7</span><br><span class="line">* Schedule:                        [0, 0, i1, 0, i2, 0, i3, 0]</span><br></pre></td></tr></table></figure></p>
<p>而后设定当前computation的表达式, 因为是输入, 因此表达式为空.</p>
<p>接下来再构造出unique的名字代替原来的变量名,
以避免用户起的变量名出现冲突的情况,
然后修改schedule的维度名字为:<code>&#123; input[t1, t2, t3] -&gt; input[0, 0, i = t1, 0, j = t2, 0, c = t3, 0] : 0 &lt;= t1 &lt;= 99 and 0 &lt;= t2 &lt;= 199 and 0 &lt;= t3 &lt;= 2 &#125;</code></p>
<p>最后是检测到当前 computation具备有效的边界值,
自动构造了buffer,并将当前computation<code>store_in</code>到这个buffer中.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-input-cpp">input
log</a></p>
<h3 id="定义计算">2. 定义计算</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i, j, c = tm.var(<span class="string">&quot;i&quot;</span>, <span class="number">0</span>, N - <span class="number">2</span>), tm.var(<span class="string">&#x27;j&#x27;</span>, <span class="number">0</span>, M - <span class="number">2</span>), tm.var(<span class="string">&#x27;c&#x27;</span>, <span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">d = tm.expr(<span class="number">3</span>).cast(tm.primitive_t.p_float32)</span><br><span class="line">bx = tm.computation(<span class="string">&#x27;bx&#x27;</span>, [i, j, c], (<span class="built_in">input</span>[i, j, c] + <span class="built_in">input</span>[i, j + <span class="number">1</span>, c] + <span class="built_in">input</span>[i, j + <span class="number">2</span>, c]) / d)</span><br><span class="line">by = tm.computation(<span class="string">&#x27;by&#x27;</span>, [i, j, c], (bx[i, j, c] + bx[i + <span class="number">1</span>, j, c] + bx[i + <span class="number">2</span>, j, c]) / d)]</span><br></pre></td></tr></table></figure>
<p>定义bx和by也是类似同上的逻辑, 不过这里因为存在了表达式,
所以多了一步递归的将表达式转换为非仿射的访问关系.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-computation-cpp">computation
log</a></p>
<h3 id="调度计算">3. 调度计算</h3>
<p>tiramisu的调度都被记录在function中,
function更像是所有computation的聚合. 与halide不同,
这里一份代码中只有一个全局function, 许多调度默认操作这个全局变量.</p>
<p><img src="/2023/09/06/tiramisu/schstructure.png" /></p>
<p>接下来我们看一下function是如何记录调度操作:</p>
<ol type="1">
<li>after</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.after(by, j)</span><br></pre></td></tr></table></figure>
<p>首先是找到迭代变量<code>j</code>所对应的循环层级为1,
然后在sched_graph添加by指向bx的连接, 同时将循环层级设置为1.
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">[src/tiramisu_core.cpp:<span class="number">2354</span> after]</span><br><span class="line">|   [src/tiramisu_core.cpp:<span class="number">2728</span> get_loop_level_numbers_from_dimension_names]</span><br><span class="line">|   |   Searching <span class="keyword">for</span> the dimension j</span><br><span class="line">|   |   Searching in the range of  &#123; bx[t5, t6, t7] -&gt; bx[<span class="number">0</span>, <span class="number">0</span>, i = t5, <span class="number">0</span>, j = t6, <span class="number">0</span>, c = t7, <span class="number">0</span>] : <span class="number">0</span> &lt;= t5 &lt;= <span class="number">97</span> <span class="keyword">and</span> <span class="number">0</span> &lt;= t6 &lt;= <span class="number">197</span> <span class="keyword">and</span> <span class="number">0</span> &lt;= t7 &lt;= <span class="number">2</span> &#125;</span><br><span class="line">|   |   Corresponding loop level is <span class="number">1</span></span><br><span class="line">|   |   Checking the validity of loop level <span class="number">1</span></span><br><span class="line">|   The loop level that corresponds to j is <span class="number">1</span></span><br><span class="line">|   [src/tiramisu_core.cpp:<span class="number">2374</span> after]</span><br><span class="line">|   |   Scheduling bx to be executed after by at level <span class="number">1</span></span><br><span class="line">|   |   sched_graph[by, bx] = <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li>interchange</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.interchange(i, j)</span><br></pre></td></tr></table></figure>
<p>交互循环, 对于基于isl的ir来说非常简单.
首先获取两个迭代变量所对应的循环层级,然后构造一个<code>transformation map</code>,
然后对computation的schedule进行apply range即可完成变换.
具体的细节如下:</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-interchange-cpp">interchange
log</a></p>
<ol start="3" type="1">
<li>shift</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.shift(i, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>同样也是找到对应的循环维度然后对实施变换即可.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-shift-cpp">shift
log</a></p>
<ol start="4" type="1">
<li>split</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i0,  i1 = tm.var(tm.primitive_t.p_int32, <span class="string">&quot;i0&quot;</span>), tm.var(tm.primitive_t.p_int32, <span class="string">&quot;i1&quot;</span>)</span><br><span class="line">bx.split(i, <span class="number">16</span>, i0, i1)</span><br></pre></td></tr></table></figure>
<p>获取循环维度后同样构造Transformation map,
首先是通过当前参数构造Origin Transformation
map的字符串<code>&#123;bx[t15,t16,t17,t18,t19,t20,t21,t22] -&gt; bx[t15,t16,t12, t13, t14,t18,t19,t20,t21,t22] : t15 = 0 and t12 = floor(t17/16) and t14 = (t17%16) and t13 = 0&#125;</code>,
然后使用isl自动构造出优化后的Transformation map
:<code>&#123; bx[t15 = 0, t16, t17, t18, t19, t20, t21, t22] -&gt; bx[t15' = 0, t16' = t16, t12, t13 = 0, t14, t18' = t18, t19' = t19, t20' = t20, t21' = t21, t22' = t22] : (-t17 + t14) mod 16 = 0 and -15 + t17 &lt;= 16t12 &lt;= t17 and 0 &lt;= t14 &lt;= 15 &#125;</code>,
再应用变换到schedule, 最后再把变换后的schedule中维度的名字进行修改.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-split-cpp">split
log</a></p>
<ol start="5" type="1">
<li>unroll/vectorize/parallelize/distribute</li>
</ol>
<p>作者为了通用化起见,其实这这些调度都走了同一的逻辑,
都是按一定约束系数分离出原始的计算,然后把循环变量保存到对应的列表中.
这里就以<code>unroll</code>为例子(按作者的代码实现看,他在论文中应该把unroll的调度放到IR的第二层才对):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.unroll(c, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>首先拿到循环维度,
然后通过<code>separateAndSplit</code>函数检查当前unroll的大小是否可以保证被split.
如果可以被split, 循环维度将扩展两个, 否则只扩展一个.
在<code>separateAndSplit</code>函数中, 生成time_space_domain,
也就是获得实际执行的order, 然后获取maximal_AST_depth为后续使用.
再收集当前循环维度的上下界, 这里收集到的上下界分别是2和0,
总次数即(2-0+1). 接下来就可以调用<code>separate</code>函数,
将原始的computation分离两部分,
一部分是<code>i &lt; v * floor(loop_bound/v)</code>另一部分为<code>i &gt;= v * floor(loop_bound/v)</code>,
称前面部分为<code>full computation</code>后面为<code>separated computation</code>.
在这个例子中,<code>separated computation</code>为空,
因此并不会添加新的computation,
但是之前所构造的约束还是要通过<code>add_schedule_constraint</code>函数添加到原始的computation中.
后续的的<code>split_with_lower_bound</code>也因为没有分离所以并没有实际的操作.</p>
<p>中间有一步<code>tag_unroll_level</code>就是将当前循环变量保存到对应的列表中,
同样<code>vectorize/parallelize/distribute</code>则是保存到不同的列表中.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-unroll-cpp">unroll
log</a></p>
<ol start="6" type="1">
<li>gpu_tile</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i0, j0, i1, j1 = tm.var(tm.primitive_t.p_int32, <span class="string">&quot;i0&quot;</span>), tm.var(tm.primitive_t.p_int32, <span class="string">&quot;j0&quot;</span>), tm.var(</span><br><span class="line">    tm.primitive_t.p_int32, <span class="string">&quot;i1&quot;</span>), tm.var(tm.primitive_t.p_int32, <span class="string">&quot;j1&quot;</span>)</span><br><span class="line">by.gpu_tile(i, j, <span class="number">32</span>, <span class="number">32</span>, i0, j0, i1, j1)</span><br></pre></td></tr></table></figure>
<p>看代码实现上, 其实gpu tile就是调用两次split并交换循环维度,
然后将循环维度分别映射到block/thread上,
我理解这个scheudle应该也是可以放到IR的第一层中.</p>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-gpu_tile-cpp">gpu_tile
log</a></p>
<ol start="7" type="1">
<li>compute_at</li>
</ol>
<p>这个调度我是在gpu tile之后继续进行的, 因为在不同的循环层级去计算,
需要考虑数据依赖等问题, 所以这个调度实现就比较复杂. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bx.compute_at(by, j0)</span><br></pre></td></tr></table></figure></p>
<p>compute_at函数假设by作为消费者消费由bx(生产者)产生的值.
根据消费者的每个唯一值按需计算此computation,
此时by消费的值在bx中的循环维度计算, 并与消费者处于同一循环嵌套中.
如果消费者by需要冗余计算,
则调度会创建必要的冗余计算并在消费者之前对其进行调度.</p>
<p>此函数会执行: - 按需在消费者之前调度此计算的执行 -
如果需要冗余计算此计算,则创建冗余计算</p>
<p>此函数不执行: - 不为此计算创建任何数据映射.
用户需要为此计算提供访问关系, 就像对任何其他正常计算所做的那样. -
不为此计算分配任何缓冲区. 用户需要声明一个缓冲区以存储此计算的结果.</p>
<p>如果此函数创建了计算的副本,则用户不需要设置其访问关系,
复制的计算将自动具有与原始计算相同的访问关系.此函数不返回用于操作副本计算的句柄,
它不允许用户自由操作副本. 副本将自动安排在消费者之前执行.</p>
<p>下面开始正式的调度流程:</p>
<ol type="1">
<li>通过compute_needed_and_produced计算producer(即this)和consumer之间的needed关系,也就是consumer需要读取producer的哪些数据
<ol type="1">
<li>获取producer_domain,
producer_sched以及consumer_domain,consumer_sched</li>
<li>根据consumer的expression得到对于producer的访问关系consumer_accesses,
并过滤其中无效的部分得到
<code>&#123; by[i, j, c] -&gt; bx[i', j' = j, c' = c] : i &gt;= 0 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 and i &lt;= i' &lt;= 97 and i' &lt;= 2 + i &#125;</code></li>
<li>获取producer_domain,consumer_domain到time-processor上,
也就是apply对应的sched.</li>
<li>将consumer_accesses也转换到time-processor上,
也就是对consumer_accesses的domain应用producer_sched,
他的range应用consumer_sched</li>
<li>对齐上述集合和关系的维度</li>
<li>在consumer_domain上应用consumer_accesses, 得到needed,
即为consumer需要读取的producer的数据集合:
<code>[t40, t41] -&gt; &#123; bx[0, 0, i, 0, j, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : t40 &gt;= 0 and 32t40 &lt;= i &lt;= 97 and i &lt;= 33 + 32t40 and j &gt;= 32t41 and 0 &lt;= j &lt;= 197 and j &lt;= 31 + 32t41 and 0 &lt;= c &lt;= 2 and -32 - 32t41 - j &lt;= 32*floor((-1 - j)/32) &lt;= 165 - 32t41 - j &#125;</code></li>
<li>返回needed和producer_domain(此时的producer_domain表示是produced数据集合)
:<code>[t40, t41] -&gt; &#123; bx[0, 0, i = t40, 0, j = t41, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : 0 &lt;= t40 &lt;= 97 and 0 &lt;= t41 &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
</ol></li>
<li>计算producer本身的迭代域produced</li>
<li>计算missing = needed - produced(减号表示difference),
即consumer需要但producer没有produce的部分(这个例子中,missing的区域被分为了两块):<code>[t40, t41] -&gt; &#123; bx[0, 0, i, 0, j, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : t40 &gt;= 0 and 32t40 &lt;= i &lt;= 97 and i &lt;= 33 + 32t40 and j &gt;= 32t41 and t41 &lt; j &lt;= 197 and j &lt;= 31 + 32t41 and 0 &lt;= c &lt;= 2 and -32 - 32t41 - j &lt;= 32*floor((-1 - j)/32) &lt;= 165 - 32t41 - j; bx[0, 0, i, 0, j = 0, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : t41 = 0 and t40 &gt;= 0 and i &gt;= 32t40 and t40 &lt; i &lt;= 97 and i &lt;= 33 + 32t40 and 0 &lt;= c &lt;= 2 and 32*floor((-1)/1) &lt; 0 &#125;</code></li>
<li>如果missing不为空, 那么开始对missing进行操作</li>
<li>首先使用<code>get_shift_degrees</code>对missing计算位移度
<ol type="1">
<li>首先遍历missing集合的每个循环层级, 这里是循环1,
对应维度则是2和4.</li>
<li>然后将missing集合投影到除当前维度之外的所有维度,
这里的实现是通过<code>isl_set_project_out</code>删除从<code>[0,dim)</code>和<code>[1,max_dim-1)</code>两个部分,从而获得只有当前维度的投影,
比如投影维度为2则得到:<code>[t40, t41] -&gt; &#123; [i] : t40 &gt;= 0 and 32t40 &lt;= i &lt;= 97 and i &lt;= 33 + 32t40 and ((0 &lt;= t41 &lt;= 6) or (t41 = 0 and i &gt; t40)) &#125;</code></li>
<li>对投影后的集合,假设其只剩下当前维度,并且形式为:<code>[T0]-&gt;&#123;[i0]: i0 = T0 + c&#125;</code>且<code>c</code>是常量,
那么<code>-c</code>就是当前维度的移位度(可以理解成shift的offset)</li>
<li>将当前循环层级的位移度push到列表中</li>
</ol></li>
<li>循环的将参数替换为<a
target="_blank" rel="noopener" href="https://coq.inria.fr/refman/language/extensions/evars.html#:~:text=An%20existential%20variable%20is%20defined,expected%20type%20of%20the%20placeholder.">existential
variables</a>并消除他们.
<ol type="1">
<li>存在变量是代码在程序分析和优化中,
引入新的变量来表示computation中的某个未知变量,
从而可以在不改变原始computation语义的前提下, 进行变换和优化</li>
<li>遍历missing的参数遍历, 都加上前缀<code>p</code>.</li>
<li>遍历获取missing的每个basic set, 比如当前的basic set:
<code>[t40, t41] -&gt; &#123; bx[0, 0, i, 0, j, 0, c, 0, t38 = 0, 0, t39 = 0, 0, pt40, pt41] : t40 &gt;= 0 and 32t40 &lt;= i &lt;= 97 and i &lt;= 33 + 32t40 and j &gt;= 32t41 and t41 &lt; j &lt;= 197 and j &lt;= 31 + 32t41 and 0 &lt;= c &lt;= 2 and -32 - 32t41 - j &lt;= 32*floor((-1 - j)/32) &lt;= 165 - 32t41 - j &#125;</code>,
其中最后两个维度<code>pt40, pt41</code>就是被新加入前缀的变量.</li>
<li>遍历basic set每个constraint</li>
<li>检查每个constraint是不是有原始参数<code>[t40,t41]</code>参与.</li>
<li>如果有参与,比如constraint为<code>([t40, t41] -&gt; &#123; bx[i0, i1, i, i3, j, i5, c, i7, t38, i9, t39, i11, pt40, pt41] : t40 &gt;= 0 &#125;)</code>,
那么修改constraint为中用到的变量为加过前缀的变量:<code>([t40, t41] -&gt; &#123; bx[i0, i1, i, i3, j, i5, c, i7, t38, i9, t39, i11, pt40, pt41] : pt40 &gt;= 0 &#125;)</code></li>
<li>将所有constraint合并起来后, project out掉之前修改过的变量维度,
也就是<code>[pt40, pt41]</code></li>
</ol></li>
<li>最终原始missing从<code>[t40, t41] -&gt; &#123; bx[0, 0, i, 0, j, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : t40 &gt;= 0 and 32t40 &lt;= i &lt;= 97 and i &lt;= 33 + 32t40 and j &gt;= 32t41 and t41 &lt; j &lt;= 197 and j &lt;= 31 + 32t41 and 0 &lt;= c &lt;= 2 and -32 - 32t41 - j &lt;= 32*floor((-1 - j)/32) &lt;= 165 - 32t41 - j; bx[0, 0, i, 0, j = 0, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : t41 = 0 and t40 &gt;= 0 and i &gt;= 32t40 and t40 &lt; i &lt;= 97 and i &lt;= 33 + 32t40 and 0 &lt;= c &lt;= 2 and 32*floor((-1)/1) &lt; 0 &#125;</code>变为了<code>&#123; bx[0, 0, i, 0, j, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : 0 &lt;= i &lt;= 97 and 0 &lt; j &lt;= 197 and 0 &lt;= c &lt;= 2 and -32 - j - 32*floor((-1 - j)/32) &lt;= 32*floor((j)/32) &lt;= 165 - j - 32*floor((-1 - j)/32); bx[0, 0, i, 0, j = 0, 0, c, 0, t38 = 0, 0, t39 = 0, 0] : 0 &lt; i &lt;= 97 and 0 &lt;= c &lt;= 2 &#125;</code></li>
<li>因为现在missing不为空,
那么by作为consumer就需要bx重新计算出missing的值,
所以接下来需要创建duplicated producer
<ol type="1">
<li>将此时的missing作为<code>range_constraints_set</code>开始duplicate</li>
<li>duplicate就是将复制原始的schedule中的并增加第一个维度,
从<code>&#123; bx[t5, t6, t7] -&gt; bx[0, 0, i = t5, 0, j = t6, 0, c = t7, 0, t38 = 0, 0, t39 = 0, 0] : 0 &lt;= t5 &lt;= 97 and 0 &lt;= t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code>变为了<code>&#123; bx[t5, t6, t7] -&gt; bx[1, 0, i = t5, 0, j = t6, 0, c = t7, 0, t38 = 0, 0, t39 = 0, 0] : 0 &lt;= t5 &lt;= 97 and t6 &gt;= 0 and -t5 &lt; t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code></li>
<li>然后copy出原始的computation后将新的schedule赋值到新的computation上</li>
</ol></li>
<li>指定duplicated computation -&gt; producer computation -&gt; comsumer
computation的执行顺序</li>
<li>因为此时duplicated computation中的一些计算是发生在指定循环内部的,
但之前copy过来的计算映射是带有指定循环外部的偏移,
也就是之前计算的<code>get_shift_degrees</code>, 此时再将偏移补回去</li>
</ol>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/8ea9ef7c04430af70ff56633ebd94f93#file-compute_at-cpp">compute_at
log</a></p>
<h3 id="代码生成">4. 代码生成</h3>
<p>这里简单的再添加一下host/device数据复制的操作, 然后进行代码生成.
本来我想使用他论文中提到的gpu的方式进行调度,
但可能由于python包装的一些问题, 导致生成有问题,
因此我就使用cpu的数据搬运操作进行模拟.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N = <span class="number">100</span></span><br><span class="line">M = <span class="number">200</span></span><br><span class="line">C = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = tm.<span class="built_in">input</span>(<span class="string">&quot;input&quot;</span>, [<span class="string">&quot;i&quot;</span>, <span class="string">&quot;j&quot;</span>, <span class="string">&quot;c&quot;</span>], [N, M, C], tm.primitive_t.p_float32)</span><br><span class="line"></span><br><span class="line">i, j, c = tm.var(<span class="string">&quot;i&quot;</span>, <span class="number">0</span>, N - <span class="number">2</span>), tm.var(<span class="string">&#x27;j&#x27;</span>, <span class="number">0</span>, M - <span class="number">2</span>), tm.var(<span class="string">&#x27;c&#x27;</span>, <span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">cp1 = tm.computation(<span class="string">&#x27;cp1&#x27;</span>, [i, j, c], <span class="built_in">input</span>[i, j, c])</span><br><span class="line">d = tm.expr(<span class="number">3</span>).cast(tm.primitive_t.p_float32)</span><br><span class="line">bx = tm.computation(<span class="string">&#x27;bx&#x27;</span>, [i, j, c], (cp1[i, j, c] + cp1[i, j + <span class="number">1</span>, c] + cp1[i, j + <span class="number">2</span>, c]) / d)</span><br><span class="line">by = tm.computation(<span class="string">&#x27;by&#x27;</span>, [i, j, c], (bx[i, j, c] + bx[i + <span class="number">1</span>, j, c] + bx[i + <span class="number">2</span>, j, c]) / d)</span><br><span class="line">cp2 = tm.computation(<span class="string">&#x27;cp2&#x27;</span>, [i, j, c], by[i, j, c])</span><br><span class="line">by.after(bx, j)</span><br><span class="line">cp1.before(bx, tm.computation.root)</span><br><span class="line">cp2.after(by, tm.computation.root)</span><br><span class="line"></span><br><span class="line">inbuf =  <span class="built_in">input</span>.get_buffer() <span class="comment"># note lifetime problem</span></span><br><span class="line">outbuf = cp2.get_buffer()</span><br><span class="line"></span><br><span class="line">tm.codegen([inbuf, outbuf], <span class="string">&quot;func.o&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这里调度和构造computation的过程就先不看了, 直接开始看codegen部分:
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> tiramisu::function::<span class="built_in">codegen</span>(<span class="type">const</span> std::vector&lt;tiramisu::buffer *&gt; &amp;arguments, <span class="type">const</span> std::string obj_filename, <span class="type">const</span> <span class="type">bool</span> gen_cuda_stmt, <span class="type">bool</span> gen_python)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">DEBUG_FCT_NAME</span>(<span class="number">3</span>);</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">set_arguments</span>(arguments);</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">lift_dist_comps</span>();</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">gen_time_space_domain</span>();</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">gen_isl_ast</span>();</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">gen_halide_stmt</span>();</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">gen_halide_obj</span>(obj_filename, gen_python);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里作者所分割的流程还是比较清楚的, 我们一个个来看.</p>
<ol type="1">
<li><code>set_arguments</code>
<ol type="1">
<li>将传入的buffers作为function的参数</li>
</ol></li>
<li><code>lift_dist_comps</code>
<ol type="1">
<li>列出分布式的相关内容, 这里暂时没使用到</li>
</ol></li>
<li><code>gen_time_space_domain</code> (构建时序空间)
<ol type="1">
<li><code>gen_ordering_schedules</code> (获取schedule的顺序)
<ol type="1">
<li><code>dump_sched_graph</code>,
根据此前before/after的调度时添加的连接关系dump出依赖图
<code>cp1=[root]=&gt;bx ,bx=[1]=&gt;by, by=[root]=&gt;cp2</code>
可以看到是一个比较依赖图, 其中方括号中记录是依赖的循环层级.</li>
<li>遍历sched graph,
通过调用<code>after_low_level</code>函数来调整computation的执行顺序.
<ol type="1">
<li>首先将所有的computation的schedule进行对齐,
也就是把schedule中的维度个数进行扩展到相同.
比如<code>&#123; cp1[t14 = 0] -&gt; cp1[0, 0, t13 = 0, 0] &#125;</code>就被扩展到了<code>&#123; cp1[t14 = 0] -&gt; cp1[0, 0, t13 = 0, 0, 0, 0, 0, 0] &#125;</code>,
从而匹配bx/by的两级循环.</li>
<li>接下来修改schedule来实现先后顺序
<ol type="1">
<li>此时bx需要排在cp1之后,
原本的bx为<code>&#123; bx[t5, t6, t7] -&gt; bx[0, 0, i = t5, 0, j = t6, 0, c = t7, 0] : 0 &lt;= t5 &lt;= 97 and 0 &lt;= t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code>,
这里通过增大相同维度词典序(+10)来修改执行顺序,修改后bx为<code>&#123; bx[t5, t6, t7] -&gt; bx[0, 10, i = t5, 0, j = t6, 0, c = t7, 0] : 0 &lt;= t5 &lt;= 97 and 0 &lt;= t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code></li>
<li>bx修改后,修改by,
原本by为<code>&#123; by[t9, t10, t11] -&gt; by[0, 0, i = t9, 0, j = t10, 0, c = t11, 0] : 0 &lt;= t9 &lt;= 97 and 0 &lt;= t10 &lt;= 197 and 0 &lt;= t11 &lt;= 2 &#125;</code>,
此时他需要排在bx后面, 那么首先dim 1需要匹配, 同时dim
5需要大于bx因此得到<code>&#123; by[t9, t10, t11] -&gt; by[0, 10, i = t9, 0, j = t10, 10, c = t11, 0] : 0 &lt;= t9 &lt;= 97 and 0 &lt;= t10 &lt;= 197 and 0 &lt;= t11 &lt;= 2 &#125;</code></li>
<li>后续按相同逻辑修改好每个computation的schedule.</li>
</ol></li>
</ol></li>
<li>遍历所有的computation,
调用<code>computation.gen_time_space_domain</code>构建时序空间
<ol type="1">
<li>直接对当前computation的iter
domain应用它的schedule即可得到time_space_domain并返回</li>
<li>比如<code>&#123; by[i, j, c] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code>
apply schedule:
<code>&#123; by[t9, t10, t11] -&gt; by[0, 10, i = t9, 0, j = t10, 10, c = t11, 0] : 0 &lt;= t9 &lt;= 97 and 0 &lt;= t10 &lt;= 197 and 0 &lt;= t11 &lt;= 2 &#125;</code>
得到:
<code>&#123; by[0, 10, i, 0, j, 10, c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
</ol></li>
</ol></li>
</ol></li>
<li><code>gen_isl_ast</code> 构造整个function的isl ast
<ol type="1">
<li><code>get_trimmed_time_processor_domain</code>将每个之前schedule中多余的第0维消除掉.</li>
<li><code>get_aligned_identity_schedules</code>
获取function内部所有computation的aligned的identity schedule
<ol type="1">
<li>也就是将他的schedule的domain取出后进行identity映射,
然后再和<code>trimmed_time_processor_domain</code>进行求交集,
比如by的schedule为
<code>&#123; by[0, 10, i, 0, j, 10, c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code>,
它的identity_schedule为<code>&#123; by[10, i, 0, j, 10, c, 0] -&gt; [10, i' = i, 0, j' = j, 10, c' = c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code>
(这里by的第0维在是与<code>trimmed_time_processor_domain</code>求交集消除的)</li>
</ol></li>
<li><code>rename_computations</code>, 避免名字冲突,
需要给computation添加unique name</li>
<li>构造<code>isl_ast_build</code>并设定codegen选项
<ol type="1">
<li><code>atomic_upper_bound=true</code>(表示生成的循环变量在判断上界时只使用一次)</li>
<li><code>group_coscheduled=true</code>(处理相同位置的两个实例)</li>
</ol></li>
<li>为ast build
设定<code>after_each_for</code>以及<code>at_each_domain</code>的callback.</li>
<li>设定迭代器, 这里他并没有从computation中获取循环名,
而是默认为<code>c0..cn</code></li>
<li>将<code>aligned_identity_schedules</code>与<code>trimmed_time_processor_domain</code>进行取domain的交集,
得到Identity schedule intersect trimmed Time-Processor domain :
<code>&#123; cp2[20, t16 = 0, 0, t20 = 0, 0, t21 = 0, 0] -&gt; [20, t16' = 0, 0, t20' = 0, 0, t21' = 0, 0]; bx[10, i, 0, j, 0, c, 0] -&gt; [10, i' = i, 0, j' = j, 0, c' = c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2; cp1[0, t13 = 0, 0, t18 = 0, 0, t19 = 0, 0] -&gt; [0, t13' = 0, 0, t18' = 0, 0, t19' = 0, 0]; by[10, i, 0, j, 10, c, 0] -&gt; [10, i' = i, 0, j' = j, 10, c' = c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
<li>接下来对这个map进行执行<code>isl_ast_build_node_from_schedule_map</code>,
此时会执行到各个callback
<ol type="1">
<li><code>after_each_for</code>的callback为空</li>
<li><code>at_each_domain</code>的callback为<code>stmt_code_generator</code>
<ol type="1">
<li>当前传入的ast node调用<code>get_computation_by_node</code>, 通过ast
node的expr, 获得第一个参数的名字得到computation name,
然后再从function获得对应的computation 的vector</li>
<li><code>filter_computations_by_domain</code>, 获得当前build的schedule
map domain, 对上一步获得的computation vector进行过滤
<ol type="1">
<li>假设当前build的ast
node的domain为:<code>&#123; bx[10, i, 0, j, 0, c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code>,
当前的computation vector中存在bx.</li>
<li>遍历computation vector
<ol type="1">
<li>获得当前computation的原始domain为:<code>&#123; bx[i, j, c] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
<li>domain apply
之前<code>trimmed_union_of_schedules</code>得到computation在time
space上的domain:<code>&#123; bx[10, i, 0, j, 0, c, 0] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
<li>将当前的build node dmoian与time space上的domain取交集,
如果交集不为空, 那么将当前computation选中放到filtered_comp_vec中.</li>
</ol></li>
</ol></li>
<li>遍历filtered_comp_vec
<ol type="1">
<li>以当前computation构造出isl id,
并通过<code>isl_ast_node_set_annotation</code>将这个id作为node的标记</li>
<li>通过<code>get_access_relation_adapted_to_time_processor_domain</code>来获取access(此时的access是lhs,
也就是写入的buffer的访问)
<ol type="1">
<li>获取原始读写buffer的access为:<code>&#123; bx[i, j, c] -&gt; _bx_b1[i' = i, j' = j, c' = c] &#125;</code></li>
<li>原始的schedule为:<code>&#123; bx[t5, t6, t7] -&gt; bx[0, 10, i = t5, 0, j = t6, 0, c = t7, 0] : 0 &lt;= t5 &lt;= 97 and 0 &lt;= t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code></li>
<li>trimmed schedule为:
<code>&#123; bx[t5, t6, t7] -&gt; bx[10, i = t5, 0, j = t6, 0, c = t7, 0] : 0 &lt;= t5 &lt;= 97 and 0 &lt;= t6 &lt;= 197 and 0 &lt;= t7 &lt;= 2 &#125;</code></li>
<li>将trimmed schedule对access relation进行apply domain得到access
function:<code>&#123; bx[10, i, 0, j, 0, c, 0] -&gt; _bx_b1[i' = i, j' = j, c' = c] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
</ol></li>
<li>通过<code>get_rhs_accesses</code>解析得到的access function
(这里是读数据的访问)
<ol type="1">
<li>获取当前computation的expr,
比如bx原本的表达式为<code>(input[i, j, c] + input[i, j + 1, c] + input[i, j + 2, c]) / d</code></li>
<li>递归执行<code>traverse_expr_and_extract_accesses</code>将expr中的accesses提取出来
<ol type="1">
<li>首先提取到第一个访问的表达式为:<code>input[i, j, c]</code></li>
<li>以当前computation的domain<code>bx[i, j, c]</code>构建出Transformation
map:<code>&#123; bx[i, j, c] -&gt; input[i', j', c'] &#125;</code></li>
<li>遍历domain的dim和range的dim,如果他们的id相同,那么添加等价约束,
得到:<code>&#123; bx[i, j, c] -&gt; input[i' = i, j' = j, c' = c] &#125;</code></li>
<li>然后依次遍历得到其他两个access
relation<code>&#123; bx[i, j, c] -&gt; input[i' = i, j' = 1 + j, c' = c] &#125;</code>和<code>&#123; bx[i, j, c] -&gt; input[i' = i, j' = 2 + j, c' = c] &#125;</code></li>
</ol></li>
</ol></li>
<li>计算iterators map, 假设原来的循环为<code>c[i0, i1]</code>,
由于之前重新生成了迭代变量, 所以需要将他们联系起来,
得到类似<code>&#123; i0 : c0*10+c2, i1: c1*10+c3&gt;&#125;</code>的字典.
<ol type="1">
<li>获取当前computation的iter domian/schedule</li>
<li>domian进行identity之后再使用schedule apply domain得到新的identity:
<code>&#123; cp1[0, t13 = 0, 0, t18 = 0, 0, t19 = 0, 0] -&gt; cp1[t13' = 0]</code>
(此时map的domain的经过对齐的, 而range则是原始的)</li>
<li>通过<code>create_isl_ast_index_expression</code>构造取index的<code>isl_ast_expr</code>,
将上一步获取的identity作为access relation传入
<ol type="1">
<li>拿到原始schedule:<code>&#123; bx[10, i, 0, j, 0, c, 0] -&gt; [t13 = i, t18 = j, t19 = c] : 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code>进行reverse得到:
<code>&#123; [t13, t18, t19] -&gt; bx[10, i = t13, 0, j = t18, 0, c = t19, 0] : 0 &lt;= t13 &lt;= 97 and 0 &lt;= t18 &lt;= 197 and 0 &lt;= t19 &lt;= 2 &#125;</code></li>
<li>将reversed map转换为pw
aff为iterator_map:<code>&#123; [t13, t18, t19] -&gt; bx[(10), (t13), (0), (t18), (0), (t19), (0)] : 0 &lt;= t13 &lt;= 97 and 0 &lt;= t18 &lt;= 197 and 0 &lt;= t19 &lt;= 2 &#125;</code></li>
<li>将access转换为pw
aff为index_aff:<code>&#123; bx[i0, i, i2, j, i4, c, i6] -&gt; bx[(i), (j), (c)] : i0 = 10 and i2 = 0 and i4 = 0 and i6 = 0 and 0 &lt;= i &lt;= 97 and 0 &lt;= j &lt;= 197 and 0 &lt;= c &lt;= 2 &#125;</code></li>
<li>将两个pw
aff的参数进行对齐得到:<code>&#123; bx[i0, i, i2, j, i4, c, i6] -&gt; bx[i', j', c'] &#125;</code>和<code>&#123; [t13, t18, t19] -&gt; bx[o0, i, o2, j, o4, c, o6] &#125;</code></li>
<li>然后将两个pw
aff进行复合<code>isl_pw_multi_aff_pullback_pw_multi_aff(index_aff,iterator_map)</code>得到<code>&#123; [t13, t18, t19] -&gt; bx[(t13), (t18), (t19)] : 0 &lt;= t13 &lt;= 97 and 0 &lt;= t18 &lt;= 197 and 0 &lt;= t19 &lt;= 2 &#125;</code></li>
<li>通过<code>isl_ast_build_access_from_pw_multi_aff</code>取复合后的pw
aff的access表达式得到<code>&#123; op: access, args: [ &#123; id: bx &#125;, &#123; id: c1 &#125;, &#123; id: c3 &#125;, &#123; id: c5 &#125; ] &#125;</code>就是当前computation的index表达式.<br />
</li>
</ol></li>
<li>得到iterators map
为<code>&#123; i :  &#123; id: c1 &#125;, j :  &#123; id: c3 &#125;, c :  &#123; id: c5 &#125; &#125;</code></li>
</ol></li>
<li>接下来遍历所有的rhs的access, 为每个rhs
的access<code>create_isl_ast_index_expression</code>:
<ol type="1">
<li><code>&#123; op: access, args: [ &#123; id: _input_b0 &#125;, &#123; id: c1 &#125;, &#123; id: c3 &#125;, &#123; id: c5 &#125; ] &#125;</code></li>
<li><code>&#123; op: access, args: [ &#123; id: _input_b0 &#125;, &#123; id: c1 &#125;, &#123; op: add, args: [ &#123; id: c3 &#125;, &#123; val: 1 &#125; ] &#125;, &#123; id: c5 &#125; ] &#125;</code></li>
<li><code>&#123; op: access, args: [ &#123; id: _input_b0 &#125;, &#123; id: c1 &#125;, &#123; op: add, args: [ &#123; id: c3 &#125;, &#123; val: 2 &#125; ] &#125;, &#123; id: c5 &#125; ] &#125;</code></li>
</ol></li>
<li>最终所有的access的index expression为:
<code>_bx_b1[c1][c3][c5],  _input_b0[c1][c3][c5],  _input_b0[c1][c3 + 1][c5],  _input_b0[c1][c3 + 2][c5]</code></li>
</ol></li>
<li>然后将当前computation的iterators map以及index
expression都保存起来.</li>
</ol></li>
</ol></li>
<li>此时所有的ast node都构造完毕了, 通过isl printer打印最终的ast node为:
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> c1 = <span class="number">0</span>; c1 &lt;= <span class="number">97</span>; c1 += <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> c3 = <span class="number">0</span>; c3 &lt;= <span class="number">197</span>; c3 += <span class="number">1</span>)</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c5 = <span class="number">0</span>; c5 &lt;= <span class="number">2</span>; c5 += <span class="number">1</span>)</span><br><span class="line">        cp1(<span class="number">0</span>, c1, <span class="number">0</span>, c3, <span class="number">0</span>, c5, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> c1 = <span class="number">0</span>; c1 &lt;= <span class="number">97</span>; c1 += <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> c3 = <span class="number">0</span>; c3 &lt;= <span class="number">197</span>; c3 += <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c5 = <span class="number">0</span>; c5 &lt;= <span class="number">2</span>; c5 += <span class="number">1</span>)</span><br><span class="line">        bx(<span class="number">10</span>, c1, <span class="number">0</span>, c3, <span class="number">0</span>, c5, <span class="number">0</span>);</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c5 = <span class="number">0</span>; c5 &lt;= <span class="number">2</span>; c5 += <span class="number">1</span>)</span><br><span class="line">        by(<span class="number">10</span>, c1, <span class="number">0</span>, c3, <span class="number">10</span>, c5, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> c1 = <span class="number">0</span>; c1 &lt;= <span class="number">97</span>; c1 += <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> c3 = <span class="number">0</span>; c3 &lt;= <span class="number">197</span>; c3 += <span class="number">1</span>)</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c5 = <span class="number">0</span>; c5 &lt;= <span class="number">2</span>; c5 += <span class="number">1</span>)</span><br><span class="line">        cp2(<span class="number">20</span>, c1, <span class="number">0</span>, c3, <span class="number">0</span>, c5, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol></li>
<li><code>gen_halide_stmt</code>, 将isl ast
lower到halide的stmt上从而利用halide所提供的codegen功能
<ol type="1">
<li>调用<code>halide_stmt_from_isl_node</code>函数递归的将isl
ast转换为halide stmt,
对于stmt来说主要有以下一些ast类型<code>for,if,block</code></li>
<li>对于表达式则是通过之前所构造的isl ast
node中所添加的annotation找到对应的computation,
然后通过computation构造出具体的halide expression.</li>
</ol></li>
</ol>
<p><a
target="_blank" rel="noopener" href="https://gist.github.com/zhen8838/c579bbf43d4bfe3c3e53c828ce9ce507">codegen
log</a></p>
<h1 id="总结">总结</h1>
<p>其实对于isl来说, 只需要有<code>access relation</code>,
<code>iteration domain</code>以及<code>schedule</code>就可以构造出对应的<code>ast</code>,
但是还缺少每个<code>statement</code>中具体的表达式才能得到完整的程序.
tiramisu是在<code>computation</code>的抽象中存放了isl所需要内容以及表达式,
也将两者进行了联系,
对<code>computation</code>的调度即是修改isl的<code>schedule</code>和<code>iteration domain</code>,
最终利用调度和关系生产ast, 通过表达式与ast的联系生成halide IR.</p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DSL/" rel="tag">DSL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tiramisu/" rel="tag">Tiramisu</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" rel="tag">多面体模型</a></li></ul></div><div class="post-nav"><a class="pre" href="/2023/09/19/easydist/">Alibaba EasyDist 浅析</a><a class="next" href="/2023/06/16/dl-costmodel/">基于DL的CostModel</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a> <a href="/tags/%E7%AE%97%E5%AD%90/" style="font-size: 15px;">算子</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/09/26/flashattn/">Flash Attention记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/08/28/chimera/">Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>