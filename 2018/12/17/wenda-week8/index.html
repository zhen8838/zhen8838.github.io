<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>机器学习作业第八周 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习作业第八周</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习作业第八周</h1><div class="post-meta">2018-12-17<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 4.1k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 25</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ex8.py"><span class="toc-number">1.</span> <span class="toc-text">ex8.py</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%88%E6%9E%9C"><span class="toc-number">1.1.</span> <span class="toc-text">效果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ex8_cofi.py"><span class="toc-number">2.</span> <span class="toc-text">ex8_cofi.py</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%88%E6%9E%9C-1"><span class="toc-number">2.1.</span> <span class="toc-text">效果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#fucs8.py"><span class="toc-number">3.</span> <span class="toc-text">fucs8.py</span></a></li></ol></div></div><div class="post-content"><p>终于到了最后一周接下来就是学习深度学习相关内容,一个是吴恩达老师的深度学习课程,他的深度学习前面一些内容学过机器学习就不需要看了.然后还可以看斯坦福大学的<code>UFLDL</code>教程,也有翻译中文版.</p>
<span id="more"></span>
<h1 id="ex8.py">ex8.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.core <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">from</span> imageio <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> fucs8 <span class="keyword">import</span> estimateGaussian, multivariateGaussian, visualizeFit, selectThreshold</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Machine Learning Online Class</span></span><br><span class="line">    <span class="comment">#  Exercise 8 | Anomaly Detection and Collaborative Filtering</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  Instructions</span></span><br><span class="line">    <span class="comment">#  ------------</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  This file contains code that helps you get started on the</span></span><br><span class="line">    <span class="comment">#  exercise. You will need to complete the following functions:</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     estimateGaussian.m</span></span><br><span class="line">    <span class="comment">#     selectThreshold.m</span></span><br><span class="line">    <span class="comment">#     cofiCostFunc.m</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  For this exercise, you will not need to change any code in this file,</span></span><br><span class="line">    <span class="comment">#  or any other files other than those mentioned above.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 1: Load Example Dataset  ===================</span></span><br><span class="line">    <span class="comment">#  We start this exercise by using a small dataset that is easy to</span></span><br><span class="line">    <span class="comment">#  visualize.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  Our example case consists of 2 network server statistics across</span></span><br><span class="line">    <span class="comment">#  several machines: the latency and throughput of each machine.</span></span><br><span class="line">    <span class="comment">#  This exercise will help us find possibly faulty (or very fast) machines.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Visualizing example dataset for outlier detection.\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  The following command loads the dataset. You should now have the</span></span><br><span class="line">    <span class="comment">#  variables X, Xval, yval in your environment</span></span><br><span class="line">    data = loadmat(<span class="string">&#x27;ex8data1.mat&#x27;</span>)</span><br><span class="line">    X = data[<span class="string">&#x27;X&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    Xval = data[<span class="string">&#x27;Xval&#x27;</span>]</span><br><span class="line">    yval = data[<span class="string">&#x27;yval&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Visualize the example dataset</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], <span class="string">&#x27;xb&#x27;</span>)</span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">30</span>, <span class="number">0</span>, <span class="number">30</span>])</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Latency (ms)&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Throughput (mb/s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Program paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 2: Estimate the dataset statistics ===================</span></span><br><span class="line">    <span class="comment">#  For this exercise, we assume a Gaussian distribution for the dataset.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  We first estimate the parameters of our assumed Gaussian distribution,</span></span><br><span class="line">    <span class="comment">#  then compute the probabilities for each of the points and then visualize</span></span><br><span class="line">    <span class="comment">#  both the overall distribution and where each of the points falls in</span></span><br><span class="line">    <span class="comment">#  terms of that distribution.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Visualizing Gaussian fit.\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Estimate my and sigma2</span></span><br><span class="line">    mu, sigma2 = estimateGaussian(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Returns the density of the multivariate normal at each data point (row)</span></span><br><span class="line">    <span class="comment">#  of X</span></span><br><span class="line">    p = multivariateGaussian(X, mu, sigma2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Visualize the fit</span></span><br><span class="line">    visualizeFit(X,  mu, sigma2)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Latency (ms)&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Throughput (mb/s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Program paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 3: Find Outliers ===================</span></span><br><span class="line">    <span class="comment">#  Now you will find a good epsilon threshold using a cross-validation set</span></span><br><span class="line">    <span class="comment">#  probabilities given the estimated Gaussian distribution</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    pval = multivariateGaussian(Xval, mu, sigma2)</span><br><span class="line"></span><br><span class="line">    epsilon, F1 = selectThreshold(yval, pval)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best epsilon found using cross-validation: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epsilon))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best F1 on Cross Validation Set:  &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(F1))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;   (you should see a value epsilon of about 8.99e-05)&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;   (you should see a Best F1 value of  0.875000)\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Find the outliers in the training set and plot the</span></span><br><span class="line">    outliers = nonzero(p &lt; epsilon)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Draw a red circle around those outliers</span></span><br><span class="line">    plt.plot(X[outliers, <span class="number">0</span>], X[outliers, <span class="number">1</span>], <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Program paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 4: Multidimensional Outliers ===================</span></span><br><span class="line">    <span class="comment">#  We will now use the code from the previous part and apply it to a</span></span><br><span class="line">    <span class="comment">#  harder problem in which more features describe each datapoint and only</span></span><br><span class="line">    <span class="comment">#  some features indicate whether a point is an outlier.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Loads the second dataset. You should now have the</span></span><br><span class="line">    <span class="comment">#  variables X, Xval, yval in your environment</span></span><br><span class="line">    data = loadmat(<span class="string">&#x27;ex8data2.mat&#x27;</span>)</span><br><span class="line">    X = data[<span class="string">&#x27;X&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    Xval = data[<span class="string">&#x27;Xval&#x27;</span>]</span><br><span class="line">    yval = data[<span class="string">&#x27;yval&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Apply the same steps to the larger dataset</span></span><br><span class="line">    mu, sigma2 = estimateGaussian(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Training set</span></span><br><span class="line">    p = multivariateGaussian(X, mu, sigma2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Cross-validation set</span></span><br><span class="line">    pval = multivariateGaussian(Xval, mu, sigma2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Find the best threshold</span></span><br><span class="line">    epsilon, F1 = selectThreshold(yval, pval)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best epsilon found using cross-validation: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epsilon))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best F1 on Cross Validation Set:  &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(F1))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;   (you should see a value epsilon of about 1.38e-18)&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;   (you should see a Best F1 value of 0.615385)&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;# Outliers found: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">sum</span>(p &lt; epsilon)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="效果">效果</h2>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Visualizing example dataset <span class="keyword">for</span> outlier detection.</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line">Visualizing Gaussian fit.</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line">/media/zqh/程序与工程/Python_study/Machine_learning/machine_learning_exam/week8/fucs8.py:113: RuntimeWarning: invalid value encountered <span class="keyword">in</span> long_scalars</span><br><span class="line">  prec = tp / (tp + fp)</span><br><span class="line">Best epsilon found using cross-validation: 8.990852779269495e-05</span><br><span class="line">Best F1 on Cross Validation Set:  0.8750000000000001</span><br><span class="line">   (you should see a value epsilon of about 8.99e-05)</span><br><span class="line">   (you should see a Best F1 value of  0.875000)</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line">Best epsilon found using cross-validation: 1.377228890761358e-18</span><br><span class="line">Best F1 on Cross Validation Set:  0.6153846153846154</span><br><span class="line">   (you should see a value epsilon of about 1.38e-18)</span><br><span class="line">   (you should see a Best F1 value of 0.615385)</span><br><span class="line"><span class="comment"># Outliers found: 117</span></span><br></pre></td></tr></table></figure>
<p><img src="/2018/12/17/wenda-week8/11.png" /></p>
<h1 id="ex8_cofi.py">ex8_cofi.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> numpy.core <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> c_, r_</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> fmin_cg</span><br><span class="line"><span class="keyword">from</span> fucs8 <span class="keyword">import</span> cofiCostFunc, checkCostFunction, loadMovieList, normalizeRatings</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Machine Learning Online Class</span></span><br><span class="line">    <span class="comment">#  Exercise 8 | Anomaly Detection and Collaborative Filtering</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  Instructions</span></span><br><span class="line">    <span class="comment">#  ------------</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  This file contains code that helps you get started on the</span></span><br><span class="line">    <span class="comment">#  exercise. You will need to complete the following functions:</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     estimateGaussian.m</span></span><br><span class="line">    <span class="comment">#     selectThreshold.m</span></span><br><span class="line">    <span class="comment">#     cofiCostFunc.m</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  For this exercise, you will not need to change any code in this file,</span></span><br><span class="line">    <span class="comment">#  or any other files other than those mentioned above.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># =============== Part 1: Loading movie ratings dataset ================</span></span><br><span class="line">    <span class="comment">#  You will start by loading the movie ratings dataset to understand the</span></span><br><span class="line">    <span class="comment">#  structure of the data.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Loading movie ratings dataset.\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Load data</span></span><br><span class="line">    data = loadmat(<span class="string">&#x27;ex8_movies.mat&#x27;</span>)</span><br><span class="line">    Y = data[<span class="string">&#x27;Y&#x27;</span>]</span><br><span class="line">    R = data[<span class="string">&#x27;R&#x27;</span>]</span><br><span class="line">    <span class="comment">#  Y is a 1682x943 matrix, containing ratings (1-5) of 1682 movies on</span></span><br><span class="line">    <span class="comment">#  943 users</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  R is a 1682x943 matrix, where R(i,j) = 1 if and only if user j gave a</span></span><br><span class="line">    <span class="comment">#  rating to movie i</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  From the matrix, we can compute statistics like average rating.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Average rating for movie 1 (Toy Story): &#123;&#125; / 5&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        mean(Y[<span class="number">0</span>, nonzero(R[<span class="number">0</span>, :])])))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  We can &quot;visualize&quot; the ratings matrix by plotting it with imagesc</span></span><br><span class="line"></span><br><span class="line">    plt.imshow(Y)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Movies&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Users&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ============ Part 2: Collaborative Filtering Cost Function ===========</span></span><br><span class="line">    <span class="comment">#  You will now implement the cost function for collaborative filtering.</span></span><br><span class="line">    <span class="comment">#  To help you debug your cost function, we have included set of weights</span></span><br><span class="line">    <span class="comment">#  that we trained on that. Specifically, you should complete the code in</span></span><br><span class="line">    <span class="comment">#  cofiCostFunc.m to return J.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Load pre-trained weights (X, Theta, num_users, num_movies, num_features)</span></span><br><span class="line">    data = loadmat(<span class="string">&#x27;ex8_movieParams.mat&#x27;</span>)</span><br><span class="line">    X = data[<span class="string">&#x27;X&#x27;</span>]</span><br><span class="line">    Theta = data[<span class="string">&#x27;Theta&#x27;</span>]</span><br><span class="line">    num_users = data[<span class="string">&#x27;num_users&#x27;</span>]</span><br><span class="line">    num_movies = data[<span class="string">&#x27;num_movies&#x27;</span>]</span><br><span class="line">    num_features = data[<span class="string">&#x27;num_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Reduce the data set size so that this runs faster</span></span><br><span class="line">    num_users = <span class="number">4</span></span><br><span class="line">    num_movies = <span class="number">5</span></span><br><span class="line">    num_features = <span class="number">3</span></span><br><span class="line">    X = X[: num_movies, : num_features]</span><br><span class="line">    Theta = Theta[: num_users, : num_features]</span><br><span class="line">    Y = Y[: num_movies, : num_users]</span><br><span class="line">    R = R[: num_movies, : num_users]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Evaluate cost function</span></span><br><span class="line">    J, _ = cofiCostFunc(r_[X.ravel(), Theta.ravel()], Y, R,</span><br><span class="line">                        num_users, num_movies, num_features, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Cost at loaded parameters: &#123;&#125;\n(this value should be about 22.22)&#x27;</span>.<span class="built_in">format</span>(J))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Program paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ============== Part 3: Collaborative Filtering Gradient ==============</span></span><br><span class="line">    <span class="comment">#  Once your cost function matches up with ours, you should now implement</span></span><br><span class="line">    <span class="comment">#  the collaborative filtering gradient function. Specifically, you should</span></span><br><span class="line">    <span class="comment">#  complete the code in cofiCostFunc.m to return the grad argument.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nChecking Gradients (without regularization) ... &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Check gradients by running checkNNGradients</span></span><br><span class="line">    checkCostFunction()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ========= Part 4: Collaborative Filtering Cost Regularization ========</span></span><br><span class="line">    <span class="comment">#  Now, you should implement regularization for the cost function for</span></span><br><span class="line">    <span class="comment">#  collaborative filtering. You can implement it by adding the cost of</span></span><br><span class="line">    <span class="comment">#  regularization to the original cost computation.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Evaluate cost function</span></span><br><span class="line">    J, _ = cofiCostFunc(r_[X.ravel(), Theta.ravel()], Y, R, num_users, num_movies,</span><br><span class="line">                        num_features, <span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Cost at loaded parameters (lambda = 1.5): &#123;&#125; \</span></span><br><span class="line"><span class="string">           \n(this value should be about 31.34)&#x27;</span>.<span class="built_in">format</span>(J))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======= Part 5: Collaborative Filtering Gradient Regularization ======</span></span><br><span class="line">    <span class="comment">#  Once your cost matches up with ours, you should proceed to implement</span></span><br><span class="line">    <span class="comment">#  regularization for the gradient.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nChecking Gradients (with regularization) ... &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Check gradients by running checkNNGradients</span></span><br><span class="line">    checkCostFunction(<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ============== Part 6: Entering ratings for a new user ===============</span></span><br><span class="line">    <span class="comment">#  Before we will train the collaborative filtering model, we will first</span></span><br><span class="line">    <span class="comment">#  add ratings that correspond to a new user that we just observed. This</span></span><br><span class="line">    <span class="comment">#  part of the code will also allow you to put in your own ratings for the</span></span><br><span class="line">    <span class="comment">#  movies in our dataset!</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    movieList = loadMovieList()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Initialize my ratings</span></span><br><span class="line">    my_ratings = zeros((<span class="number">1682</span>, ))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Check the file movie_idx.txt for id of each movie in our dataset</span></span><br><span class="line">    <span class="comment"># For example, Toy Story (1995) has ID 1, so to rate it &quot;4&quot;, you can set</span></span><br><span class="line">    my_ratings[<span class="number">0</span>] = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Or suppose did not enjoy Silence of the Lambs [1991], you can set</span></span><br><span class="line">    my_ratings[<span class="number">97</span>] = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># We have selected a few movies we liked / did not like and the ratings we</span></span><br><span class="line">    <span class="comment"># gave are as follows:</span></span><br><span class="line">    my_ratings[<span class="number">6</span>] = <span class="number">3</span></span><br><span class="line">    my_ratings[<span class="number">11</span>] = <span class="number">5</span></span><br><span class="line">    my_ratings[<span class="number">53</span>] = <span class="number">4</span></span><br><span class="line">    my_ratings[<span class="number">63</span>] = <span class="number">5</span></span><br><span class="line">    my_ratings[<span class="number">65</span>] = <span class="number">3</span></span><br><span class="line">    my_ratings[<span class="number">68</span>] = <span class="number">5</span></span><br><span class="line">    my_ratings[<span class="number">182</span>] = <span class="number">4</span></span><br><span class="line">    my_ratings[<span class="number">225</span>] = <span class="number">5</span></span><br><span class="line">    my_ratings[<span class="number">354</span>] = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nNew user ratings:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(my_ratings)):</span><br><span class="line">        <span class="keyword">if</span> my_ratings[i] &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Rated &#123;&#125; for &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(my_ratings[i], movieList[i]))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 7: Learning Movie Ratings ====================</span></span><br><span class="line">    <span class="comment">#  Now, you will train the collaborative filtering model on a movie rating</span></span><br><span class="line">    <span class="comment">#  dataset of 1682 movies and 943 users</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTraining collaborative filtering...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Load data</span></span><br><span class="line">    data = loadmat(<span class="string">&#x27;ex8_movies.mat&#x27;</span>)</span><br><span class="line">    Y = data[<span class="string">&#x27;Y&#x27;</span>]</span><br><span class="line">    R = data[<span class="string">&#x27;R&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Y is a 1682x943 matrix, containing ratings (1-5) of 1682 movies by</span></span><br><span class="line">    <span class="comment">#  943 users</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#  R is a 1682x943 matrix, where R(i,j) = 1 if and only if user j gave a</span></span><br><span class="line">    <span class="comment">#  rating to movie i</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Add our own ratings to the data matrix</span></span><br><span class="line">    Y = c_[my_ratings, Y]</span><br><span class="line">    R = c_[(my_ratings != <span class="number">0</span>)+<span class="number">0</span>, R]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Normalize Ratings</span></span><br><span class="line">    Ynorm, Ymean = normalizeRatings(Y, R)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Useful Values</span></span><br><span class="line">    num_users = size(Y, <span class="number">1</span>)</span><br><span class="line">    num_movies = size(Y, <span class="number">0</span>)</span><br><span class="line">    num_features = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set Initial Parameters (Theta, X)</span></span><br><span class="line">    X = randn(num_movies, num_features)</span><br><span class="line">    Theta = randn(num_users, num_features)</span><br><span class="line"></span><br><span class="line">    initial_parameters = r_[X.ravel(), Theta.ravel()]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set options for fmincg</span></span><br><span class="line">    MaxIter = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set Regularization</span></span><br><span class="line">    lamda = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">costFuc</span>(<span class="params">x</span>): <span class="keyword">return</span> cofiCostFunc(x, Ynorm, R, num_users, num_movies,</span><br><span class="line">                                        num_features, lamda)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gradFuc</span>(<span class="params">x</span>): <span class="keyword">return</span> cofiCostFunc(x, Ynorm, R, num_users, num_movies,</span><br><span class="line">                                        num_features, lamda)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    theta = fmin_cg(costFuc, initial_parameters, gradFuc, maxiter=MaxIter)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unfold the returned theta back into U and W</span></span><br><span class="line">    X = reshape(theta[: num_movies*num_features], (num_movies, num_features))</span><br><span class="line">    Theta = reshape(theta[num_movies*num_features:], (num_users, num_features))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Recommender system learning completed.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nProgram paused. Press enter to continue.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================== Part 8: Recommendation for you ====================</span></span><br><span class="line">    <span class="comment">#  After training the model, you can now make recommendations by computing</span></span><br><span class="line">    <span class="comment">#  the predictions matrix.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    p = X @ Theta.T</span><br><span class="line">    my_predictions = p[:, <span class="number">0</span>] + Ymean.ravel()</span><br><span class="line"></span><br><span class="line">    movieList = loadMovieList()</span><br><span class="line"></span><br><span class="line">    ix = argsort(my_predictions)[::-<span class="number">1</span>]</span><br><span class="line">    r = sort(my_predictions)[::-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTop recommendations for you:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        j = ix[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Predicting rating &#123;:.1f&#125; for movie &#123;&#125; &#x27;</span>.<span class="built_in">format</span>(my_predictions[j],</span><br><span class="line">                                                              movieList[j]))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nOriginal ratings provided:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(my_ratings)):</span><br><span class="line">        <span class="keyword">if</span> my_ratings[i] &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Rated &#123;&#125; for &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(my_ratings[i],</span><br><span class="line">                                           movieList[i]))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="效果-1">效果</h2>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Loading movie ratings dataset.</span><br><span class="line"></span><br><span class="line">Average rating <span class="keyword">for</span> movie 1 (Toy Story): 3.8783185840707963 / 5</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line">Cost at loaded parameters: 22.22460372568567</span><br><span class="line">(this value should be about 22.22)</span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line"></span><br><span class="line">Checking Gradients (without regularization) ...</span><br><span class="line">[  1.43203539  -0.63274492  -1.00531856   0.89769276  -0.28926118</span><br><span class="line">  -0.65993552  10.17121834  10.43486571 -12.40615625   0.35938134</span><br><span class="line">  -0.02758239  -0.38856257  -5.66399174 -10.80568736  18.42971531</span><br><span class="line">  -3.17534552   1.28489352  10.89656357  -0.23222024  -0.66648527</span><br><span class="line">   0.9995297   -0.0185099    0.65721699   0.33866012   0.</span><br><span class="line">   0.           0.        ] [  1.43203539  -0.63274492  -1.00531856   0.89769276  -0.28926118</span><br><span class="line">  -0.65993552  10.17121834  10.43486571 -12.40615625   0.35938134</span><br><span class="line">  -0.02758239  -0.38856257  -5.66399174 -10.80568736  18.42971531</span><br><span class="line">  -3.17534552   1.28489352  10.89656357  -0.23222024  -0.66648527</span><br><span class="line">   0.9995297   -0.0185099    0.65721699   0.33866012   0.</span><br><span class="line">   0.           0.        ]</span><br><span class="line">The above two columns you get should be very similar.</span><br><span class="line">(Left-Your Numerical Gradient, Right-Analytical Gradient)</span><br><span class="line"></span><br><span class="line">If your cost <span class="keyword">function</span> implementation is correct, <span class="keyword">then</span></span><br><span class="line">the relative difference will be small (less than 1e-9).</span><br><span class="line"></span><br><span class="line">Relative Difference: 1.3943940851783395e-12</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line">Cost at loaded parameters (lambda = 1.5): 31.344056244274213</span><br><span class="line">(this value should be about 31.34)</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line"></span><br><span class="line">Checking Gradients (with regularization) ...</span><br><span class="line">[-0.3960421  -3.42481695 -0.52898699  0.05550482  1.45849918 -1.46259522</span><br><span class="line">  2.19529571  2.05102836  0.22049044  0.37247193  1.01557475 -5.3171257</span><br><span class="line"> -2.28357796 -1.12923924  1.67314559 -1.21504222 -0.7500923  -2.03542911</span><br><span class="line"> -0.24564074  1.62362884 -4.8857543   1.13231058 -0.71201535 -1.5937657</span><br><span class="line">  2.36345388  3.61334864  1.43292096] [-0.3960421  -3.42481695 -0.52898699  0.05550482  1.45849918 -1.46259522</span><br><span class="line">  2.19529571  2.05102836  0.22049044  0.37247193  1.01557475 -5.3171257</span><br><span class="line"> -2.28357796 -1.12923924  1.67314559 -1.21504222 -0.7500923  -2.03542911</span><br><span class="line"> -0.24564074  1.62362884 -4.8857543   1.13231058 -0.71201535 -1.5937657</span><br><span class="line">  2.36345388  3.61334864  1.43292096]</span><br><span class="line">The above two columns you get should be very similar.</span><br><span class="line">(Left-Your Numerical Gradient, Right-Analytical Gradient)</span><br><span class="line"></span><br><span class="line">If your cost <span class="keyword">function</span> implementation is correct, <span class="keyword">then</span></span><br><span class="line">the relative difference will be small (less than 1e-9).</span><br><span class="line"></span><br><span class="line">Relative Difference: 2.3144279833807326e-12</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line"></span><br><span class="line">New user ratings:</span><br><span class="line">Rated 4.0 <span class="keyword">for</span> Toy Story (1995)</span><br><span class="line">Rated 3.0 <span class="keyword">for</span> Twelve Monkeys (1995)</span><br><span class="line">Rated 5.0 <span class="keyword">for</span> Usual Suspects, The (1995)</span><br><span class="line">Rated 4.0 <span class="keyword">for</span> Outbreak (1995)</span><br><span class="line">Rated 5.0 <span class="keyword">for</span> Shawshank Redemption, The (1994)</span><br><span class="line">Rated 3.0 <span class="keyword">for</span> While You Were Sleeping (1995)</span><br><span class="line">Rated 5.0 <span class="keyword">for</span> Forrest Gump (1994)</span><br><span class="line">Rated 2.0 <span class="keyword">for</span> Silence of the Lambs, The (1991)</span><br><span class="line">Rated 4.0 <span class="keyword">for</span> Alien (1979)</span><br><span class="line">Rated 5.0 <span class="keyword">for</span> Die Hard 2 (1990)</span><br><span class="line">Rated 5.0 <span class="keyword">for</span> Sphere (1998)</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line"></span><br><span class="line">Training collaborative filtering...</span><br><span class="line">Warning: Maximum number of iterations has been exceeded.</span><br><span class="line">         Current <span class="keyword">function</span> value: 38967.455063</span><br><span class="line">         Iterations: 50</span><br><span class="line">         Function evaluations: 85</span><br><span class="line">         Gradient evaluations: 85</span><br><span class="line">Recommender system learning completed.</span><br><span class="line"></span><br><span class="line">Program paused. Press enter to <span class="built_in">continue</span>.</span><br><span class="line"></span><br><span class="line">Top recommendations <span class="keyword">for</span> you:</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Entertaining Angels: The Dorothy Day Story (1996)</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Santa with Muscles (1996)</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Someone Else<span class="string">&#x27;s America (1995)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Prefontaine (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie They Made Me a Criminal (1939)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Great Day in Harlem, A (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Star Kid (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Aiqing wansui (1994)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Original ratings provided:</span></span><br><span class="line"><span class="string">Rated 4.0 for Toy Story (1995)</span></span><br><span class="line"><span class="string">Rated 3.0 for Twelve Monkeys (1995)</span></span><br><span class="line"><span class="string">Rated 5.0 for Usual Suspects, The (1995)</span></span><br><span class="line"><span class="string">Rated 4.0 for Outbreak (1995)</span></span><br><span class="line"><span class="string">Rated 5.0 for Shawshank Redemption, The (1994)</span></span><br><span class="line"><span class="string">Rated 3.0 for While You Were Sleeping (1995)</span></span><br><span class="line"><span class="string">Rated 5.0 for Forrest Gump (1994)</span></span><br><span class="line"><span class="string">Rated 2.0 for Silence of the Lambs, The (1991)</span></span><br><span class="line"><span class="string">Rated 4.0 for Alien (1979)</span></span><br><span class="line"><span class="string">Rated 5.0 for Die Hard 2 (1990)</span></span><br><span class="line"><span class="string">Rated 5.0 for Sphere (1998)</span></span><br></pre></td></tr></table></figure>
<p><img src="/2018/12/17/wenda-week8/21.png" /></p>
<h1 id="fucs8.py">fucs8.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> diag, linspace, meshgrid, c_, r_, isinf</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> rand, randn</span><br><span class="line"><span class="keyword">from</span> numpy.core <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> det, pinv, norm</span><br><span class="line"><span class="keyword">from</span> numpy.matrixlib <span class="keyword">import</span> mat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">estimateGaussian</span>(<span class="params">X: ndarray</span>):</span><br><span class="line">    <span class="comment"># ESTIMATEGAUSSIAN This function estimates the parameters of a</span></span><br><span class="line">    <span class="comment"># Gaussian distribution using the data in X</span></span><br><span class="line">    <span class="comment">#   [mu sigma2] = estimateGaussian(X),</span></span><br><span class="line">    <span class="comment">#   The input X is the dataset with each n-dimensional data point in one row</span></span><br><span class="line">    <span class="comment">#   The output is an n-dimensional vector mu, the mean of the data set</span></span><br><span class="line">    <span class="comment">#   and the variances sigma^2, an n x 1 vector</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Useful variables</span></span><br><span class="line">    m, n = shape(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># You should return these values correctly</span></span><br><span class="line">    mu = zeros((n, <span class="number">0</span>))</span><br><span class="line">    sigma2 = zeros((n, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ====================== YOUR CODE HERE ======================</span></span><br><span class="line">    <span class="comment"># Instructions: Compute the mean of the data and the variances</span></span><br><span class="line">    <span class="comment">#               In particular, mu(i) should contain the mean of</span></span><br><span class="line">    <span class="comment">#               the data for the i-th feature and sigma2(i)</span></span><br><span class="line">    <span class="comment">#               should contain variance of the i-th feature.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    mu = mean(X, <span class="number">0</span>)</span><br><span class="line">    sigma2 = <span class="number">1</span>/m * <span class="built_in">sum</span>((X-mu.reshape(<span class="number">1</span>, -<span class="number">1</span>))**<span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># =============================================================</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mu, sigma2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multivariateGaussian</span>(<span class="params">X: ndarray, mu: ndarray, Sigma2: ndarray</span>):</span><br><span class="line">    <span class="comment"># MULTIVARIATEGAUSSIAN Computes the probability density function of the</span></span><br><span class="line">    <span class="comment"># multivariate gaussian distribution.</span></span><br><span class="line">    <span class="comment">#    p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability</span></span><br><span class="line">    <span class="comment">#    density function of the examples X under the multivariate gaussian</span></span><br><span class="line">    <span class="comment">#    distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is</span></span><br><span class="line">    <span class="comment">#    treated as the covariance matrix. If Sigma2 is a vector, it is treated</span></span><br><span class="line">    <span class="comment">#    as the \sigma^2 values of the variances in each dimension (a diagonal</span></span><br><span class="line">    <span class="comment">#    covariance matrix)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    k = <span class="built_in">len</span>(mu)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size(mat(Sigma2), <span class="number">1</span>) == <span class="number">1</span>) <span class="keyword">or</span> (size(mat(Sigma2), <span class="number">0</span>) == <span class="number">1</span>):</span><br><span class="line">        Sigma2 = diag(Sigma2)</span><br><span class="line"></span><br><span class="line">    x = X - mu.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    p = (<span class="number">2</span> * pi)**(- k / <span class="number">2</span>) * det(Sigma2) ** (-<span class="number">0.5</span>) * \</span><br><span class="line">        exp(-<span class="number">0.5</span> * <span class="built_in">sum</span>(x@pinv(Sigma2)*x, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualizeFit</span>(<span class="params">X, mu, sigma2</span>):</span><br><span class="line">    <span class="comment"># VISUALIZEFIT Visualize the dataset and its estimated distribution.</span></span><br><span class="line">    <span class="comment">#   VISUALIZEFIT(X, p, mu, sigma2) This visualization shows you the</span></span><br><span class="line">    <span class="comment">#   probability density function of the Gaussian distribution. Each example</span></span><br><span class="line">    <span class="comment">#   has a location (x1, x2) that depends on its feature values.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    X1, X2 = meshgrid(arange(<span class="number">0</span>, <span class="number">35.5</span>, <span class="number">.5</span>), arange(<span class="number">0</span>, <span class="number">35.5</span>, <span class="number">.5</span>))  <span class="comment"># type:ndarray</span></span><br><span class="line">    Z = multivariateGaussian(c_[X1.ravel(), X2.ravel()], mu, sigma2)</span><br><span class="line">    Z = reshape(Z, shape(X1))</span><br><span class="line"></span><br><span class="line">    plt.plot(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], <span class="string">&#x27;bx&#x27;</span>)</span><br><span class="line">    <span class="comment"># Do not plot if there are infinities</span></span><br><span class="line">    <span class="comment"># map(lamda x: 10**x, range(-20, 0, 3))</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">sum</span>(isinf(Z)) == <span class="number">0</span>):</span><br><span class="line">        plt.contour(X1, X2, Z, <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="number">10</span>**x, <span class="built_in">range</span>(-<span class="number">20</span>, <span class="number">0</span>, <span class="number">3</span>))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectThreshold</span>(<span class="params">yval: ndarray, pval: ndarray</span>):</span><br><span class="line">    <span class="comment"># SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting</span></span><br><span class="line">    <span class="comment"># outliers</span></span><br><span class="line">    <span class="comment">#   [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best</span></span><br><span class="line">    <span class="comment">#   threshold to use for selecting outliers based on the results from a</span></span><br><span class="line">    <span class="comment">#   validation set (pval) and the ground truth (yval).</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    bestEpsilon = <span class="number">0</span></span><br><span class="line">    bestF1 = <span class="number">0</span></span><br><span class="line">    F1 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    stepsize = (<span class="built_in">max</span>(pval) - <span class="built_in">min</span>(pval)) / <span class="number">1000</span></span><br><span class="line">    <span class="keyword">for</span> epsilon <span class="keyword">in</span> arange(<span class="built_in">min</span>(pval), <span class="built_in">max</span>(pval), stepsize):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ====================== YOUR CODE HERE ======================</span></span><br><span class="line">        <span class="comment"># Instructions: Compute the F1 score of choosing epsilon as the</span></span><br><span class="line">        <span class="comment">#               threshold and place the value in F1. The code at the</span></span><br><span class="line">        <span class="comment">#               end of the loop will compare the F1 score for this</span></span><br><span class="line">        <span class="comment">#               choice of epsilon and set it to be the best epsilon if</span></span><br><span class="line">        <span class="comment">#               it is better than the current choice of epsilon.</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Note: You can use predictions = (pval &lt; epsilon) to get a binary vector</span></span><br><span class="line">        <span class="comment">#       of 0&#x27;s and 1&#x27;s of the outlier predictions</span></span><br><span class="line"></span><br><span class="line">        predictions = (pval &lt; epsilon)</span><br><span class="line"></span><br><span class="line">        fp = <span class="built_in">sum</span>((predictions == <span class="number">1</span>) &amp; (yval.ravel() == <span class="number">0</span>))</span><br><span class="line">        fn = <span class="built_in">sum</span>((predictions == <span class="number">0</span>) &amp; (yval.ravel() == <span class="number">1</span>))</span><br><span class="line">        tp = <span class="built_in">sum</span>((predictions == <span class="number">1</span>) &amp; (yval.ravel() == <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        prec = tp / (tp + fp)</span><br><span class="line">        rec = tp / (tp + fn)</span><br><span class="line"></span><br><span class="line">        F1 = <span class="number">2</span> * prec * rec / (prec + rec)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># =============================================================</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> F1 &gt; bestF1:</span><br><span class="line">            bestF1 = F1</span><br><span class="line">            bestEpsilon = epsilon</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bestEpsilon, bestF1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cofiCostFunc</span>(<span class="params">params, Y, R, num_users, num_movies, num_features, lamda</span>):</span><br><span class="line">    <span class="comment"># COFICOSTFUNC Collaborative filtering cost function</span></span><br><span class="line">    <span class="comment">#   [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...</span></span><br><span class="line">    <span class="comment">#   num_features, lamda) returns the cost and gradient for the</span></span><br><span class="line">    <span class="comment">#   collaborative filtering problem.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unfold the U and W matrices from params</span></span><br><span class="line">    X = reshape(params[: num_movies*num_features],</span><br><span class="line">                (num_movies, num_features))  <span class="comment"># type:ndarray</span></span><br><span class="line">    Theta = reshape(params[num_movies*num_features:],</span><br><span class="line">                    (num_users, num_features))  <span class="comment"># type:ndarray</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># You need to return the following values correctly</span></span><br><span class="line">    J = <span class="number">0</span></span><br><span class="line">    X_grad = zeros(shape(X))</span><br><span class="line">    Theta_grad = zeros(shape(Theta))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ====================== YOUR CODE HERE ======================</span></span><br><span class="line">    <span class="comment"># Instructions: Compute the cost function and gradient for collaborative</span></span><br><span class="line">    <span class="comment">#               filtering. Concretely, you should first implement the cost</span></span><br><span class="line">    <span class="comment">#               function (without regularization) and make sure it is</span></span><br><span class="line">    <span class="comment">#               matches our costs. After that, you should implement the</span></span><br><span class="line">    <span class="comment">#               gradient and use the checkCostFunction routine to check</span></span><br><span class="line">    <span class="comment">#               that the gradient is correct. Finally, you should implement</span></span><br><span class="line">    <span class="comment">#               regularization.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Notes: X - num_movies  x num_features matrix of movie features</span></span><br><span class="line">    <span class="comment">#        Theta - num_users  x num_features matrix of user features</span></span><br><span class="line">    <span class="comment">#        Y - num_movies x num_users matrix of user ratings of movies</span></span><br><span class="line">    <span class="comment">#        R - num_movies x num_users matrix, where R(i, j) = 1 if the</span></span><br><span class="line">    <span class="comment">#            i-th movie was rated by the j-th user</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># You should set the following variables correctly:</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#        X_grad - num_movies x num_features matrix, containing the</span></span><br><span class="line">    <span class="comment">#                 partial derivatives w.r.t. to each element of X</span></span><br><span class="line">    <span class="comment">#        Theta_grad - num_users x num_features matrix, containing the</span></span><br><span class="line">    <span class="comment">#                     partial derivatives w.r.t. to each element of Theta</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    J_temp = (X @ Theta.T - Y) ** <span class="number">2</span></span><br><span class="line">    J = <span class="built_in">sum</span>(J_temp[nonzero(R == <span class="number">1</span>)])/<span class="number">2</span> + lamda/<span class="number">2</span> * \</span><br><span class="line">        <span class="built_in">sum</span>(Theta ** <span class="number">2</span>) + lamda/<span class="number">2</span> * <span class="built_in">sum</span>(X ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    X_grad = ((X@Theta.T - Y) * R) @ Theta + lamda*X</span><br><span class="line">    Theta_grad = ((X@Theta.T - Y) * R).T @ X + lamda*Theta</span><br><span class="line"></span><br><span class="line">    <span class="comment"># =============================================================</span></span><br><span class="line"></span><br><span class="line">    grad = r_[X_grad.ravel(), Theta_grad.ravel()]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> J, grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computeNumericalGradient</span>(<span class="params">J, theta: ndarray</span>):</span><br><span class="line">    <span class="comment"># COMPUTENUMERICALGRADIENT Computes the gradient using &quot;finite differences&quot;</span></span><br><span class="line">    <span class="comment"># and gives us a numerical estimate of the gradient.</span></span><br><span class="line">    <span class="comment">#   numgrad = COMPUTENUMERICALGRADIENT(J, theta) computes the numerical</span></span><br><span class="line">    <span class="comment">#   gradient of the function J around theta. Calling y = J(theta) should</span></span><br><span class="line">    <span class="comment">#   return the function value at theta.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Notes: The following code implements numerical gradient checking, and</span></span><br><span class="line">    <span class="comment">#        returns the numerical gradient.It sets numgrad(i) to (a numerical</span></span><br><span class="line">    <span class="comment">#        approximation of) the partial derivative of J with respect to the</span></span><br><span class="line">    <span class="comment">#        i-th input argument, evaluated at theta. (i.e., numgrad(i) should</span></span><br><span class="line">    <span class="comment">#        be the (approximately) the partial derivative of J with respect</span></span><br><span class="line">    <span class="comment">#        to theta(i).)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    numgrad = zeros(shape(theta))</span><br><span class="line">    perturb = zeros(shape(theta))</span><br><span class="line">    e = <span class="number">1e-4</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(size(theta)):</span><br><span class="line">        <span class="comment"># Set perturbation vector</span></span><br><span class="line">        perturb[p] = e</span><br><span class="line">        loss1 = J(theta - perturb)[<span class="number">0</span>]</span><br><span class="line">        loss2 = J(theta + perturb)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># Compute Numerical Gradient</span></span><br><span class="line">        numgrad[p] = (loss2 - loss1) / (<span class="number">2</span>*e)</span><br><span class="line">        perturb[p] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> numgrad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">checkCostFunction</span>(<span class="params">lamda=<span class="number">0</span></span>):</span><br><span class="line">    <span class="comment"># CHECKCOSTFUNCTION Creates a collaborative filering problem</span></span><br><span class="line">    <span class="comment"># to check your cost function and gradients</span></span><br><span class="line">    <span class="comment">#   CHECKCOSTFUNCTION(lamda) Creates a collaborative filering problem</span></span><br><span class="line">    <span class="comment">#   to check your cost function and gradients, it will output the</span></span><br><span class="line">    <span class="comment">#   analytical gradients produced by your code and the numerical gradients</span></span><br><span class="line">    <span class="comment">#   (computed using computeNumericalGradient). These two gradient</span></span><br><span class="line">    <span class="comment">#   computations should result in very similar values.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create small problem</span></span><br><span class="line">    X_t = rand(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">    Theta_t = rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zap out most entries</span></span><br><span class="line">    Y = X_t @ Theta_t.T</span><br><span class="line">    Y[nonzero(rand(size(Y, <span class="number">0</span>), size(Y, <span class="number">1</span>)) &gt; <span class="number">0.5</span>)] = <span class="number">0</span></span><br><span class="line">    R = zeros(shape(Y))</span><br><span class="line">    R[nonzero(Y != <span class="number">0</span>)] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run Gradient Checking</span></span><br><span class="line">    X = randn(size(X_t))</span><br><span class="line">    Theta = randn(size(Theta_t))</span><br><span class="line">    num_users = size(Y, <span class="number">1</span>)</span><br><span class="line">    num_movies = size(Y, <span class="number">0</span>)</span><br><span class="line">    num_features = size(Theta_t, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Costfunc</span>(<span class="params">x</span>): <span class="keyword">return</span> cofiCostFunc(</span><br><span class="line">        x, Y, R, num_users, num_movies, num_features, lamda)</span><br><span class="line"></span><br><span class="line">    numgrad = computeNumericalGradient(Costfunc, r_[X.ravel(), Theta.ravel()])</span><br><span class="line"></span><br><span class="line">    cost, grad = cofiCostFunc(r_[X.ravel(), Theta.ravel()],  Y, R, num_users, num_movies,</span><br><span class="line">                              num_features, lamda)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(numgrad, grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;The above two columns you get should be very similar.\n\</span></span><br><span class="line"><span class="string">(Left-Your Numerical Gradient, Right-Analytical Gradient)\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    diff = norm(numgrad-grad)/norm(numgrad+grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;If your cost function implementation is correct, then \n\</span></span><br><span class="line"><span class="string">the relative difference will be small (less than 1e-9). \n\</span></span><br><span class="line"><span class="string">\nRelative Difference: &#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(diff))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadMovieList</span>():</span><br><span class="line">    <span class="comment"># GETMOVIELIST reads the fixed movie list in movie.txt and returns a</span></span><br><span class="line">    <span class="comment"># cell array of the words</span></span><br><span class="line">    <span class="comment">#   movieList = GETMOVIELIST() reads the fixed movie list in movie.txt</span></span><br><span class="line">    <span class="comment"># and returns a cell array of the words in movieList.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store all movies in cell array movie&#123;&#125;</span></span><br><span class="line">    n = <span class="number">1682</span></span><br><span class="line">    movieList = []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;movie_ids.txt&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fid:</span><br><span class="line">            movieList.append(line.strip().split(<span class="string">&#x27; &#x27;</span>, maxsplit=<span class="number">1</span>)[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> movieList</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalizeRatings</span>(<span class="params">Y: ndarray, R: ndarray</span>):</span><br><span class="line">    <span class="comment"># NORMALIZERATINGS Preprocess data by subtracting mean rating for every</span></span><br><span class="line">    <span class="comment"># movie (every row)</span></span><br><span class="line">    <span class="comment">#   [Ynorm, Ymean] = NORMALIZERATINGS(Y, R) normalized Y so that each movie</span></span><br><span class="line">    <span class="comment">#   has a rating of 0 on average, and returns the mean rating in Ymean.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    m, n = shape(Y)</span><br><span class="line">    Ymean = zeros((m, <span class="number">1</span>))</span><br><span class="line">    Ynorm = zeros(shape(Y))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        idx = nonzero(R[i, :] == <span class="number">1</span>)</span><br><span class="line">        Ymean[i, :] = mean(Y[i, idx])</span><br><span class="line">        Ynorm[i, idx] = Y[i, idx] - Ymean[i]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Ynorm, Ymean</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" rel="tag">吴恩达课程</a></li></ul></div><div class="post-nav"><a class="pre" href="/2018/12/24/LeNet-5/">LeNet-5</a><a class="next" href="/2018/12/15/wenda-week7/">机器学习作业第七周</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx_en/">Explore AMX instructions: Unlock the performance of Apple Silicon</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/13/macos-bundle/">macos中bundle的使用</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>