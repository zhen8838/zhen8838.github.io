<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>TVM TensorIR | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TVM TensorIR</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">TVM TensorIR</h1><div class="post-meta">2021-12-04<span> | </span><span class="category"><a href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 3.3k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 15</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ffi-navigator%E7%9A%84bug%E4%BF%AE%E5%A4%8D"><span class="toc-number">1.</span> <span class="toc-text">1. ffi navigator的bug修复</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tvm.script.tir-%E4%B8%8E-tvm.tir"><span class="toc-number">2.</span> <span class="toc-text">2. tvm.script.tir 与 tvm.tir</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tvm.script---tir%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">3. tvm.script -&gt; tir的流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ir-builder%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">4 ir builder流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tvm.te-%E4%B8%8E-tvm.tir"><span class="toc-number">5.</span> <span class="toc-text">5. tvm.te 与 tvm.tir</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%BA%9Btir%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">6. 一些tir的作用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#block-reads-writes"><span class="toc-number">6.1.</span> <span class="toc-text">6.1 block reads &amp;&amp; writes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#block-iter_var"><span class="toc-number">6.2.</span> <span class="toc-text">6.2 block iter_var</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bufferload-lower"><span class="toc-number">6.3.</span> <span class="toc-text">6.3 BufferLoad lower</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90"><span class="toc-number">7.</span> <span class="toc-text">7. 代码生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ssa%E8%B5%8B%E5%80%BC"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 ssa赋值</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8Erelay%E5%88%B0tir"><span class="toc-number">8.</span> <span class="toc-text">从relay到tir</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%9B%B4%E5%8A%A0%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99tiling"><span class="toc-number">9.</span> <span class="toc-text">如何更加优雅的写tiling?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E5%9C%A8tvm%E4%B8%AD"><span class="toc-number">9.1.</span> <span class="toc-text">如果在TVM中:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E5%9C%A8csharp%E4%B8%AD"><span class="toc-number">9.2.</span> <span class="toc-text">如果在CSharp中:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%82%E9%85%8D%E8%80%81%E6%9E%B6%E6%9E%84%E7%9A%84segment%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="toc-number">9.2.1.</span> <span class="toc-text">1. 适配老架构的segment的方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5glb_tensor%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E7%B4%A2%E5%BC%95%E7%9A%84%E6%96%B9%E5%BC%8F%E8%BF%9B%E8%A1%8Ctiling-%E8%80%8C%E5%90%8E%E6%9E%84%E9%80%A0%E6%8C%87%E4%BB%A4."><span class="toc-number">9.2.2.</span> <span class="toc-text">2.
输入glb_tensor,可以通过索引的方式进行tiling, 而后构造指令.</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>关于TVM的Tensor level IR.</p>
<span id="more"></span>
<h1 id="ffi-navigator的bug修复">1. ffi navigator的bug修复</h1>
<p>我这里是python3.9, 不知道为什么tvm的ffi
navigator插件有一个类型问题启动不了.
所以需要修改<code>/Users/lisa/mambaforge/lib/python3.9/site-packages/ffi_navigator/dialect/tvm.py line 97</code>为如下:
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> path.startswith(<span class="string">&quot;&quot;</span> <span class="keyword">if</span> self._pypath_api_internal <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> self._pypath_api_internal):</span><br></pre></td></tr></table></figure>
有了这个看tvm的就舒服多了,不然你从python到c++的实现都非常难找.</p>
<h1 id="tvm.script.tir-与-tvm.tir">2. tvm.script.tir 与 tvm.tir</h1>
<p><code>tvm.tir</code>是内在实现.
<code>tvm.script.tir</code>主要是封装了一层用户友好的python类型接口(不存在实现).可以查看<a
target="_blank" rel="noopener" href="https://tvm.apache.org/docs/tutorial/tensor_ir_blitz_course.html">这篇文章</a>.
<code>tvm.script</code>实际上就是<code>tensor ir</code>的语法表现形式,我们通过写<code>tvm.script</code>语法,然后构建出<code>IRModule</code>.
避免了直接从ir构造的别扭,因为如果是relay这种,不需要考虑太多的条件以及循环等,如果是底层ir,用函数的方式写这些就非常蛋疼了.
比如从tir直接构造ir是这样的: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ib = tvm.tir.ir_builder.create()</span><br><span class="line">a = tir.Var(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;float32&quot;</span>)</span><br><span class="line">b = tir.Var(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;float32&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> ib.if_scope(<span class="literal">True</span>):</span><br><span class="line">    ib.emit(tir.Evaluate(tir.ret(a)))</span><br><span class="line">ib.emit(tir.Evaluate(tir.ret(b)))</span><br><span class="line">stmt = ib.get()</span><br><span class="line">func = tir.PrimFunc([a, b], stmt)</span><br><span class="line">func = build_tir_func(func)</span><br><span class="line">out = func(<span class="number">1.0</span>, <span class="number">2.0</span>)</span><br></pre></td></tr></table></figure>
如果用<code>script.tir</code>就方便多了: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@T.prim_func</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: T.handle, b: T.handle</span>):</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> T.parallel(<span class="number">0</span>, <span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> T.serial(<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">      <span class="keyword">for</span> z <span class="keyword">in</span> T.vectorized(<span class="number">3</span>, <span class="number">4</span>):</span><br><span class="line">        T.evaluate(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="tvm.script---tir的流程">3. tvm.script -&gt; tir的流程</h1>
<p>首先我们使用<code>tvm.script.tir</code>写一个计算函数,然后被转换为<code>python</code>的<code>ast</code>,由于不同
<code>python</code> 版本之间的 <code>ast</code> 不同,所以
<code>tvm</code> 单独开发了一个和 <code>python</code> 版本无关的
<code>ast parser</code> 叫 <code>synr</code>.
在<code>parser</code>的使用利用<code>tvm</code>的<code>lower transformer</code>把<code>ast</code>进行细化.
要注意,用户层面导入<code>tvm.script.tir as T</code>实际上都只有类型而已,
他对于这些类型的实际定义并没有导入进来,而是在<code>tvm.script.parser</code>中使用.
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@T.prim_func</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul</span>(<span class="params">a: T.handle, b: T.handle, c: T.handle</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  A = T.match_buffer(a, [<span class="number">128</span>, <span class="number">128</span>])</span><br><span class="line">  B = T.match_buffer(b, [<span class="number">128</span>, <span class="number">128</span>])</span><br><span class="line">  C = T.match_buffer(c, [<span class="number">128</span>, <span class="number">128</span>])</span><br><span class="line">  <span class="keyword">for</span> i, j <span class="keyword">in</span> T.grid(<span class="number">128</span>, <span class="number">128</span>):</span><br><span class="line">    <span class="keyword">with</span> T.block(<span class="string">&quot;init&quot;</span>):</span><br><span class="line">      vi, vj = T.axis.remap(<span class="string">&quot;SS&quot;</span>, [i, j])</span><br><span class="line">      C[vi, vj] = T.float32(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">128</span>):</span><br><span class="line">      <span class="keyword">with</span> T.block(<span class="string">&quot;update&quot;</span>):</span><br><span class="line">        vi, vj, vk = T.axis.remap(<span class="string">&quot;SSR&quot;</span>, [i, j, k])</span><br><span class="line">        C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]</span><br></pre></td></tr></table></figure> 转换为<code>tvm.tir.function.PrimFunc</code>就如下:
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">PrimFunc([a, b, c])  &#123;</span><br><span class="line">  block root() &#123;</span><br><span class="line">    reads([])</span><br><span class="line">    writes([])</span><br><span class="line">    <span class="keyword">for</span> (i, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (j, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">        block init(iter_var(vi, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>)), iter_var(vj, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>))) &#123;</span><br><span class="line">          bind(vi, i)</span><br><span class="line">          bind(vj, j)</span><br><span class="line">          reads([])</span><br><span class="line">          writes([C[vi, vj]])</span><br><span class="line">          C[vi, vj] = 0f</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (k, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">          block update(iter_var(vi, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>)), iter_var(vj, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>)), iter_var(vk, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>))) &#123;</span><br><span class="line">            bind(vi, i)</span><br><span class="line">            bind(vj, j)</span><br><span class="line">            bind(vk, k)</span><br><span class="line">            reads([C[vi, vj], A[vi, vk], B[vj, vk]])</span><br><span class="line">            writes([C[vi, vj]])</span><br><span class="line">            C[vi, vj] = (C[vi, vj] + (A[vi, vk]*B[vj, vk]))</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="ir-builder流程">4 ir builder流程</h1>
<p><code>ir builder</code>提供了另一种构建<code>tir</code>的方法,典型用法如下:
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ib = tvm.tir.ir_builder.create()</span><br><span class="line">n = te.size_var(<span class="string">&quot;n&quot;</span>)</span><br><span class="line">A = ib.pointer(<span class="string">&quot;float32&quot;</span>, name=<span class="string">&quot;A&quot;</span>)</span><br><span class="line">tmod = tvm.tir.truncmod</span><br><span class="line"><span class="keyword">with</span> ib.for_range(<span class="number">0</span>, n, name=<span class="string">&quot;i&quot;</span>) <span class="keyword">as</span> i:</span><br><span class="line">  <span class="keyword">with</span> ib.if_scope(tmod(i, <span class="number">2</span>) == <span class="number">0</span>):</span><br><span class="line">    A[i] = A[i] + <span class="number">1</span></span><br><span class="line">  <span class="keyword">with</span> ib.else_scope():</span><br><span class="line">    A[<span class="number">0</span>] = A[i] + <span class="number">2</span></span><br><span class="line">body = ib.get()</span><br></pre></td></tr></table></figure>
所有通过<code>ib.xx</code>构造的<code>ir</code>对象都会通过<code>ib.emit</code>的方式添加到<code>ir builer</code>内部,然后对于一些存在<code>scope</code>的比如<code>for if</code>等等,
是构造了一个<code>with scope</code>对象,然后在退出这个<code>scope</code>的时候把中间的所有<code>emit</code>生成的对象作为<code>body</code>构造成一个<code>for/if</code>的<code>ir</code>.</p>
<h1 id="tvm.te-与-tvm.tir">5. tvm.te 与 tvm.tir</h1>
<p><code>te</code>里面的实际上是老的写法,他里面又写了一套<code>tensor/data producer</code>等等的<code>ir</code>,
<code>te</code>的<code>ir</code>定义实际上是以<code>operation</code>为核心的,然后类似于<code>tensorflow</code>的<code>placeholder</code>的方式进行构建的,实际上在转换到<code>IRModule</code>的时候,还是会把这些东西转化为<code>tir.Buffer</code>.所以目前可以不看那块的内容.</p>
<h1 id="一些tir的作用">6. 一些tir的作用</h1>
<h2 id="block-reads-writes">6.1 block reads &amp;&amp; writes</h2>
<p><code>block</code>是<code>tvm</code>调度的基本单元,他的调度器通常是获得一个<code>block</code>,然后对这个块进行融合/分割/并行等等操作,同时还可以分析多个块
在<code>parser</code>的<code>block</code>的流程,他的<code>func.body</code>是只会有一个赋值的操作<code>C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]</code>(忽略了前面的<code>iter var</code>定义,应该是这些定义到时候都会被固化到代码中,所以也不会出现在计算流程中的原因),然后在<code>func.exit_scope</code>时,他会进入<code>tvm</code>的<code>callback</code>函数中
<code>python/tvm/script/tir/scope_handler.py line 255</code>,构造出带有<code>bind</code>以及<code>reads/writes</code>的<code>tir</code>.
(实际上底层还分有<code>BlockRealize</code>和<code>Block</code>两部分)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> T.block(<span class="string">&quot;update&quot;</span>):</span><br><span class="line">  vi, vj, vk = T.axis.remap(<span class="string">&quot;SSR&quot;</span>, [i, j, k])</span><br><span class="line">  C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">func.enter_scope(node, self.context, arg_list, node.rhs.func_name.span)</span><br><span class="line">func.body = self.parse_body(node)</span><br><span class="line">res = func.exit_scope(node, self.context, arg_list, node.rhs.func_name.span)</span><br></pre></td></tr></table></figure>
<p>得到的结果,实际上是把<code>remap</code>的定义融合到了<code>block</code>这个<code>ir</code>中.
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (k, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">  block update(iter_var(vi, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>)), iter_var(vj, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>)), iter_var(vk, <span class="built_in">range</span>(<span class="built_in">min</span>=<span class="number">0</span>, ext=<span class="number">128</span>))) &#123;</span><br><span class="line">    bind(vi, i)</span><br><span class="line">    bind(vj, j)</span><br><span class="line">    bind(vk, k)</span><br><span class="line">    reads([C[vi, vj], A[vi, vk], B[vj, vk]])</span><br><span class="line">    writes([C[vi, vj]])</span><br><span class="line">    C[vi, vj] = (C[vi, vj] + (A[vi, vk]*B[vj, vk]))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="block-iter_var">6.2 block iter_var</h2>
<p><code>iter_var</code>我个人把他看作一个<code>symbol var</code>,他的好处就是我们可以任意绑定一个时机的<code>value</code>,等到<code>schedule</code>做完后再消除他得到真正的索引操作.
这里要说明一下<code>iter_var</code>对于一个<code>Buffer</code>的索引操作将会得到是<code>BufferLoad</code>的<code>ir</code>,他的表现形式就是多维索引<code>B[vi,vj]</code>.
在后续这个<code>BufferLoad</code>会被<code>lower</code>到<code>Load</code>,表现形式就是<code>B.Handle[i * w + j]</code>.
即我们取<code>symbol var</code>绑定的<code>value</code>并计算出对于一个指针真正的索引.</p>
<p>🌰 原始<code>TIR</code>: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i: int32, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">  <span class="keyword">for</span> (j: int32, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">    block([<span class="number">128</span>, <span class="number">128</span>], <span class="string">&quot;B&quot;</span>) <span class="keyword">as</span> [vi, vj] &#123;</span><br><span class="line">      bind(vi, i)</span><br><span class="line">      bind(vj, j)</span><br><span class="line">      tir.reads([A[vi, vj]])</span><br><span class="line">      tir.writes([B[vi, vj]])</span><br><span class="line">      B[vi, vj] = (A[vi, vj]*2f32)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 经过<code>split</code>之后,
可以发现我们只需要修改<code>iter var</code>的绑定即可实现<code>split</code>,
不然得递归把所有的<code>i</code>改成<code>((i_0*64) + i_1)</code>,写<code>transform</code>就巨麻烦了.
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i_0: int32, <span class="number">0</span>, <span class="number">2</span>) &#123;</span><br><span class="line">  <span class="keyword">for</span> (i_1: int32, <span class="number">0</span>, <span class="number">64</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (j: int32, <span class="number">0</span>, <span class="number">128</span>) &#123;</span><br><span class="line">      block([<span class="number">128</span>, <span class="number">128</span>], <span class="string">&quot;B&quot;</span>) <span class="keyword">as</span> [vi, vj] &#123;</span><br><span class="line">        bind(vi, ((i_0*<span class="number">64</span>) + i_1))</span><br><span class="line">        bind(vj, j)</span><br><span class="line">        tir.reads([A[vi, vj]])</span><br><span class="line">        tir.writes([B[vi, vj]])</span><br><span class="line">        B[vi, vj] = (A[vi, vj]*2f32)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="bufferload-lower">6.3 BufferLoad lower</h2>
<ol type="1">
<li>利用<code>ConvertBlocksToOpaque</code>的<code>transform</code>把<code>iter_var.var</code>都替换成对应的<code>value</code>,
这里我其实没明白,为什么不把<code>itervar</code>也设计成<code>expr</code>,
理论上应该没啥问题吧. <!-- 2. 把所有的buffer load --></li>
</ol>
<h1 id="代码生成">7. 代码生成</h1>
<h2 id="ssa赋值">7.1 ssa赋值</h2>
<p>我自己写了一下c代码生成才发现不能无脑对综合了stmt以及expr的ir进行ssa赋值.怪不得tvm的c代码生成默认不开ssa赋值.</p>
<p>🌰 把下面的代码转换为c代码 <figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">RefFunc</span>(<span class="params"><span class="built_in">int</span>[] A, <span class="built_in">int</span> n</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="function">i <span class="title">in</span> (<span class="params"><span class="number">0</span>, n</span>))</span></span><br><span class="line">    &#123;</span><br><span class="line">        A[i] = A[i] + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="function">j <span class="title">in</span> (<span class="params"><span class="number">0</span>, <span class="number">10</span></span>))</span></span><br><span class="line">        &#123;</span><br><span class="line">            A[i] = A[i] + j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
如果使用ssa赋值,同时我这里的visit
expression的时候是用结构化比较的,所以内外两个循环中相同的<code>load A[i]</code>都变成了<code>_1</code>这个<code>tmep var</code>了.
然后第二次<code>load</code>的时候就会出现没有更新值的问题.
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">func_0</span><span class="params">(<span class="type">int32_t</span>* A, <span class="type">int32_t</span> n)</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="type">int32_t</span> _3 = (i * <span class="number">1</span>);</span><br><span class="line">    <span class="type">int32_t</span> _2 = (<span class="number">0</span> + _3);</span><br><span class="line">    <span class="type">int32_t</span> _1 = A[_2];</span><br><span class="line">    <span class="type">int32_t</span> _0 = (_1 + <span class="number">1</span>);</span><br><span class="line">     A[_2] = _0;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int32_t</span> j = <span class="number">0</span>; j &lt; <span class="number">10</span>; j++) &#123;</span><br><span class="line">      <span class="type">int32_t</span> _4 = (_1 + j); <span class="comment">// 这里就会出现load没有更新值的问题</span></span><br><span class="line">       A[_2] = _4;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>所以我目前也是按照tvm的方法,把这些计算流程都转换成线性的计算.
这样就保证所有的表达式都会被<code>emit</code>,不过也带来了一个计算冗余的问题,这个后续我们可以继续优化.
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">func_0</span><span class="params">(<span class="type">int32_t</span>* A, <span class="type">int32_t</span> n)</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">     A[(<span class="number">0</span> + (i * <span class="number">1</span>))] = (A[(<span class="number">0</span> + (i * <span class="number">1</span>))] + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int32_t</span> j = <span class="number">0</span>; j &lt; <span class="number">10</span>; j++) &#123;</span><br><span class="line">       A[(<span class="number">0</span> + (i * <span class="number">1</span>))] = (A[(<span class="number">0</span> + (i * <span class="number">1</span>))] + j);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="从relay到tir">从relay到tir</h1>
<p>默认tvm是在codegen中执行这个过程, 不过没法直接dump出对应的tir来看,
不过我们可以通过自定义pass的方法插入print节点.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tvm <span class="keyword">import</span> relay</span><br><span class="line"><span class="keyword">from</span> tvm.relay <span class="keyword">import</span> testing</span><br><span class="line"><span class="keyword">import</span> tvm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resnet18 workload</span></span><br><span class="line">resnet18_mod, resnet18_params = relay.testing.resnet.get_workload(num_layers=<span class="number">18</span>)</span><br><span class="line">resnet18_mod: tvm.IRModule</span><br><span class="line"></span><br><span class="line"><span class="meta">@tvm.tir.transform.prim_func_pass(<span class="params">opt_level=<span class="number">0</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_tir</span>(<span class="params">f, mod, ctx</span>):</span><br><span class="line">    <span class="built_in">print</span>(f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tvm.transform.PassContext(</span><br><span class="line">        opt_level=<span class="number">3</span>, config=&#123;<span class="string">&quot;tir.add_lower_pass&quot;</span>: [(<span class="number">3</span>, print_tir)]&#125;</span><br><span class="line">    ):</span><br><span class="line">        lib = relay.build(resnet18_mod, target=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="如何更加优雅的写tiling">如何更加优雅的写tiling?</h1>
<h2 id="如果在tvm中">如果在TVM中:</h2>
<p>如果是手写tiling的话,最麻烦的一点就是每次都需要手动算tile大小,然后开辟出n个for循环进行写操作.
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@T.prim_func</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simple_split</span>(<span class="params">a: T.handle</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  A = T.match_buffer(a, [<span class="number">16</span>])</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> T.serial(<span class="number">0</span>, <span class="number">16</span>):</span><br><span class="line">    <span class="keyword">with</span> T.block(<span class="string">&quot;block&quot;</span>):</span><br><span class="line">      vi = T.axis.remap(<span class="string">&quot;S&quot;</span>, [i])</span><br><span class="line">      A[vi] = i + <span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_simple_split</span>():</span><br><span class="line">  sch = tir.Schedule(simple_split)</span><br><span class="line">  b = sch.get_block(<span class="string">&quot;block&quot;</span>)</span><br><span class="line">  lps = sch.get_loops(b)</span><br><span class="line">  sch.split(lps[<span class="number">0</span>], [<span class="number">7</span>,<span class="number">10</span>])</span><br><span class="line">  <span class="built_in">print</span>(sch.mod.script())</span><br><span class="line"></span><br><span class="line"><span class="comment"># from tvm.script import tir as T</span></span><br><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Module</span>:</span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">a: T.handle</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        A = T.match_buffer(a, [<span class="number">16</span>], dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        <span class="keyword">for</span> i_0, i_1 <span class="keyword">in</span> T.grid(<span class="number">7</span>, <span class="number">10</span>):</span><br><span class="line">            <span class="keyword">with</span> T.block(<span class="string">&quot;block&quot;</span>):</span><br><span class="line">                vi = T.axis.spatial(<span class="number">16</span>, i_0 * <span class="number">10</span> + i_1)</span><br><span class="line">                T.where(i_0 * <span class="number">10</span> + i_1 &lt; <span class="number">16</span>)</span><br><span class="line">                T.reads([])</span><br><span class="line">                T.writes([A[vi]])</span><br><span class="line">                A[vi] = i_0 * <span class="number">10</span> + i_1 + <span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<p>不过tvm的tir中是简化了for循环,也就是无法自定义stride,因为他面向的对象都是cpu/gpu这些的设备.
但是如果对于一些大颗粒算子的dsa来说,最好还是带有stride的for循环比较合理,否则对于一段程序我们需要这样写:
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@T.prim_func</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simple_split</span>(<span class="params">a: T.handle</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  A = T.match_buffer(a, [<span class="number">16</span>])</span><br><span class="line">  chunk_n = <span class="number">3</span></span><br><span class="line">  chunk_c = <span class="number">5</span></span><br><span class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> T.serial(<span class="number">0</span>, compute_segment(<span class="number">16</span>, chunk_n)):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> T.serial(<span class="number">0</span>, compute_segment(<span class="number">32</span>, chunk_c)):</span><br><span class="line">      <span class="keyword">with</span> T.block(<span class="string">&quot;block&quot;</span>):</span><br><span class="line">        vi, vj = T.axis.remap(<span class="string">&quot;SS&quot;</span>, [n,c])</span><br><span class="line">        A[vi * chunk_n + vj * chunk_c] = <span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<p>如果每次都自己控制chunk,那么如果有6d的tensor,也就是6层循环,
那么变量绝对多到难以控制的程度.</p>
<p>如果可以这样写肯定就舒服多了,
然后关键是就是chunk固定但是length还得每次求, 不过应该是合理一些了:
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@T.prim_func</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simple_split</span>(<span class="params">a: T.handle</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  A = T.match_buffer(a, [<span class="number">16</span>])</span><br><span class="line">  chunk_n = <span class="number">3</span></span><br><span class="line">  chunk_c = <span class="number">5</span></span><br><span class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> T.serial(<span class="number">0</span>, <span class="number">16</span>, chunk_n):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> T.serial(<span class="number">0</span>, <span class="number">32</span>, chunk_c):</span><br><span class="line">      <span class="keyword">with</span> T.block(<span class="string">&quot;block&quot;</span>):</span><br><span class="line">        vi, vj = T.axis.remap(<span class="string">&quot;SS&quot;</span>, [n,c])</span><br><span class="line">        <span class="keyword">with</span> T.let(length_n, <span class="built_in">min</span>(chunk_n, <span class="number">16</span> - vi)):</span><br><span class="line">          <span class="keyword">with</span> T.let(length_c, <span class="built_in">min</span>(chunk_c, <span class="number">32</span> - vj)):</span><br><span class="line">            A[vi + vj] = <span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<p>但是还是有一点非常麻烦,那就是求tir中定义一个变量就需要声明他的作用域,那么对于真的多层的循环复杂逻辑肯定还是很麻烦的.</p>
<h2 id="如果在csharp中">如果在CSharp中:</h2>
<p>我的想法是在csharp中基于Linq实现两套写法,
那些shape之类的可能还是没法用expr进行lazy的运算,因为一旦那样就很难用linq语法,
写起来就复杂很多.</p>
<h3 id="适配老架构的segment的方式">1. 适配老架构的segment的方式</h3>
<p>之前因为是cpp的语法,所以要实现一套基于Enumerable的dsl还是比较麻烦,所以for循环之类的刻板代码比较多,
目前我也先支持这种写法. 通过linq拆分出segment之后构造segment
4d然后进行计算.
csharp的linq可以再嵌套linq所以不用担心复杂的逻辑无法处理,
最后返回出expr即可.</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">T.PrimFunc(<span class="string">&quot;TileLoadStore&quot;</span>).Body(</span><br><span class="line">  (<span class="keyword">from</span> item <span class="keyword">in</span> glb.items</span><br><span class="line">    <span class="keyword">let</span> mmu = item.Value</span><br><span class="line">    <span class="keyword">select</span> I.MmuConf((MMU_CONF_WIDTH)mmu.width, mmu.id, mmu.start_bank, mmu.start_depth, mmu.depth)).ToSequential(),</span><br><span class="line">  (<span class="function"><span class="keyword">from</span> glb_input_batch <span class="keyword">in</span> <span class="title">SegmentByChunk</span>(<span class="params"><span class="number">0</span>, glb.last_out_shape[<span class="number">0</span>], input_shape[<span class="number">0</span>]</span>)</span></span><br><span class="line"><span class="function">    <span class="keyword">from</span> glb_input_channel <span class="keyword">in</span> <span class="title">SegmentByChunk</span>(<span class="params"><span class="number">0</span>, glb.last_out_shape[<span class="number">1</span>], input_shape[<span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="function">      <span class="keyword">from</span> glb_input_row <span class="keyword">in</span> <span class="title">SegmentByChunk</span>(<span class="params"><span class="number">0</span>, glb.last_out_shape[<span class="number">2</span>], input_shape[<span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="function">        <span class="keyword">from</span> glb_input_column <span class="keyword">in</span> <span class="title">SegmentByChunk</span>(<span class="params"><span class="number">0</span>, glb.last_out_shape[<span class="number">3</span>], input_shape[<span class="number">3</span>]</span>)</span></span><br><span class="line"><span class="function">          <span class="keyword">let</span> ofmap</span> = <span class="keyword">new</span> tensor4d_segment( glb_input_batch.OutputByStride(strides[<span class="number">0</span>]),</span><br><span class="line">                                            glb_input_channel.OutputByStride(strides[<span class="number">1</span>]),</span><br><span class="line">                                            glb_input_row.OutputByStride(strides[<span class="number">2</span>]),</span><br><span class="line">                                            glb_input_column.OutputByStride(strides[<span class="number">3</span>]))</span><br><span class="line">          <span class="keyword">let</span> ifmap = <span class="keyword">new</span> tensor4d_segment(glb_input_batch, glb_input_channel, glb_input_row, glb_input_column)</span><br><span class="line">          <span class="keyword">let</span> c_pp_split_size = (<span class="built_in">uint</span>)Math.Ceiling(<span class="number">1.0</span> * glb_input_channel.Length / glb.n_ping_pong_split)</span><br><span class="line">          <span class="keyword">let</span> in_chan_split = SegmentByChunk((<span class="built_in">int</span>)glb_input_channel.Start, (<span class="built_in">int</span>)c_pp_split_size, (<span class="built_in">int</span>)glb_input_channel.End)</span><br><span class="line">          <span class="keyword">from</span> inst <span class="keyword">in</span> in_chan_split.Select(c_pp_split =&gt;</span><br><span class="line">          &#123;</span><br><span class="line">              <span class="comment">// load ifmap</span></span><br><span class="line">              <span class="comment">// 再次对c进行切分. 然后更新ifmap中c的segment.</span></span><br><span class="line">              tensor4d_segment ifmap_pp = <span class="keyword">new</span>(ifmap[<span class="number">0</span>], c_pp_split, ifmap[<span class="number">2</span>], ifmap[<span class="number">3</span>]);</span><br><span class="line">              <span class="comment">// 然后再把ifmap_pp的start全部减去一个base,因为这个segment起始地址是切分后的.</span></span><br><span class="line">              tensor4d_segment ifmap_pp_glb = glb_tensor_index_shift(ifmap_pp, ifmap);</span><br><span class="line"></span><br><span class="line">              <span class="built_in">bool</span> clear_qarg_ccr = <span class="literal">false</span>;</span><br><span class="line">              <span class="keyword">if</span> (input_type.IsQuantType())</span><br><span class="line">              &#123;</span><br><span class="line">                  <span class="comment">// action_updater.update_load_load_qarg(i_pp, ifmap_pp, ifmap_pp_glb, load_type);</span></span><br><span class="line">                  clear_qarg_ccr = <span class="literal">true</span>;</span><br><span class="line">              &#125;</span><br><span class="line"></span><br><span class="line">              CcrSet ifmap_pp_ccrset = <span class="keyword">new</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">              tensor4d_segment ifmap_pp_ld_glb = glb_tensor_index_shift(ifmap_pp, ifmap_pp);</span><br><span class="line">              <span class="comment">// action_updater.update_load_if(ifmap_pp_ccrset, ifmap_pp, ifmap_pp_glb, ifmap_pp_ld_glb, load_type, dt_bfloat16, false, i_pp, clear_qarg_ccr);</span></span><br><span class="line"></span><br><span class="line">              segment oc_pp_split = c_pp_split.OutputByStride(strides[<span class="number">1</span>]);</span><br><span class="line">              tensor4d_segment ofmap_pp = <span class="keyword">new</span>(ofmap[<span class="number">0</span>], oc_pp_split, ofmap[<span class="number">2</span>], ofmap[<span class="number">3</span>]);</span><br><span class="line">              tensor4d_segment ofmap_pp_glb = glb_tensor_index_shift(ofmap_pp, ofmap);</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> (output_type.IsQuantType())</span><br><span class="line">              &#123;</span><br><span class="line">                  <span class="comment">// action_updater.update_load_store_qarg(i_pp, ofmap_pp, ofmap_pp_glb, store_type);</span></span><br><span class="line">              &#125;</span><br><span class="line"></span><br><span class="line">              tensor4d_segment ofmap_pp_st = <span class="keyword">new</span>(ofmap_pp.Segments);</span><br><span class="line">              <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123; ofmap_pp_st[i] = ofmap_pp_st[i] <span class="keyword">with</span> &#123; Start = ofmap_pp_st[i].Start * (<span class="built_in">uint</span>)strides[i] &#125;; &#125;</span><br><span class="line">              tensor4d_segment ofmap_pp_st_glb = glb_tensor_index_shift(ofmap_pp_st, ifmap_pp);</span><br><span class="line">              <span class="comment">// action_updater.update_store_t(item_name::ifmap, ofmap_pp, ofmap_pp_glb, ofmap_pp_st_glb, store_type, of_buf_num, i_pp, i_pp);</span></span><br><span class="line">              <span class="keyword">return</span> <span class="keyword">new</span> Var(<span class="string">&quot;1&quot;</span>, AnyType.Default);</span><br><span class="line">          &#125;)</span><br><span class="line">    <span class="keyword">select</span> inst).ToSequential()</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h3 id="输入glb_tensor可以通过索引的方式进行tiling-而后构造指令.">2.
输入glb_tensor,可以通过索引的方式进行tiling, 而后构造指令.</h3>
<p>这个glb_tensor应该是一个可以多层级的数据结构,比如当前的sub_tensor可以求关于上一层tensor的地址偏移,然后也可以求关于父节点的内存偏移.
然后基于之前segment的逻辑,就可以把写出一个优雅的tensor处理逻辑.</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">from</span> in_seg <span class="keyword">in</span> <span class="title">compute_segment</span>(<span class="params">N,chunk_n</span>)</span></span><br><span class="line"><span class="function">  <span class="keyword">from</span> ic_seg <span class="keyword">in</span> <span class="title">compute_segment</span>(<span class="params">C,chunk_c</span>)</span></span><br><span class="line"><span class="function">    <span class="keyword">from</span> ih_seg <span class="keyword">in</span> <span class="title">compute_segment</span>(<span class="params">H,chunk_h</span>)</span></span><br><span class="line"><span class="function">      <span class="keyword">from</span> iw_seg <span class="keyword">in</span> <span class="title">compute_segment</span>(<span class="params">W,chunk_w</span>)</span></span><br><span class="line"><span class="function">        <span class="keyword">let</span> sub_input</span> = input[in_seg, ic_seg, ih_seg, iw_seg];</span><br><span class="line">        <span class="function"><span class="keyword">from</span> cpp_seg <span class="keyword">in</span> <span class="title">compute_segment</span>(<span class="params">ic_seg,pp_chunk</span>)</span></span><br><span class="line"><span class="function">          <span class="keyword">let</span> ping_input</span> = sub_input[..,cpp_seg,..,..]</span><br><span class="line">          <span class="comment">// ! can&#x27;t direct add Expr in here.</span></span><br><span class="line">          <span class="keyword">select</span> I.Load(ping_input.addr,ping_input.stride,....)</span><br></pre></td></tr></table></figure>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TVM/" rel="tag">TVM</a></li></ul></div><div class="post-nav"><a class="pre" href="/2022/01/10/glenside/">Pure Tensor Program Rewriting via Access Patterns</a><a class="next" href="/2021/11/18/torchsharp/">关于如何在M1上使用TorchSharp</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>