<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>神经网络量化-基本原理 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="https://unpkg.com/normalize.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/pure-min.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="https://unpkg.com/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="https://unpkg.com/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="https://unpkg.com/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="https://unpkg.com/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="https://unpkg.com/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">神经网络量化-基本原理</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">神经网络量化-基本原理</h1><div class="post-meta">2021-03-27<span> | </span><span class="category"><a href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">网络量化的基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">1.1.</span> <span class="toc-text">背景知识</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E7%9A%84%E9%87%8F%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">矩阵运算的量化</span></a></li></ol></li></ol></div></div><div class="post-content"><p>准备系统的学习一下神经网络量化，参考网络上的一些教程同时再次整理消化，这次首先对基本原理进行了解。</p>
<p>参考资料： <a
target="_blank" rel="noopener" href="https://www.cnblogs.com/jermmyhsu/p/13169254.html">jermmyxu的神经网络量化系列教程</a></p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torchvision.models.mobilenet <span class="keyword">import</span> mobilenet_v2</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">np.set_printoptions(precision=<span class="number">4</span>,suppress=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="网络量化的基本原理">网络量化的基本原理</h2>
<h3 id="背景知识">背景知识</h3>
<p>我们通常会将一张 uint8 类型、数值范围在 <span
class="math inline">\(0\sim255\)</span> 的图片归一成 float32
类型、数值范围在 <span class="math inline">\(0.0\sim1.0\)</span>
的张量，这个过程就是反量化。</p>
<p>最简单的量化公式是min_max_map，假设使用这里我们用<span
class="math inline">\(r\)</span>表示浮点实数，<span
class="math inline">\(q\)</span>表示量化后的定点整数。浮点和整型之间的换算公式为：
<span class="math display">\[q = round(\frac{r}{S}+Z)\]</span> <span
class="math display">\[r = S(q-Z)\]</span></p>
<p>其中，<span class="math inline">\(S\)</span> 是
scale，表示实数和整数之间的比例关系，<span
class="math inline">\(Z\)</span> 是 zero point，表示实数中的 0
经过量化后对应的整数，它们的计算方法为： <span class="math display">\[S
= \frac{r_{max}-r_{min}}{q_{max}-q_{min}}\]</span> <span
class="math display">\[Z = round(q_{max} -
\frac{r_{max}}{S})\]</span></p>
<p>首先我先找一个mobilenet，得到符合真实场景的参数均值和方差。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mbv2 = mobilenet_v2(pretrained=<span class="literal">True</span>)</span><br><span class="line">conv2d: nn.Conv2d = mbv2.features[<span class="number">13</span>].conv[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">R= conv2d.weight[:,:,<span class="number">0</span>,<span class="number">0</span>].detach().numpy()</span><br><span class="line">R.mean(), R.std()</span><br></pre></td></tr></table></figure>
<pre><code>(0.00031194088, 0.055000253)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = np.random.normal(loc=<span class="number">0.00031194088</span>,scale=<span class="number">0.055000253</span>,size=<span class="number">10</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcScaleZeroPoint</span>(<span class="params">min_val, max_val, num_bits=<span class="number">8</span></span>):</span><br><span class="line">    qmin = <span class="number">0.</span></span><br><span class="line">    qmax = <span class="number">2.</span> ** num_bits - <span class="number">1.</span></span><br><span class="line">    scale = <span class="built_in">float</span>((max_val - min_val) / (qmax - qmin))</span><br><span class="line">    zero_point = qmax - max_val / scale</span><br><span class="line">    <span class="keyword">if</span> zero_point &lt; qmin:</span><br><span class="line">        zero_point = qmin</span><br><span class="line">    <span class="keyword">elif</span> zero_point &gt; qmax:</span><br><span class="line">        zero_point = qmax</span><br><span class="line">    zero_point = <span class="built_in">int</span>(zero_point)</span><br><span class="line">    <span class="keyword">return</span> scale, zero_point</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quantFloat</span>(<span class="params">r,scale, zero_point, num_bits=<span class="number">8</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">round</span>(np.clip(r/scale + zero_point,<span class="number">0</span>,<span class="number">2</span>**num_bits-<span class="number">1</span>)).astype(<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">S,Z=calcScaleZeroPoint(r.<span class="built_in">min</span>(),r.<span class="built_in">max</span>())</span><br><span class="line">q=quantFloat(r,S,Z)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;r:&#x27;</span>,r,<span class="string">&#x27;\nS:&#x27;</span>,S,<span class="string">&#x27;\nZ:&#x27;</span>,Z,<span class="string">&#x27;\nq:&#x27;</span>,q)</span><br></pre></td></tr></table></figure>
<pre><code>r: [ 0.025   0.0205 -0.0064 -0.0634  0.0538  0.0205  0.0099  0.0321 -0.0302
 -0.0709] 
S: 0.0004889321179676555 
Z: 145 
q: [196 187 132  15 255 187 165 211  83   0]</code></pre>
<p>可以发现反量化的时候将出现一定的误差：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dequantUint8</span>(<span class="params">q, scale, zero_point</span>):</span><br><span class="line">    <span class="keyword">return</span> scale * (q - zero_point)</span><br><span class="line">re_r=dequantUint8(q,S,Z)</span><br><span class="line"><span class="built_in">print</span>(r-re_r)</span><br></pre></td></tr></table></figure>
<pre><code>[ 0.     -0.     -0.      0.0002 -0.     -0.0001  0.0002 -0.0002  0.0001
 -0.    ]</code></pre>
<h3 id="矩阵运算的量化">矩阵运算的量化</h3>
<p>假设<span
class="math inline">\(r_1,r_2\)</span>是两个矩阵,他们的维度分别为<span
class="math inline">\(N\times M,M\times K\)</span>,<span
class="math inline">\(r_3\)</span>作为两个矩阵的乘积结果,维度是<span
class="math inline">\(N \times K\)</span>,乘积计算过程如下:</p>
<p><span class="math display">\[
r_3^{n,k}=\sum_{m=1}^M r_1^{n,m}r_2^{m,k}
\]</span></p>
<p>设<span class="math inline">\(S_1,Z_1\)</span>对应<span
class="math inline">\(r_1\)</span>的量化因子,同理得到<span
class="math inline">\(S_2,Z_2\)</span>和<span
class="math inline">\(S_3,Z_3\)</span>,这时候将上述矩阵相乘公式的量化计算过程如下:
<span class="math display">\[
\begin{aligned}
S_3(q_3^{n,k}-Z_3)&amp;=\sum_{m=1}^{M}S_1(q_{1}^{n,m}-Z_1)S_2(q_2^{m,k}-Z_2)\\
S_3q_3^{n,k}&amp;=S_1S_2
\sum_{m=1}^{M}(q_{1}^{n,m}-Z_1)(q_2^{m,k}-Z_2)+S_3 Z_3\\
q_3^{n,k}&amp;=\frac{S_1S_2}{S_3}
\sum_{m=1}^{M}(q_{1}^{n,m}-Z_1)(q_2^{m,k}-Z_2)+Z_3
\end{aligned}
\]</span> 此时上述公式中只有<span
class="math inline">\(\frac{S_1S_2}{S_3}\)</span>部分是浮点运算(并且这个浮点数被大量实验证明了位于0-1之间),假设未经过重新量化的矩阵计算结果为<span
class="math inline">\(Q\)</span>,固定浮点数<span
class="math inline">\(\frac{S_1S_2}{S_3}\)</span>定义为<span
class="math inline">\(F\)</span>,那么对于一个浮点数可以利用一个技巧进行近似,然后可以将这个浮点计算转换为定点计算.即将这个浮点数用一个定点整数<span
class="math inline">\(F_0\)</span>*定点小数<span
class="math inline">\(2^{-n}\)</span>的方法来近似: <span
class="math display">\[
\begin{aligned}
q_3^{n,k}&amp;=F Q+Z_3\\
&amp;=2^{-n}F_0 Q+Z_3
\end{aligned}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_r_q_mat</span>(<span class="params">h,w,loc=<span class="number">0.001</span>,scale=<span class="number">0.004</span></span>):</span><br><span class="line">    r = np.random.normal(loc=loc,scale=scale,size=(h,w))</span><br><span class="line">    s,z=calcScaleZeroPoint(r.<span class="built_in">min</span>(),r.<span class="built_in">max</span>())</span><br><span class="line">    q = quantFloat(r,s,z)</span><br><span class="line">    <span class="keyword">return</span> r,q,s,z</span><br><span class="line">r_1,q_1,S_1,Z_1= get_r_q_mat(<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line">r_2,q_2,S_2,Z_2= get_r_q_mat(<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line">r_3 = r_1 @ r_2</span><br><span class="line">S_3,Z_3=calcScaleZeroPoint(r_3.<span class="built_in">min</span>(),r_3.<span class="built_in">max</span>())</span><br><span class="line">q_3 = quantFloat(r_3,S_3,Z_3)</span><br><span class="line">Q = (q_1-Z_1) @ (q_2-Z_2)</span><br><span class="line">F= (S_1*S_2)/S_3</span><br><span class="line"><span class="built_in">print</span>(F)</span><br></pre></td></tr></table></figure>
<pre><code>0.008822082202930992</code></pre>
<p>此时我们计算<span class="math inline">\(F\)</span>的定点数<span
class="math inline">\(F_0\)</span>和<span
class="math inline">\(2^{-n}\)</span>,其实就是计算哪一个<span
class="math inline">\(F_0\)</span>和<span
class="math inline">\(n\)</span>近似<span
class="math inline">\(F\)</span>的误差最小: <span
class="math display">\[
\begin{aligned}
    \text{argmin}_{n}&amp;abs(FQ-(2^{-n} \times F_0)Q,\ \  F_0 \in
[q_{min},q_{max}]\\
    F_0 &amp;= round(\frac{F}{2^{-n}}) = round(F * (1 &lt;&lt; n)) \\
    将F_0展开,并将2^{-n}转换为位运算&amp;: \\
    \text{argmin}_{n}&amp;abs(FQ-(round(F * (1 &lt;&lt; n))Q &gt;&gt;
n))
\end{aligned}
\]</span> 接下来给出一个确定<span
class="math inline">\(F_0\)</span>与<span
class="math inline">\(n\)</span>的代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_f_0</span>(<span class="params">F,Q,is_print=<span class="literal">True</span></span>):</span><br><span class="line">    mind=<span class="number">1e9</span></span><br><span class="line">    minn=-<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">16</span>):</span><br><span class="line">        F_0=<span class="built_in">int</span>(<span class="built_in">round</span>(F * (<span class="number">1</span>&lt;&lt;n)))</span><br><span class="line">        diff = <span class="built_in">abs</span>(F*Q - (<span class="built_in">int</span>(F_0*Q)&gt;&gt;n))</span><br><span class="line">        <span class="keyword">if</span> diff&lt;mind:</span><br><span class="line">            mind,minn=diff,n</span><br><span class="line">        <span class="keyword">if</span> is_print:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;n=<span class="subst">&#123;n&#125;</span>,F_0=<span class="subst">&#123;F_0&#125;</span>,diff=<span class="subst">&#123;diff&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(F * (<span class="number">1</span>&lt;&lt;minn))),minn</span><br><span class="line">F_0,n = get_f_0(F,<span class="built_in">int</span>(Q[<span class="number">0</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>n=0,F_0=0,diff=175.27712920783293
n=1,F_0=0,diff=175.27712920783293
n=2,F_0=0,diff=175.27712920783293
n=3,F_0=0,diff=175.27712920783293
n=4,F_0=0,diff=175.27712920783293
n=5,F_0=0,diff=175.27712920783293
n=6,F_0=1,diff=135.72287079216707
n=7,F_0=1,diff=19.277129207832928
n=8,F_0=2,diff=19.277129207832928
n=9,F_0=5,diff=19.722870792167072
n=10,F_0=9,diff=0.27712920783292816
n=11,F_0=18,diff=0.27712920783292816
n=12,F_0=36,diff=0.27712920783292816
n=13,F_0=72,diff=0.27712920783292816
n=14,F_0=145,diff=0.7228707921670718
n=15,F_0=289,diff=0.7228707921670718</code></pre>
<p>观察上述输出,可以发现在<span
class="math inline">\(n=10\)</span>的时候就可以得到较好的量化因子了,这样所有的运算就可以用定点的方式来计算了.</p>
<p>此时我们写出一个完整的例子，分别使用<span
class="math inline">\(q_3\)</span>的两种解量化方式来检查量化运算的精度损失有多大：</p>
$$
<span class="math display">\[\begin{aligned}
\text{deq\_r}_{3}^1 &amp;= dequant(q_3) \\

\text{deq\_r}_{3}^2 &amp;= dequant(F Q + Z_3) \\

\text{deq\_r}_{3}^3 &amp;= dequant(2^{-n} F_0 Q + Z_3)

\end{aligned}\]</span>
<p>$$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">deq_r_3_1=dequantUint8(q_3,S_3,Z_3)</span><br><span class="line">deq_r_3_2=dequantUint8(F*Q+Z_3,S_3,Z_3)-r_3</span><br><span class="line">deq_r_3_3=dequantUint8(np.right_shift(F_0*Q,n)+Z_3,S_3,Z_3)</span><br><span class="line"><span class="built_in">print</span>((deq_r_3_1-r_3).<span class="built_in">max</span>())</span><br><span class="line"><span class="built_in">print</span>((deq_r_3_2-r_3).<span class="built_in">max</span>())</span><br><span class="line"><span class="built_in">print</span>((deq_r_3_3-r_3).<span class="built_in">max</span>())</span><br></pre></td></tr></table></figure>
<pre><code>1.6667435495922793e-07
4.1159863929325536e-05
3.4088182772356416e-07</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">可以发现精度损失并不大，表明了当前的方法有用。</span><br></pre></td></tr></table></figure>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" rel="tag">神经网络量化</a></li></ul></div><div class="post-nav"><a class="pre" href="/2021/04/05/bin-search-template/">二分查找-统一框架</a><a class="next" href="/2021/01/21/leetcode/">leetcode刷题总结</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a> <a href="/tags/%E7%AE%97%E5%AD%90/" style="font-size: 15px;">算子</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/09/26/flashattn/">Flash Attention记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/08/28/chimera/">Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>