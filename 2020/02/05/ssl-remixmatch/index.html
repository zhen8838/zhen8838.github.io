<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>半监督学习：ReMixMatch | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">半监督学习：ReMixMatch</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">半监督学习：ReMixMatch</h1><div class="post-meta">2020-02-05<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 3.2k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 14</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>第九个算法<code>ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring</code>，这也是谷歌<code>MixMatch</code>的同一作者提出的，是对<code>MixMatch</code>的改进。</p>
<span id="more"></span>
<h1 id="算法理论">算法理论</h1>
<p>通过引入两个技术:<code>Distribution Alignment</code>和<code>Augmentation Anchoring</code>改进了<code>MixMatch</code>。</p>
<h2 id="distribution-alignment">Distribution Alignment</h2>
<p>分布对齐的目标是使无标签数据的预测汇总与提供的标签数据分布相匹配。这个概念是25年前的<code>Unsupervised classifiers, mutualinformation and’phantom targets</code>所引入的，但是在<code>ReMixMatch</code>之前还没有人在半监督学习中用过这个方法。</p>
<figure>
<img src="/2020/02/05/ssl-remixmatch/remixmatch-1.png"
alt="分布对齐.根据经验性的ground-truth类别分布除以未标记数据的平均预测的比例调整猜测标签的分布" />
<figcaption
aria-hidden="true">分布对齐.根据经验性的ground-truth类别分布除以未标记数据的平均预测的比例调整猜测标签的分布</figcaption>
</figure>
<p>半监督算法的主要目标是利用未标记数据提升模型性能，<code>bridle</code>等人首先提出一种这种直觉形式化的方法，最大化无标签数据的输入与输出间的互信息。将此操作公式化为如下，以下公式推导时，假设了<span
class="math inline">\(p(x),p(y)\)</span>相互独立则有<span
class="math inline">\(p(y) = \int p(x)p(y|x)\ dx\)</span>。：</p>
<p><span class="math display">\[
\begin{align}
\mathcal{I}(y ; x) &amp;=\iint p(y, x) \log \frac{p(y, x)}{p(y) p(x)}
\mathrm{d} y \mathrm{d} x\\
&amp;=\int p(x) \mathrm{d} x \int p(y | x) \log \frac{p(y | x)}{p(y)}
\mathrm{d} y\\
&amp;=\int p(x) \mathrm{d} x \int p(y | x) \log \frac{p(y | x)}{\int
p(x) p(y | x) \mathrm{d} x} \mathrm{d} y\\
&amp;=\mathbb{E}_{x}\left[\int p(y | x) \log \frac{p(y |
x)}{\mathbb{E}_{x}[p(y | x)]} \mathrm{d} y\right]\\
\text{离散化:}\\
&amp;=\mathbb{E}_{x}\left[\sum_{i=1}^{L} p\left(y_{i} | x\right) \log
\frac{p\left(y_{i} | x\right)}{\mathbb{E}_{x}\left[p\left(y_{i} |
x\right)\right]}\right]\\
&amp;=\mathbb{E}_{x}\left[\sum_{i=1}^{L} p\left(y_{i} | x\right) \log
p\left(y_{i} | x\right)\right]-\mathbb{E}_{x}\left[\sum_{i=1}^{L}
p\left(y_{i} | x\right) \log \mathbb{E}_{x}\left[p\left(y_{i} |
x\right)\right]\right]\\
&amp;=\mathbb{E}_{x}\left[\sum_{i=1}^{L} p\left(y_{i} | x\right) \log
p\left(y_{i} | x\right)\right]-\sum_{i=1}^{L}
\mathbb{E}_{x}\left[p\left(y_{i} | x\right)\right] \log
\mathbb{E}_{x}\left[p\left(y_{i} | x\right)\right]
\end{align}\tag{1}
\]</span> <span class="math display">\[
\begin{align}
&amp;=\mathcal{H}\left(\mathbb{E}_{x}\left[p_{\text {model }}(y | x ;
\theta)\right]\right)-\mathbb{E}_{x}\left[\mathcal{H}\left(p_{\text
{model }}(y | x ; \theta)\right)\right]
\end{align}\tag{2}
\]</span></p>
<p>其中<span
class="math inline">\(\mathcal{H}(\cdot)\)</span>为熵。其中公式2是熟悉的熵最小化目标，它简单的鼓励模型输出具有更低的熵(对当前类别标签置信度更高)。但其中公式1并未广泛使用，其目标是鼓励模型在整个训练集平均预测每个类别的频率相同，<code>bridle</code>等人称之为公平性。</p>
<p>在<code>MixMatch</code>中已经使用了<code>sharpening</code>函数使猜测标签的熵最小化。现在要通过互信息的概念引入<code>公平性</code>这一原则，注意目标<span
class="math inline">\(\mathcal{H}\left(\mathbb{E}_{x}\left[p_{\text
{model }}(y | x ;
\theta)\right]\right)\)</span>本来已经暗示了它应该以相同的频率预测每个标签，但如果数据集中的<span
class="math inline">\(p(y)\)</span>的分布并不是均匀的，那这个目标就不一定有效了。虽然可以按<code>batch</code>最小化这个目标，但是为了不引入更多的超参数，因此为了解决以上问题，引入了另外一种<code>公平性</code>形式<code>Distribution Alignment</code>。其过程如下：</p>
<p>训练过程中维持模型对未标记数据的预测结果的平均值<span
class="math inline">\(\tilde{p}(y)\)</span>,给定模型在未标记数据<span
class="math inline">\(u\)</span>上的预测为<span
class="math inline">\(q=P_{\text{model}}(y|u,\theta)\)</span>，我们将利用<span
class="math inline">\(\frac{p(y)}{\tilde{p}(y)}\)</span>作为比例缩放<span
class="math inline">\(q\)</span>，然后在重新放大到有效的概率分布区间：
<span
class="math inline">\(\tilde{q}=\text{Normalize}(q\times\frac{p(y)}{\tilde{p}(y)})\)</span>，其中<code>Normalize</code>为<span
class="math inline">\(\text{Normalize}(x)_i=\frac{x_i}{\sum_j
x_j}\)</span>。 然后我们使用<span
class="math inline">\(\tilde{q}\)</span>作为<span
class="math inline">\(u\)</span>的猜测标签，然后可以再用<code>sharpening</code>或其他的处理方式。实际操作中，将计算过去<code>128</code>个<code>batch</code>中无标签数据预测值的滑动平均作为<span
class="math inline">\(\tilde{p}(y)\)</span>，如果我们直接知道<span
class="math inline">\(\tilde{p}(y)\)</span>的某些先验分布，那么应该还可以更好。</p>
<h2 id="改进一致性正则化">改进一致性正则化</h2>
<p>论文中说，使用了最新提出<code>AutoAugment</code>数据增强算法来代替原本<code>MixMatch</code>中的数据弱增强看看能不能提高性能，但是发现训练并不能收敛。因此提出了一个解决方法<code>Augmentation Anchoring</code>，它的基本想法是将模型对弱增强的未标记图像的预测结果作为同一图像的强增强的猜测标签。</p>
<p>同时因为<code>AutoAugment</code>是使用强化学习策略来搜索的，需要对有监督模型做多次尝试。在半监督学习中难以做到，为了解决这个问题，提出了一个名为<code>CTAugment</code>的方法，使用控制理论的思想在线适应，而无需任何形式的基于强化学习的训练。</p>
<h3 id="augmentation-anchoring">Augmentation Anchoring</h3>
<p>我们假设带有<code>AutoAugment</code>的<code>MixMatch</code>不稳定的原因是<code>MixMatch</code>对<span
class="math inline">\(K\)</span>个的预测取了平均值。由于增强效果可能会导致不同的预测，因此其平均值可能不是有意义的目标，取而代之的是，给定一个未标记的输入<span
class="math inline">\(u\)</span>，我们首先通过对其应用弱增强来生成一个<code>Anchor</code>。然后使用<code>CTAugment</code>生成<span
class="math inline">\(K\)</span>个<span
class="math inline">\(u\)</span>的增强，然后将(经过<code>distribution alignment</code>和<code>sharpening</code>后的)猜测标签作为<span
class="math inline">\(K\)</span>个增强后的目标。</p>
<p><img src="/2020/02/05/ssl-remixmatch/remixmatch-2.png" /></p>
<p>在实验中发现，使用<code>Augmentation Anchoring</code>之后，可以直接使用交叉熵代替原本的<code>mse</code>损失，更易于实现，同时<span
class="math inline">\(K=2\)</span>即可取得不错的效果，当然<span
class="math inline">\(K&gt;8\)</span>效果更好。</p>
<h3 id="control-theory-augment">Control Theory Augment</h3>
<p>像<code>AutoAugment</code>一样，<code>CTAugment</code>均匀的随机采样要实施的变换，但是会在训练过程中动态推断每次变换的幅度大小。由于<code>CTAugment</code>具有不敏感的超参数，因此可以直接包含在半监督模型中。直观的，对于每个建议的参数，<code>CTAugment</code>都知道它将产生被分类正确标签的图像的概率，然后使用这些概率，仅对网络可忍受范围内的误差进行采样。这个过程在<code>FastAutoAugment</code>中被称为<code>density-matching</code>。</p>
<p>首先，<code>CTAugment</code>将每个变化的每个参数范围划分为数个分组，在开始训练时将每个分组的权重设置为<code>1</code>，然后令权重向量<span
class="math inline">\(m\)</span>向某些分组变化，这些权重决定了那些幅度级别是需要实施变化的。在每个训练<code>step</code>中，对于每个图像随机地均匀采样两个变换，用于图像增强。使用改变过的权重参数<span
class="math inline">\(\bar{m}\)</span>，其中${m}_i=m_i    
m_i&gt;0.8    {m}<em>i =0 <span
class="math inline">\(，否则使用\)</span>{m}<span
class="math inline">\(作为权重进行随机分类采样。为了更新权重，首先随机地对每个转换参数均匀的采样一个\)</span>m_i<span
class="math inline">\(，将结果转换应用于带标签样本\)</span>x<span
class="math inline">\(以获得增强版本\)</span>{x}<span
class="math inline">\(，然后测量模型的预测与标签的匹配程度为\)</span>-|p</em>{}(y|{x};)-p|<span
class="math inline">\(，每个采样权重的权重更新为\)</span>m_i=m_i+(1-)<span
class="math inline">\(，其中\)</span>$是固定的指数衰减超参数。</p>
<h3 id="综合">综合</h3>
<p>综合算法流程如下：</p>
<p><img src="/2020/02/05/ssl-remixmatch/remixmatch-3.png" /></p>
<p>主要是生成两个集合<span
class="math inline">\(\mathcal{X}&#39;\)</span>和<span
class="math inline">\(\mathcal{U}&#39;\)</span>，由增强后的带标记的有标签无标签数据<code>mixup</code>生成。<span
class="math inline">\(\mathcal{X}&#39;\)</span>和<span
class="math inline">\(\mathcal{U}&#39;\)</span>的标签与猜测标签根据模型预测输入到标准的交叉熵损失中。还有<span
class="math inline">\(\mathcal{U}_1\)</span>是由无标签数据经过单个强增强组成的，并且他的猜测标签没有应用<code>mixup</code>，<span
class="math inline">\(\mathcal{U}_1\)</span>是用在两个额外的损失项中，它能提供很大的改善。</p>
<p><code>Pre-mixup unlabeled loss</code>： 将<span
class="math inline">\(\mathcal{U}_1\)</span>的猜测标签和预测输入一个单独的交叉熵损失项。</p>
<p><code>Rotation loss</code>
：最近的结果表明，将自我监督学习的思想应用于半监督学习可以产生出色的性能(
Self-supervised semi-supervised
learning)。将这个想法通过旋转每个图像<span
class="math inline">\(\text{Rotate}(u,r) \in
\mathcal{U}_1\)</span>来整合，<span class="math inline">\(r \sim
{0,90,180,270}\)</span>，然后要求模型将旋转量预测为四类分类问题。</p>
<p><span class="math display">\[
\begin{align}
\begin{aligned}
\sum_{x, p \in \mathcal{X}^{\prime}} \mathrm{H}\left(p, p_{\text {model
}}(y | x ; \theta)\right)+\lambda_{\mathcal{U}} \sum_{u, q \in
\mathcal{U}^{\prime}} \mathrm{H}\left(q, p_{\text {model }}(y | u ;
\theta)\right) \\
+\lambda_{\hat{u}_{1}} \sum_{u, q \in \hat{\mathcal{U}}_{1}}
\mathrm{H}\left(q, p_{\text {model }}(y | u ; \theta)\right)+\lambda_{r}
\sum_{u \in \hat{\mathcal{U}}_{1}} \mathrm{H}\left(r, p_{\text {model
}}(r | \text { Rotate }(u, r) ; \theta)\right)
\end{aligned}
\end{align}
\]</span></p>
<p>根据消融测试结果：</p>
<p><img src="/2020/02/05/ssl-remixmatch/remixmatch-4.png" /></p>
<p>如果没有弱增强和强增强间的<code>augment anchoring</code>错误率就立马上升非常多。其次是将<code>guess label</code>的损失从交叉熵变成<code>l2 loss</code>，不过这里我挺奇怪的，之前其他的算法都是说<code>l2 loss</code>的约束性更大，效果会更好。</p>
<h1 id="代码">代码</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">classifier_rot</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># 旋转目标分类器</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;classify_rot&#x27;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        <span class="keyword">return</span> tf.layers.dense(x, <span class="number">4</span>, kernel_initializer=tf.glorot_normal_initializer())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">guess_label</span>(<span class="params">self, logits_y, p_data, p_model, T, use_dm, redux, **kwargs</span>):</span><br><span class="line">    <span class="keyword">del</span> kwargs</span><br><span class="line">    <span class="keyword">if</span> redux == <span class="string">&#x27;swap&#x27;</span>:</span><br><span class="line">        p_model_y = tf.concat([tf.nn.softmax(x) <span class="keyword">for</span> x <span class="keyword">in</span> logits_y[<span class="number">1</span>:] + logits_y[:<span class="number">1</span>]], axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> redux == <span class="string">&#x27;mean&#x27;</span>:</span><br><span class="line">        p_model_y = <span class="built_in">sum</span>(tf.nn.softmax(x) <span class="keyword">for</span> x <span class="keyword">in</span> logits_y) / <span class="built_in">len</span>(logits_y)</span><br><span class="line">        p_model_y = tf.tile(p_model_y, [<span class="built_in">len</span>(logits_y), <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">elif</span> redux == <span class="string">&#x27;1st&#x27;</span>:</span><br><span class="line">        p_model_y = tf.nn.softmax(logits_y[<span class="number">0</span>])</span><br><span class="line">        p_model_y = tf.tile(p_model_y, [<span class="built_in">len</span>(logits_y), <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算目标分布</span></span><br><span class="line">    <span class="comment"># 默认是使用分布match的</span></span><br><span class="line">    <span class="keyword">if</span> use_dm:</span><br><span class="line">        p_ratio = (<span class="number">1e-6</span> + p_data) / (<span class="number">1e-6</span> + p_model)</span><br><span class="line">        p_weighted = p_model_y * p_ratio</span><br><span class="line">        p_weighted /= tf.reduce_sum(p_weighted, axis=<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        p_weighted = p_model_y</span><br><span class="line">    <span class="comment"># 再进行锐化</span></span><br><span class="line">    p_target = tf.<span class="built_in">pow</span>(p_weighted, <span class="number">1.</span> / T)</span><br><span class="line">    p_target /= tf.reduce_sum(p_target, axis=<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> EasyDict(p_target=p_target, p_model=p_model_y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">self, batch, lr, wd, beta, w_kl, w_match, w_rot, K, use_xe, warmup_kimg=<span class="number">1024</span>, T=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">          mixmode=<span class="string">&#x27;xxy.yxy&#x27;</span>, dbuf=<span class="number">128</span>, ema=<span class="number">0.999</span>, **kwargs</span>):</span><br><span class="line">    hwc = [self.dataset.height, self.dataset.width, self.dataset.colors]</span><br><span class="line">    xt_in = tf.placeholder(tf.float32, [batch] + hwc, <span class="string">&#x27;xt&#x27;</span>)  <span class="comment"># For training</span></span><br><span class="line">    x_in = tf.placeholder(tf.float32, [<span class="literal">None</span>] + hwc, <span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    <span class="comment"># K个强增强 + 1一个弱增强</span></span><br><span class="line">    y_in = tf.placeholder(tf.float32, [batch, K + <span class="number">1</span>] + hwc, <span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    l_in = tf.placeholder(tf.int32, [batch], <span class="string">&#x27;labels&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    w_match *= tf.clip_by_value(tf.cast(self.step, tf.float32) / (warmup_kimg &lt;&lt; <span class="number">10</span>), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    lrate = tf.clip_by_value(tf.to_float(self.step) / (FLAGS.train_kimg &lt;&lt; <span class="number">10</span>), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    lr *= tf.cos(lrate * (<span class="number">7</span> * np.pi) / (<span class="number">2</span> * <span class="number">8</span>))</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;monitors/lr&#x27;</span>, lr)</span><br><span class="line">    augment = layers.MixMode(mixmode)</span><br><span class="line">    <span class="comment"># 使用多gpu并行分类</span></span><br><span class="line">    gpu = utils.get_gpu()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">classifier_to_gpu</span>(<span class="params">x, **kw</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.device(<span class="built_in">next</span>(gpu)):</span><br><span class="line">            <span class="keyword">return</span> self.classifier(x, **kw, **kwargs).logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_rotate</span>(<span class="params">x</span>):</span><br><span class="line">        b4 = batch // <span class="number">4</span></span><br><span class="line">        x, xt = x[:<span class="number">2</span> * b4], tf.transpose(x[<span class="number">2</span> * b4:], [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">        l = np.zeros(b4, np.int32)</span><br><span class="line">        l = tf.constant(np.concatenate([l, l + <span class="number">1</span>, l + <span class="number">2</span>, l + <span class="number">3</span>], axis=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> tf.concat([x[:b4], x[b4:, ::-<span class="number">1</span>, ::-<span class="number">1</span>], xt[:b4, ::-<span class="number">1</span>], xt[b4:, :, ::-<span class="number">1</span>]], axis=<span class="number">0</span>), l</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 当前估计标签的分布滑动平均值</span></span><br><span class="line">    p_model = layers.PMovingAverage(<span class="string">&#x27;p_model&#x27;</span>, self.nclass, dbuf)</span><br><span class="line">    <span class="comment"># 当前标签的分布滑动平均值，用于绘图观察真实标签的分布情况</span></span><br><span class="line">    p_target = layers.PMovingAverage(<span class="string">&#x27;p_target&#x27;</span>, self.nclass, dbuf)  <span class="comment"># Rectified distribution (only for plotting)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 推断真实无标签数据的分布</span></span><br><span class="line">    p_data = layers.PData(self.dataset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 旋转数据并进行分类</span></span><br><span class="line">    <span class="keyword">if</span> w_rot &gt; <span class="number">0</span>:</span><br><span class="line">        rot_y, rot_l = random_rotate(y_in[:, <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">with</span> tf.device(<span class="built_in">next</span>(gpu)):</span><br><span class="line">            rot_logits = self.classifier_rot(self.classifier(rot_y, training=<span class="literal">True</span>, **kwargs).embeds)</span><br><span class="line">        loss_rot = tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(rot_l, <span class="number">4</span>), logits=rot_logits)</span><br><span class="line">        loss_rot = tf.reduce_mean(loss_rot)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;losses/rot&#x27;</span>, loss_rot)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_rot = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 这里是对于guess label处理过程，因为有多个y的预测值，可以选择其一也可以平均他。</span></span><br><span class="line">    <span class="keyword">if</span> kwargs[<span class="string">&#x27;redux&#x27;</span>] == <span class="string">&#x27;1st&#x27;</span> <span class="keyword">and</span> w_kl &lt;= <span class="number">0</span>:</span><br><span class="line">        logits_y = [classifier_to_gpu(y_in[:, <span class="number">0</span>], training=<span class="literal">True</span>)] * (K + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">elif</span> kwargs[<span class="string">&#x27;redux&#x27;</span>] == <span class="string">&#x27;1st&#x27;</span>:</span><br><span class="line">        logits_y = [classifier_to_gpu(y_in[:, i], training=<span class="literal">True</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        logits_y += logits_y[:<span class="number">1</span>] * (K - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logits_y = [classifier_to_gpu(y_in[:, i], training=<span class="literal">True</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K + <span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># 做augment anchor损失</span></span><br><span class="line">    guess = self.guess_label(logits_y, p_data(), p_model(), T=T, **kwargs)</span><br><span class="line">    ly = tf.stop_gradient(guess.p_target)</span><br><span class="line">    <span class="keyword">if</span> w_kl &gt; <span class="number">0</span>:</span><br><span class="line">        w_kl *= tf.clip_by_value(tf.cast(self.step, tf.float32) / (warmup_kimg &lt;&lt; <span class="number">10</span>), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        loss_kl = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ly[:batch], logits=logits_y[<span class="number">1</span>])</span><br><span class="line">        loss_kl = tf.reduce_mean(loss_kl)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;losses/kl&#x27;</span>, loss_kl)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_kl = <span class="number">0</span></span><br><span class="line">    <span class="keyword">del</span> logits_y</span><br><span class="line">    <span class="comment"># mixup</span></span><br><span class="line">    lx = tf.one_hot(l_in, self.nclass)</span><br><span class="line">    xy, labels_xy = augment([xt_in] + [y_in[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K + <span class="number">1</span>)], [lx] + tf.split(ly, K + <span class="number">1</span>),</span><br><span class="line">                            [beta, beta])</span><br><span class="line">    x, y = xy[<span class="number">0</span>], xy[<span class="number">1</span>:]</span><br><span class="line">    labels_x, labels_y = labels_xy[<span class="number">0</span>], tf.concat(labels_xy[<span class="number">1</span>:], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">del</span> xy, labels_xy</span><br><span class="line"></span><br><span class="line">    batches = layers.interleave([x] + y, batch)</span><br><span class="line">    logits = [classifier_to_gpu(yi, training=<span class="literal">True</span>) <span class="keyword">for</span> yi <span class="keyword">in</span> batches[:-<span class="number">1</span>]]</span><br><span class="line">    skip_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line">    logits.append(classifier_to_gpu(batches[-<span class="number">1</span>], training=<span class="literal">True</span>))</span><br><span class="line">    post_ops = [v <span class="keyword">for</span> v <span class="keyword">in</span> tf.get_collection(tf.GraphKeys.UPDATE_OPS) <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> skip_ops]</span><br><span class="line">    logits = layers.interleave(logits, batch)</span><br><span class="line">    logits_x = logits[<span class="number">0</span>]</span><br><span class="line">    logits_y = tf.concat(logits[<span class="number">1</span>:], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">del</span> batches, logits</span><br><span class="line">    <span class="comment"># 分类损失</span></span><br><span class="line">    loss_xe = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_x, logits=logits_x)</span><br><span class="line">    loss_xe = tf.reduce_mean(loss_xe)</span><br><span class="line">    <span class="keyword">if</span> use_xe:</span><br><span class="line">        loss_xeu = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_y, logits=logits_y)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_xeu = tf.square(labels_y - tf.nn.softmax(logits_y))</span><br><span class="line">    loss_xeu = tf.reduce_mean(loss_xeu)</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;losses/xe&#x27;</span>, loss_xe)</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;losses/%s&#x27;</span> % (<span class="string">&#x27;xeu&#x27;</span> <span class="keyword">if</span> use_xe <span class="keyword">else</span> <span class="string">&#x27;l2u&#x27;</span>), loss_xeu)</span><br><span class="line">    self.distribution_summary(p_data(), p_model(), p_target())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L2 regularization</span></span><br><span class="line">    loss_wd = <span class="built_in">sum</span>(tf.nn.l2_loss(v) <span class="keyword">for</span> v <span class="keyword">in</span> utils.model_vars(<span class="string">&#x27;classify&#x27;</span>) <span class="keyword">if</span> <span class="string">&#x27;kernel&#x27;</span> <span class="keyword">in</span> v.name)</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;losses/wd&#x27;</span>, loss_wd)</span><br><span class="line"></span><br><span class="line">    ema = tf.train.ExponentialMovingAverage(decay=ema)</span><br><span class="line">    ema_op = ema.apply(utils.model_vars())</span><br><span class="line">    ema_getter = functools.partial(utils.getter_ema, ema)</span><br><span class="line">    post_ops.extend([ema_op,</span><br><span class="line">                     p_model.update(guess.p_model),</span><br><span class="line">                     p_target.update(guess.p_target)])</span><br><span class="line">    <span class="keyword">if</span> p_data.has_update:</span><br><span class="line">        post_ops.append(p_data.update(lx))</span><br><span class="line"></span><br><span class="line">    train_op = tf.train.MomentumOptimizer(lr, <span class="number">0.9</span>, use_nesterov=<span class="literal">True</span>).minimize(</span><br><span class="line">        loss_xe + w_kl * loss_kl + w_match * loss_xeu + w_rot * loss_rot + wd * loss_wd,</span><br><span class="line">        colocate_gradients_with_ops=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([train_op]):</span><br><span class="line">        train_op = tf.group(*post_ops)</span><br></pre></td></tr></table></figure>
<h1 id="实验">实验</h1>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">半监督学习</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/02/06/ssl-fixmatch/">半监督学习：FixMatch</a><a class="next" href="/2020/02/04/ssl-uda/">半监督学习：Unsupervised Data Augmentation</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx_en/">Explore AMX instructions: Unlock the performance of Apple Silicon</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/13/macos-bundle/">macos中bundle的使用</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>