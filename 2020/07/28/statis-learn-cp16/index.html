<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>统计学习方法:马尔科夫链蒙特卡洛法 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="https://unpkg.com/normalize.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/pure-min.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="https://unpkg.com/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="https://unpkg.com/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="https://unpkg.com/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="https://unpkg.com/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="https://unpkg.com/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法:马尔科夫链蒙特卡洛法</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法:马尔科夫链蒙特卡洛法</h1><div class="post-meta">2020-07-28<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.3k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 11</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%8E%A5%E5%8F%97-%E6%8B%92%E7%BB%9D%E6%B3%95%E9%87%87%E6%A0%B7"><span class="toc-number">1.</span> <span class="toc-text">蒙特卡洛接受-拒绝法采样</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE"><span class="toc-number">2.</span> <span class="toc-text">马尔科夫链</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#metropolis-hastings%E9%87%87%E6%A0%B7"><span class="toc-number">3.</span> <span class="toc-text">Metropolis-Hastings采样</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gibbs%E9%87%87%E6%A0%B7"><span class="toc-number">4.</span> <span class="toc-text">Gibbs采样</span></a></li></ol></div></div><div class="post-content"><p>蒙特卡洛法是对概率模型进行抽样来近似数值计算的方法.马尔科夫链蒙特卡洛法就是以<strong>马尔科夫链</strong>作为概率模型的蒙特卡洛法.</p>
<p>我的理解是传统的蒙特卡洛法需要进行采样,但他的采样还是需要依赖于目标分布<span
class="math inline">\(p(x)\)</span>,当目标分布<span
class="math inline">\(p(x)\)</span>是一个多元函数,或者概率密度函数是奇怪的分布,或者内部分量不独立时,总之就是难以直接采样时,引入<strong>一个满足遍历定理的马尔科夫链</strong>,让他的平稳分布就是目标分布<span
class="math inline">\(p(x)\)</span>,接下来我们利用<strong>马尔科夫链</strong>生成许多样本,生成的样本数量越大,那么这些样本就接近于直接抽样的结果.解决了难以直接抽样的问题.</p>
<span id="more"></span>
<h1 id="蒙特卡洛接受-拒绝法采样">蒙特卡洛接受-拒绝法采样</h1>
<p>原理书本上都有,我这里给出一个具体的例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats._discrete_distns <span class="keyword">import</span> binom</span><br><span class="line"><span class="keyword">from</span> scipy.stats._continuous_distns <span class="keyword">import</span> beta, norm</span><br><span class="line"><span class="keyword">from</span> scipy.stats._continuous_distns <span class="keyword">import</span> uniform</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;STZhongsong&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">q_x = uniform</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_x</span>(<span class="params">x</span>):</span><br><span class="line">  <span class="keyword">return</span> x * np.cos(<span class="number">71</span> * x) + np.sin(<span class="number">13</span> * x) + <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">point = <span class="number">0.75</span></span><br><span class="line">c = np.<span class="built_in">max</span>(p_x(x))</span><br><span class="line">upper = c * q_x.pdf(point)</span><br><span class="line">plt.plot(x, c * q_x.pdf(x), label=<span class="string">&#x27;$cq(x)$&#x27;</span>)</span><br><span class="line">plt.plot(x, p_x(x), label=<span class="string">&#x27;$p(x)$&#x27;</span>)</span><br><span class="line">plt.arrow(point, <span class="number">0</span>, <span class="number">0</span>, p_x(point), linewidth=<span class="number">1</span>,</span><br><span class="line">          head_width=<span class="number">0.03</span>, head_length=<span class="number">0.01</span>, fc=<span class="string">&#x27;g&#x27;</span>, ec=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.arrow(point, upper, <span class="number">0</span>, -(upper - p_x(point)), linewidth=<span class="number">1</span>,</span><br><span class="line">          head_width=<span class="number">0.03</span>, head_length=<span class="number">0.01</span>, fc=<span class="string">&#x27;r&#x27;</span>, ec=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.text(point + <span class="number">.05</span>, <span class="number">2.</span>, <span class="string">&#x27;Reject&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.text(point + <span class="number">.05</span>, <span class="number">0.75</span>, <span class="string">&#x27;Accept&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;接受-拒绝抽样示意图&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">n = <span class="number">500000</span></span><br><span class="line">sample_x = q_x.rvs(size=n)<span class="comment"># 从均匀分布中采样x</span></span><br><span class="line">u = uniform.rvs(size=n)  <span class="comment"># 这里采样u作为比例进行计算</span></span><br><span class="line">v = sample_x[u &lt;= (p_x(sample_x) / (c * q_x.pdf(sample_x)))]  <span class="comment"># v为接受的样本</span></span><br><span class="line"></span><br><span class="line">hist, bin_edges = np.histogram(v, bins=<span class="number">100</span>, normed=<span class="literal">True</span>)</span><br><span class="line">factor = <span class="number">2</span> <span class="comment"># 这个参数本来应该是通过p(x)的cdf计算得到的,我这里偷懒了</span></span><br><span class="line">bin_centers = (bin_edges[:-<span class="number">1</span>] + bin_edges[<span class="number">1</span>:]) / <span class="number">2.</span></span><br><span class="line">plt.step(bin_centers, hist * factor, linewidth=<span class="number">2</span>, label=<span class="string">&#x27;sampling&#x27;</span>)</span><br><span class="line">plt.plot(x, c * q_x.pdf(x), label=<span class="string">&#x27;$cq(x)$&#x27;</span>)</span><br><span class="line">plt.plot(x, p_x(x), label=<span class="string">&#x27;$p(x)$&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">f&#x27;接受-拒绝抽样 接受率<span class="subst">&#123;np.size(v)/n:<span class="number">.3</span>f&#125;</span>&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>当我给定目标分布为<span
class="math inline">\(p(x)=x\cos(71x)+\sin(13*x)+2\)</span>,建议分布为<span
class="math inline">\(q(x)\sim U(0,1)\)</span>,<span
class="math inline">\(c\)</span>为目标分布大最大值,抽样的示意图如下所示:</p>
<p><img src="/2020/07/28/statis-learn-cp16/mcmc_accept_1.png" /></p>
<p>根据书中的流程进行编码得到抽样结果如下,因为我这个目标分布是随便定义的,他的累积概率最终不为1,因此在绘制统计图的时候需要乘上一个系数.</p>
<p><img src="/2020/07/28/statis-learn-cp16/mcmc_accept_2.png" /></p>
<h1 id="马尔科夫链">马尔科夫链</h1>
<p>之前隐马尔科夫模型其实已经讲到了,但是那边讲的并不详细.书本上在这一章详细介绍了马尔科夫链.我这里也给出一个简单的例子,假设我们有三个岛屿,岛屿上的人口初始分布不同,有一个转移矩阵表示了每年三个岛屿人口迁移概率,经过数年迭代之后到达<strong>平稳分布</strong>,中间的状态称为<strong>燃烧期</strong>:
<span class="math display">\[
T=\begin{bmatrix}
    0.9&amp; 0.05&amp; 0.05\\
    0.1&amp; 0.8&amp; 0.1\\
    0.04&amp; 0.01&amp; 0.95
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;STZhongsong&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"></span><br><span class="line">A = np.array([</span><br><span class="line">    [<span class="number">0.9</span>, <span class="number">0.05</span>, <span class="number">0.05</span>],</span><br><span class="line">    [<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>],</span><br><span class="line">    [<span class="number">0.04</span>, <span class="number">0.01</span>, <span class="number">0.95</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">300000</span>, <span class="number">400000</span>, <span class="number">100000</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xs = [x]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">80</span>):</span><br><span class="line">  xs.append(xs[i] @ A)</span><br><span class="line"></span><br><span class="line">xs = np.array(xs)</span><br><span class="line">plt.plot(xs[:, <span class="number">0</span>], label=<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">plt.plot(xs[:, <span class="number">1</span>], label=<span class="string">&#x27;B&#x27;</span>)</span><br><span class="line">plt.plot(xs[:, <span class="number">2</span>], label=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;马尔科夫链转移示意图&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/07/28/statis-learn-cp16/markov_chain.png" /></p>
<h1 id="metropolis-hastings采样">Metropolis-Hastings采样</h1>
<p>我这里给出一个典型的例子,就是使用Metropolis-Hastings采样方法从参数的先验分布与对应的似然分布得到数据的后验分布.即:
<span class="math display">\[
\begin{aligned}
P(\theta|y)&amp;\propto P(y|\theta)P(\theta)\\
\text{假设如下:}&amp;\\
P(\theta)&amp;=Be(\alpha,\beta)\\
P(y|\theta)&amp;=Bin(n,k,\theta)\\
T&amp;\sim N(0,\sigma)
\end{aligned}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm, binom, beta, uniform</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;STZhongsong&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>(<span class="params">like: binom, prior: beta, n, h, theta</span>):</span><br><span class="line">  <span class="keyword">if</span> theta &lt; <span class="number">0</span> <span class="keyword">or</span> theta &gt; <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> like(n, theta).pmf(h) * prior.pdf(theta)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">h = <span class="number">61</span></span><br><span class="line">a = <span class="number">10</span></span><br><span class="line">b = <span class="number">10</span></span><br><span class="line">like = binom</span><br><span class="line">prior = beta(a, b)</span><br><span class="line">sigma = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">naccept = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">niters = <span class="number">10000</span></span><br><span class="line">thetas = np.zeros(niters + <span class="number">1</span>)</span><br><span class="line">thetas[<span class="number">0</span>] = <span class="number">0.1</span>  <span class="comment"># 设定初始参数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(niters):</span><br><span class="line">  <span class="comment"># 以当前状态下,转移矩阵为N(0,sigma)</span></span><br><span class="line">  theta_p = norm(thetas[i], sigma).rvs()</span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  rho = <span class="built_in">min</span>(<span class="number">1</span>, target(like, prior, n, h, theta_p) /</span><br><span class="line">            target(like, prior, n, h, thetas[i]))</span><br><span class="line">  u = np.random.uniform()</span><br><span class="line">  <span class="keyword">if</span> u &lt; rho:</span><br><span class="line">    naccept += <span class="number">1</span></span><br><span class="line">    thetas[i + <span class="number">1</span>] = theta_p</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    thetas[i + <span class="number">1</span>] = thetas[i]</span><br><span class="line">nmcmc = <span class="built_in">len</span>(thetas) // <span class="number">2</span>  <span class="comment"># 为了尽量选取平稳状态的采样值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">200</span>)</span><br><span class="line">true_posterior = prior.pdf(x) * like(n, x).pmf(h)  <span class="comment"># 先验*似然</span></span><br><span class="line">true_posterior /= (np.<span class="built_in">sum</span>(true_posterior) / np.size(true_posterior))</span><br><span class="line">plt.hist(thetas[nmcmc:], <span class="number">80</span>, density=<span class="literal">True</span>, label=<span class="string">&#x27;posterior&#x27;</span>)</span><br><span class="line">plt.hist(prior.rvs(nmcmc), <span class="number">80</span>, density=<span class="literal">True</span>, label=<span class="string">&#x27;prior&#x27;</span>)</span><br><span class="line">plt.plot(x, true_posterior, label=<span class="string">&#x27;true posterior&#x27;</span>, c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">f&quot;采样效率 = <span class="subst">&#123;naccept / niters:<span class="number">.3</span>f&#125;</span>&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; 收敛状态评估 &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mh_coin</span>(<span class="params">niters, init_theta</span>):</span><br><span class="line">  thetas = np.zeros(niters + <span class="number">1</span>)</span><br><span class="line">  thetas[<span class="number">0</span>] = init_theta  <span class="comment"># 设定初始参数</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(niters):</span><br><span class="line">    <span class="comment"># 以当前状态下,转移矩阵为N(0,sigma)</span></span><br><span class="line">    theta_p = norm(thetas[i], sigma).rvs()</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    rho = <span class="built_in">min</span>(<span class="number">1</span>, target(like, prior, n, h, theta_p) /</span><br><span class="line">              target(like, prior, n, h, thetas[i]))</span><br><span class="line">    u = np.random.uniform()</span><br><span class="line">    <span class="keyword">if</span> u &lt; rho:</span><br><span class="line">      thetas[i + <span class="number">1</span>] = theta_p</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      thetas[i + <span class="number">1</span>] = thetas[i]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> thetas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">thetass = [mh_coin(<span class="number">100</span>, i) <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0.1</span>, <span class="number">1.1</span>, <span class="number">0.2</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> thetas, init <span class="keyword">in</span> <span class="built_in">zip</span>(thetass, np.arange(<span class="number">0.1</span>, <span class="number">1.1</span>, <span class="number">0.2</span>)):</span><br><span class="line">  plt.plot(thetas, <span class="string">&#x27;-&#x27;</span>, label=<span class="string">f&#x27;init=<span class="subst">&#123;init:<span class="number">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">f&quot;马尔科夫链收敛状态评估&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>经过采样后我们统计采样结果的分布,可以发现和后验概率分布相同.不过可以看到他的接受率并不高.</p>
<p><img src="/2020/07/28/statis-learn-cp16/metro_hastings_1.png" /></p>
<p>同时重复以上过程,我们可以发现进入马尔科夫链进入平稳分布的速度还是比较快的.</p>
<p><img src="/2020/07/28/statis-learn-cp16/metro_hastings_2.png" /></p>
<h1 id="gibbs采样">Gibbs采样</h1>
<p>这里我暂时没想明白,如果说依次更新参数,当如果两个参数是独立的时候..</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm, binom, beta, uniform, bernoulli, gaussian_kde, multivariate_normal</span><br><span class="line"><span class="keyword">from</span> toolz <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;STZhongsong&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">binom2</span>(<span class="params">p1, p2, k1, k2, N1, N2</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot; 二维伯努利分布 &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">return</span> binom.pmf(k1, N1, p1) * binom.pmf(k2, N2, p2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_thetas</span>(<span class="params">xmin, xmax, n</span>):</span><br><span class="line">  xs = np.linspace(xmin, xmax, n)</span><br><span class="line">  widths = (xs[<span class="number">1</span>:] - xs[:-<span class="number">1</span>]) / <span class="number">2.0</span></span><br><span class="line">  thetas = xs[:-<span class="number">1</span>] + widths</span><br><span class="line">  <span class="keyword">return</span> thetas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_plots</span>(<span class="params">X, Y, prior, likelihood, posterior, projection=<span class="literal">None</span></span>):</span><br><span class="line">  fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, subplot_kw=<span class="built_in">dict</span>(</span><br><span class="line">      projection=projection), figsize=(<span class="number">12</span>, <span class="number">3</span>))</span><br><span class="line">  <span class="keyword">if</span> projection == <span class="string">&#x27;3d&#x27;</span>:</span><br><span class="line">    ax[<span class="number">0</span>].plot_surface(X, Y, prior, alpha=<span class="number">0.3</span>, cmap=plt.cm.jet)</span><br><span class="line">    ax[<span class="number">1</span>].plot_surface(X, Y, likelihood, alpha=<span class="number">0.3</span>, cmap=plt.cm.jet)</span><br><span class="line">    ax[<span class="number">2</span>].plot_surface(X, Y, posterior, alpha=<span class="number">0.3</span>, cmap=plt.cm.jet)</span><br><span class="line">    <span class="keyword">for</span> ax_ <span class="keyword">in</span> ax:</span><br><span class="line">      ax_._axis3don = <span class="literal">False</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    ax[<span class="number">0</span>].contour(X, Y, prior, cmap=plt.cm.jet)</span><br><span class="line">    ax[<span class="number">1</span>].contour(X, Y, likelihood, cmap=plt.cm.jet)</span><br><span class="line">    ax[<span class="number">2</span>].contour(X, Y, posterior, cmap=plt.cm.jet)</span><br><span class="line">  ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Prior&#x27;</span>)</span><br><span class="line">  ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Likelihood&#x27;</span>)</span><br><span class="line">  ax[<span class="number">2</span>].set_title(<span class="string">&#x27;Posteior&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">thetas1 = make_thetas(<span class="number">0</span>, <span class="number">1</span>, <span class="number">101</span>)</span><br><span class="line">thetas2 = make_thetas(<span class="number">0</span>, <span class="number">1</span>, <span class="number">101</span>)</span><br><span class="line">X, Y = np.meshgrid(thetas1, thetas2)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; 先验分布参数 &quot;&quot;&quot;</span></span><br><span class="line">a = <span class="number">2</span></span><br><span class="line">b = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; 似然分布参数 &quot;&quot;&quot;</span></span><br><span class="line">k1 = <span class="number">11</span></span><br><span class="line">N1 = <span class="number">14</span></span><br><span class="line">k2 = <span class="number">7</span></span><br><span class="line">N2 = <span class="number">14</span></span><br><span class="line"></span><br><span class="line">prior = beta(a, b).pdf(X) * beta(a, b).pdf(Y)</span><br><span class="line">likelihood = binom2(X, Y, k1, k2, N1, N2)</span><br><span class="line">posterior = beta(a + k1, b + N1 - k1).pdf(X) * beta(a + k2, b + N2 - k2).pdf(Y)</span><br><span class="line">make_plots(X, Y, prior, likelihood, posterior)</span><br><span class="line">plt.title(<span class="string">f&quot;原始分布&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; M-H采样 &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prior</span>(<span class="params">theta1, theta2</span>): <span class="keyword">return</span> beta(a, b).pdf(theta1) * beta(a, b).pdf(theta2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lik = partial(binom2, k1=k1, k2=k2, N1=N1, N2=N2)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>(<span class="params">theta1, theta2</span>): <span class="keyword">return</span> prior(theta1, theta2) * lik(theta1, theta2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sigma = np.diag([<span class="number">0.2</span>, <span class="number">0.2</span>])</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">proposal</span>(<span class="params">theta</span>): <span class="keyword">return</span> multivariate_normal(theta, sigma).rvs()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">metro_hastings</span>(<span class="params">niters: <span class="built_in">int</span>, burnin: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                   theta: np.ndarray, proposal: <span class="built_in">callable</span>,</span></span><br><span class="line"><span class="params">                   target: <span class="built_in">callable</span></span>):</span><br><span class="line">  thetas = np.zeros((niters - burnin, <span class="number">2</span>), np.<span class="built_in">float</span>)</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(niters):</span><br><span class="line">    new_theta = proposal(theta)</span><br><span class="line">    p = <span class="built_in">min</span>(target(*new_theta) / target(*theta), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> np.random.rand() &lt; p:</span><br><span class="line">      theta = new_theta</span><br><span class="line">    <span class="keyword">if</span> i &gt;= burnin:</span><br><span class="line">      thetas[i - burnin] = theta</span><br><span class="line">  <span class="keyword">return</span> thetas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">init_theta = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">niters = <span class="number">10000</span></span><br><span class="line">burnin = <span class="number">500</span></span><br><span class="line">thetas = metro_hastings(niters, burnin, init_theta, proposal, target)</span><br><span class="line">kde = gaussian_kde(thetas.T)</span><br><span class="line">XY = np.vstack([X.ravel(), Y.ravel()])</span><br><span class="line">posterior_metroplis = kde(XY).reshape(X.shape)</span><br><span class="line">make_plots(X, Y, prior(X, Y), lik(X, Y), posterior_metroplis)</span><br><span class="line">plt.title(<span class="string">f&quot;M-H采样&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; gibbs &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">theta = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">niters = <span class="number">10000</span></span><br><span class="line">burnin = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gibbs</span>(<span class="params">niters: <span class="built_in">int</span>, burnin: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          theta: np.ndarray, proposal: <span class="built_in">callable</span>,</span></span><br><span class="line"><span class="params">          target: <span class="built_in">callable</span></span>):</span><br><span class="line">  thetas = np.zeros((niters - burnin, <span class="number">2</span>), np.<span class="built_in">float</span>)</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(niters):</span><br><span class="line">    theta = [beta(a + k1, b + N1 - k1).rvs(), theta[<span class="number">1</span>]]</span><br><span class="line">    theta = [theta[<span class="number">0</span>], beta(a + k2, b + N2 - k2).rvs()]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i &gt;= burnin:</span><br><span class="line">      thetas[i - burnin] = theta</span><br><span class="line">  <span class="keyword">return</span> thetas</span><br><span class="line"></span><br><span class="line">thetas = gibbs(niters, burnin, init_theta, proposal, target)</span><br><span class="line">kde = gaussian_kde(thetas.T)</span><br><span class="line">XY = np.vstack([X.ravel(), Y.ravel()])</span><br><span class="line">posterior_metroplis = kde(XY).reshape(X.shape)</span><br><span class="line">make_plots(X, Y, prior(X, Y), lik(X, Y), posterior_metroplis)</span><br><span class="line">plt.title(<span class="string">f&quot;Gibbs采样&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.tight_layout(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行结果: <img src="/2020/07/28/statis-learn-cp16/gibbs_1.png" />
<img src="/2020/07/28/statis-learn-cp16/gibbs_2.png" /> <img
src="/2020/07/28/statis-learn-cp16/gibbs_3.png" /></p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" rel="tag">概率论</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/08/03/statis-learn-cp17/">统计学习方法:潜在狄利克雷分配模型</a><a class="next" href="/2020/07/21/statis-learn-cp15/">统计学习方法:概率潜在语义模型</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a> <a href="/tags/%E7%AE%97%E5%AD%90/" style="font-size: 15px;">算子</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/09/26/flashattn/">Flash Attention记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/08/28/chimera/">Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>