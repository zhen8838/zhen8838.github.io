<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>tensorflow与pytorch代码差异 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="https://unpkg.com/normalize.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/pure-min.css"><link rel="stylesheet" type="text/css" href="https://unpkg.com/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="https://unpkg.com/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="https://unpkg.com/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="https://unpkg.com/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="https://unpkg.com/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="https://unpkg.com/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">tensorflow与pytorch代码差异</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">tensorflow与pytorch代码差异</h1><div class="post-meta">2020-07-05<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.3k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 6</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#torch%E4%B8%ADnn.conv2d%E7%9A%84groups%E5%8F%82%E6%95%B0"><span class="toc-number">1.</span> <span class="toc-text">1.
torch中nn.Conv2d的groups参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nn.adaptiveavgpool2d%E4%B8%8Ekl.globalaveragepooling2d"><span class="toc-number">2.</span> <span class="toc-text">2.
nn.AdaptiveAvgPool2d与kl.GlobalAveragePooling2D</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tf.contrib.layers.layer_norm%E4%B8%8Etf.keras.layernorm%E4%B8%8Enn.layernorm"><span class="toc-number">3.</span> <span class="toc-text">tf.contrib.layers.layer_norm与tf.keras.LayerNorm与nn.LayerNorm</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#tf.contrib.layers.layer_norm"><span class="toc-number">3.1.</span> <span class="toc-text">tf.contrib.layers.layer_norm</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tf.keras.layernorm"><span class="toc-number">3.2.</span> <span class="toc-text">tf.keras.LayerNorm</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#nn.layernorm"><span class="toc-number">3.3.</span> <span class="toc-text">nn.LayerNorm</span></a></li></ol></li></ol></div></div><div class="post-content"><p>可能会长期更新,因为经常需要从<code>pytorch</code>偷代码翻译成<code>tensorflow</code>😑因此记录一下差异的地方.</p>
<span id="more"></span>
<h4 id="torch中nn.conv2d的groups参数">1.
<code>torch</code>中<code>nn.Conv2d</code>的<code>groups</code>参数</h4>
<p><code>torch</code>中<code>groups</code>控制输入和输出之间的连接,<code>in_channels</code>和<code>out_channels</code>必须都可以被组整除.
- <code>groups=1</code> 传统的卷积方式. - <code>groups=2</code>
等效于并排设置两个<code>conv</code>层，每个<code>conv</code>层看到一半的输入通道，并产生一半的输出通道，并且随后将它们都连接在一起.
- <code>groups=in_channels</code> 每个输入通道都有自己的滤波器.</p>
<p>等价写法: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.Conv2d(expand_size, expand_size, kernel_size=kernel_size, </span><br><span class="line">          stride=stride, padding=kernel_size//<span class="number">2</span>, groups=expand_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">kl.DepthwiseConv2D(kernel_size=kernel_size,</span><br><span class="line">                  strides=stride, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>NOTE:</p>
<p>这里<code>pytorch</code>生成的卷积核<code>shape = [out_channel, 1, kh, kw]</code>
这里<code>tflite</code>生成的卷积核<code>shape = [1, kh, kw, out_channel]</code></p>
<h4 id="nn.adaptiveavgpool2d与kl.globalaveragepooling2d">2.
<code>nn.AdaptiveAvgPool2d</code>与<code>kl.GlobalAveragePooling2D</code></h4>
<p>当<code>nn.AdaptiveAvgPool2d(1)</code>时和<code>kl.GlobalAveragePooling2D()</code>相同,但是注意<code>torch</code>的输出是保持<code>4</code>维的,而<code>tensorflow</code>不保持维度.</p>
<p>等价写法: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=nn.AdaptiveAvgPool2d(<span class="number">1</span>)(x)</span><br><span class="line"><span class="comment"># -----------------------------</span></span><br><span class="line">pool=kl.GlobalAveragePooling2D()</span><br><span class="line">x=k.backend.expand_dims(k.backend.expand_dims(pool(x),<span class="number">1</span>),<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>当然直接修改<code>GlobalAveragePooling2D</code>里,添加<code>keepdims=true</code>参数也可以.</p>
<h4
id="tf.contrib.layers.layer_norm与tf.keras.layernorm与nn.layernorm">tf.contrib.layers.layer_norm与tf.keras.LayerNorm与nn.LayerNorm</h4>
<h5
id="tf.contrib.layers.layer_norm"><code>tf.contrib.layers.layer_norm</code></h5>
<p>tf以前遗留代码还是挺蛋疼的。在<code>tf.contrib.layers.layer_norm</code>中，对于输入为<code>(4, 10, 10, 3)</code>的张量，是对<code>(h,w,c)</code>进行归一化处理，但是他的仿射系数默认只对<code>c</code>有效：
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = tf.reshape(tf.<span class="built_in">range</span>(<span class="number">4</span> * <span class="number">3</span> * <span class="number">10</span> * <span class="number">10</span>, dtype=tf.float32), (<span class="number">4</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">xout = tf_contrib.layers.layer_norm(x,</span><br><span class="line">                                    center=<span class="literal">True</span>, scale=<span class="literal">True</span>,</span><br><span class="line">                                    scope=<span class="string">&#x27;layer_norm&#x27;</span>)</span><br><span class="line">mean.shape = (<span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>) </span><br><span class="line">gamma.shape = (<span class="number">3</span>,)</span><br></pre></td></tr></table></figure></p>
<h5 id="tf.keras.layernorm"><code>tf.keras.LayerNorm</code></h5>
<p><code>tf.keras.LayerNorm</code>我就属实不懂了，讲道理他的归一化是对<code>(h,w,c)</code>进行归一化处理，仿射系数对<code>c</code>有效，但是输出归一化结果是<code>400=4×10x10</code>，这就很奇怪了，他默认的特征维度是<code>-1</code>，但是看起来却没有干<code>LayerNorm</code>应该做的事情，反而把<code>batch</code>维度也归一化了，<strong>但是</strong>在最终测试输出的时候发现结果是符合预期的。。属实不理解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs_np = tf.convert_to_tensor(</span><br><span class="line">    np.arange(<span class="number">4</span> * <span class="number">3</span> * <span class="number">10</span> * <span class="number">10</span>).reshape((<span class="number">4</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>)), dtype=tf.float32)</span><br><span class="line">inputs = k.Input((<span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>), batch_size=<span class="literal">None</span>)</span><br><span class="line">lm = k.layers.LayerNormalization()</span><br><span class="line">lm.weights</span><br><span class="line">lm_out = lm(inputs)</span><br><span class="line">md = k.Model(inputs, lm_out) </span><br><span class="line">scale.shape <span class="comment"># (3,)</span></span><br><span class="line">mean.shape <span class="comment"># (400,1)</span></span><br><span class="line"></span><br><span class="line">lm_out_np = md(inputs_np)</span><br><span class="line">lm_out_np = lm_out_np.numpy()</span><br><span class="line">np.mean(lm_out_np[<span class="number">0</span>, ...]) <span class="comment"># -3.8146972e-08</span></span><br><span class="line">np.var(lm_out_np[<span class="number">0</span>, ...]) <span class="comment"># 0.9985023</span></span><br></pre></td></tr></table></figure>
<h5 id="nn.layernorm"><code>nn.LayerNorm</code></h5>
<p><code>nn.LayerNorm</code>是对<code>(c,h,w)</code>进行归一化处理，仿射系数对<code>c,h,w</code>有效，但有个非常蛋疼的问题就是，他没有办法复现老版本<code>tf</code>的行为，即只用<code>c</code>作为仿射系数，如果开启仿射会导致参数非常大。。。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = torch.tensor(np.arange(<span class="number">4</span> * <span class="number">3</span> * <span class="number">10</span> * <span class="number">10</span>).reshape((<span class="number">4</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>)), dtype=torch.float32)</span><br><span class="line">lm = nn.LayerNorm([<span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>], elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">ln_out = lm(inputs)</span><br><span class="line">lm.weight.shape <span class="comment"># torch.Size([3, 10, 10])</span></span><br></pre></td></tr></table></figure>
<p>我继续检查他的源码,在<code>aten/src/ATen/native/layer_norm.h</code>中，将输入维度分为<code>M*N</code>，按照我们上面的做法即<code>M=4,N=3*10*10</code>。
然后进入cuda代码<code>aten/src/ATen/native/cuda/layer_norm_kernel.cu</code>利用<code>RowwiseMomentsCUDAKernel</code>计算均值与方差：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LayerNormKernelImplInternal</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; X,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; gamma,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; beta,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> M,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> N,</span></span></span><br><span class="line"><span class="params"><span class="function">    T eps,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* Y,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* mean,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* rstd)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DCHECK_EQ</span>(X.<span class="built_in">numel</span>(), M * N);</span><br><span class="line">  <span class="built_in">DCHECK</span>(!gamma.<span class="built_in">defined</span>() || gamma.<span class="built_in">numel</span>() == N);</span><br><span class="line">  <span class="built_in">DCHECK</span>(!beta.<span class="built_in">defined</span>() || beta.<span class="built_in">numel</span>() == N);</span><br><span class="line">  <span class="type">const</span> T* X_data = X.<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  <span class="type">const</span> T* gamma_data = gamma.<span class="built_in">defined</span>() ? gamma.<span class="built_in">data_ptr</span>&lt;T&gt;() : <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="type">const</span> T* beta_data = beta.<span class="built_in">defined</span>() ? beta.<span class="built_in">data_ptr</span>&lt;T&gt;() : <span class="literal">nullptr</span>;</span><br><span class="line">  T* Y_data = Y-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  T* mean_data = mean-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  T* rstd_data = rstd-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  cudaStream_t cuda_stream = at::cuda::<span class="built_in">getCurrentCUDAStream</span>();</span><br><span class="line">  RowwiseMomentsCUDAKernel&lt;T&gt;</span><br><span class="line">      &lt;&lt;&lt;M, cuda_utils::kCUDABlockReduceNumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">          N, eps, X_data, mean_data, rstd_data);</span><br><span class="line">  LayerNormForwardCUDAKernel&lt;T&gt;&lt;&lt;&lt;M, kCUDANumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">      N, X_data, mean_data, rstd_data, gamma_data, beta_data, Y_data);</span><br><span class="line">  <span class="built_in">AT_CUDA_CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来我们检查一下<code>group norm</code>，首先给定<code>group</code>，他将模型输入分为<code>N,C,HxW</code>。在<code>aten/src/ATen/native/cuda/group_norm_kernel.cu</code>中，当<code>group=1</code>的时候，<code>D=C/G=C</code>，<code>N×G=N</code>,也就是<code>group=1</code>的是等同于<code>layer norm</code>，并且此时他的可变化参数为<code>C</code>，可以用来等效<code>tf.contrib.layers.layer_norm</code>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">GroupNormKernelImplInternal</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; X,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; gamma,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Tensor&amp; beta,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> N,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> C,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> HxW,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> group,</span></span></span><br><span class="line"><span class="params"><span class="function">    T eps,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* Y,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* mean,</span></span></span><br><span class="line"><span class="params"><span class="function">    Tensor* rstd)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">using</span> T_ACC = acc_type&lt;T, <span class="literal">true</span>&gt;;</span><br><span class="line">  <span class="built_in">TORCH_CHECK</span>(X.<span class="built_in">numel</span>() == N * C * HxW);</span><br><span class="line">  <span class="built_in">TORCH_CHECK</span>(!gamma.<span class="built_in">defined</span>() || gamma.<span class="built_in">numel</span>() == C);</span><br><span class="line">  <span class="built_in">TORCH_CHECK</span>(!beta.<span class="built_in">defined</span>() || beta.<span class="built_in">numel</span>() == C);</span><br><span class="line">  <span class="keyword">if</span> (N == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">const</span> <span class="type">int64_t</span> G = group;</span><br><span class="line">  <span class="type">const</span> <span class="type">int64_t</span> D = C / G;</span><br><span class="line">  <span class="type">const</span> T* X_data = X.<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  <span class="type">const</span> T* gamma_data = gamma.<span class="built_in">defined</span>() ? gamma.<span class="built_in">data_ptr</span>&lt;T&gt;() : <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="type">const</span> T* beta_data = beta.<span class="built_in">defined</span>() ? beta.<span class="built_in">data_ptr</span>&lt;T&gt;() : <span class="literal">nullptr</span>;</span><br><span class="line">  T* Y_data = Y-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  T* mean_data = mean-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  T* rstd_data = rstd-&gt;<span class="built_in">data_ptr</span>&lt;T&gt;();</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span> kAccType = X.<span class="built_in">scalar_type</span>() == kHalf ? kFloat : X.<span class="built_in">scalar_type</span>();</span><br><span class="line">  Tensor a = at::<span class="built_in">empty</span>(&#123;N, C&#125;, X.<span class="built_in">options</span>().<span class="built_in">dtype</span>(kAccType));</span><br><span class="line">  Tensor b = at::<span class="built_in">empty</span>(&#123;N, C&#125;, X.<span class="built_in">options</span>().<span class="built_in">dtype</span>(kAccType));</span><br><span class="line">  T_ACC* a_data = a.<span class="built_in">data_ptr</span>&lt;T_ACC&gt;();</span><br><span class="line">  T_ACC* b_data = b.<span class="built_in">data_ptr</span>&lt;T_ACC&gt;();</span><br><span class="line">  cudaStream_t cuda_stream = at::cuda::<span class="built_in">getCurrentCUDAStream</span>();</span><br><span class="line">  RowwiseMomentsCUDAKernel&lt;T&gt;</span><br><span class="line">      &lt;&lt;&lt;N * G, cuda_utils::kCUDABlockReduceNumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">          D * HxW, eps, X_data, mean_data, rstd_data);</span><br><span class="line">  <span class="type">int64_t</span> B = (N * C + kCUDANumThreads - <span class="number">1</span>) / kCUDANumThreads;</span><br><span class="line">  ComputeFusedParamsCUDAKernel&lt;T&gt;&lt;&lt;&lt;B, kCUDANumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">      N, C, G, mean_data, rstd_data, gamma_data, beta_data, a_data, b_data);</span><br><span class="line">  <span class="keyword">if</span> (HxW &lt; kCUDANumThreads) &#123;</span><br><span class="line">    B = (N * C * HxW + kCUDANumThreads - <span class="number">1</span>) / kCUDANumThreads;</span><br><span class="line">    GroupNormForwardSimpleCUDAKernel&lt;T&gt;&lt;&lt;&lt;B, kCUDANumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">        N, C, HxW, X_data, a_data, b_data, Y_data);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    GroupNormForwardCUDAKernel&lt;T&gt;&lt;&lt;&lt;N * C, kCUDANumThreads, <span class="number">0</span>, cuda_stream&gt;&gt;&gt;(</span><br><span class="line">        HxW, X_data, a_data, b_data, Y_data);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">AT_CUDA_CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/07/21/statis-learn-cp15/">统计学习方法:概率潜在语义模型</a><a class="next" href="/2020/06/19/RealMix-EnAET/">半监督学习：RealMix与EnAET</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a> <a href="/tags/%E7%AE%97%E5%AD%90/" style="font-size: 15px;">算子</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/10/15/jax-reshard/">探究jax reshard优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/09/26/flashattn/">Flash Attention记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/08/28/chimera/">Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="https://unpkg.com/@fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>