<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>mindspore vs tensorflow | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">mindspore vs tensorflow</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">mindspore vs tensorflow</h1><div class="post-meta">2020-09-21<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 3.2k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 18</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#mindspore%E7%89%88"><span class="toc-number">1.</span> <span class="toc-text">mindspore版</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tensorflow%E7%89%88"><span class="toc-number">2.</span> <span class="toc-text">tensorflow版</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#megengine%E7%89%88"><span class="toc-number">3.</span> <span class="toc-text">megengine版</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="post-content"><p>尝试用了一下<code>mindspore</code>，这里给出一个<code>dcgan</code>的<code>demo</code>对比一下两个框架。
我使用<code>mindspore 0.7</code>，<code>tensorflow 2.2</code>，<code>megengine 0.6</code>，其他参数均相同。</p>
<span id="more"></span>
<h4 id="mindspore版"><code>mindspore</code>版</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mindspore.nn.wrap.grad_reducer <span class="keyword">import</span> DistributedGradReducer</span><br><span class="line"><span class="keyword">from</span> mindspore.train.parallel_utils <span class="keyword">import</span> ParallelMode</span><br><span class="line"><span class="keyword">from</span> mindspore.parallel._utils <span class="keyword">import</span> (_get_device_num, _get_mirror_mean, _get_parallel_mode)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> mindspore <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> mindspore.context <span class="keyword">as</span> context</span><br><span class="line"><span class="keyword">import</span> mindspore.nn.wrap <span class="keyword">as</span> mwp</span><br><span class="line"><span class="keyword">import</span> mindspore.nn.layer <span class="keyword">as</span> ml</span><br><span class="line"><span class="keyword">import</span> mindspore.train.callback <span class="keyword">as</span> callback</span><br><span class="line"><span class="keyword">import</span> mindspore.nn.loss <span class="keyword">as</span> mls</span><br><span class="line"><span class="keyword">import</span> mindspore.nn.optim <span class="keyword">as</span> moptim</span><br><span class="line"><span class="keyword">from</span> mindspore.nn <span class="keyword">import</span> Cell</span><br><span class="line"><span class="keyword">import</span> mindspore.ops.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> mindspore.ops.operations <span class="keyword">as</span> P</span><br><span class="line"><span class="keyword">import</span> mindspore.ops.composite <span class="keyword">as</span> C</span><br><span class="line"><span class="keyword">from</span> mindspore.common <span class="keyword">import</span> initializer <span class="keyword">as</span> minit</span><br><span class="line"><span class="keyword">import</span> mindspore.dataset <span class="keyword">as</span> ds</span><br><span class="line"><span class="keyword">import</span> mindspore.dataset.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unzipfile</span>(<span class="params">gzip_path</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;unzip dataset file</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      gzip_path: dataset file path</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  open_file = <span class="built_in">open</span>(gzip_path.replace(<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;&#x27;</span>), <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">  gz_file = gzip.GzipFile(gzip_path)</span><br><span class="line">  open_file.write(gz_file.read())</span><br><span class="line">  gz_file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_dataset</span>():</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Download the dataset from http://yann.lecun.com/exdb/mnist/.&quot;&quot;&quot;</span></span><br><span class="line">  train_path = <span class="string">&quot;./MNIST_Data/train/&quot;</span></span><br><span class="line">  test_path = <span class="string">&quot;./MNIST_Data/test/&quot;</span></span><br><span class="line">  train_path_check = os.path.exists(train_path)</span><br><span class="line">  test_path_check = os.path.exists(test_path)</span><br><span class="line">  <span class="keyword">if</span> train_path_check == <span class="literal">False</span> <span class="keyword">and</span> test_path_check == <span class="literal">False</span>:</span><br><span class="line">    os.makedirs(train_path)</span><br><span class="line">    os.makedirs(test_path)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;******Downloading the MNIST dataset******&quot;</span>)</span><br><span class="line">  train_url = &#123;<span class="string">&quot;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&quot;</span>,</span><br><span class="line">               <span class="string">&quot;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&quot;</span>&#125;</span><br><span class="line">  test_url = &#123;<span class="string">&quot;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&quot;</span>,</span><br><span class="line">              <span class="string">&quot;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&quot;</span>&#125;</span><br><span class="line">  <span class="keyword">for</span> url <span class="keyword">in</span> train_url:</span><br><span class="line">    url_parse = urlparse(url)</span><br><span class="line">    <span class="comment"># split the file name from url</span></span><br><span class="line">    file_name = os.path.join(train_path, url_parse.path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_name.replace(<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;&#x27;</span>)):</span><br><span class="line">      file = urllib.request.urlretrieve(url, file_name)</span><br><span class="line">      unzipfile(file_name)</span><br><span class="line">      os.remove(file_name)</span><br><span class="line">  <span class="keyword">for</span> url <span class="keyword">in</span> test_url:</span><br><span class="line">    url_parse = urlparse(url)</span><br><span class="line">    <span class="comment"># split the file name from url</span></span><br><span class="line">    file_name = os.path.join(test_path, url_parse.path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_name.replace(<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;&#x27;</span>)):</span><br><span class="line">      file = urllib.request.urlretrieve(url, file_name)</span><br><span class="line">      unzipfile(file_name)</span><br><span class="line">      os.remove(file_name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">data_path, noise_dim, batch_size=<span class="number">32</span>, repeat_size=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                   num_parallel_workers=<span class="number">1</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot; create dataset for train or test</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      data_path: Data path</span></span><br><span class="line"><span class="string">      batch_size: The number of data records in each group</span></span><br><span class="line"><span class="string">      repeat_size: The number of replicated data records</span></span><br><span class="line"><span class="string">      num_parallel_workers: The number of parallel workers</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># define dataset</span></span><br><span class="line">  mnist_ds = ds.MnistDataset(data_path)</span><br><span class="line"></span><br><span class="line">  hwc2chw_op = transforms.vision.c_transforms.HWC2CHW()</span><br><span class="line">  <span class="comment"># apply map operations on images</span></span><br><span class="line">  mnist_ds = (mnist_ds.<span class="built_in">map</span>(operations=<span class="keyword">lambda</span> x: ((x - <span class="number">127.5</span>) / <span class="number">127.5</span>).astype(<span class="string">&#x27;float32&#x27;</span>), input_columns=<span class="string">&quot;image&quot;</span>,</span><br><span class="line">                           num_parallel_workers=num_parallel_workers)</span><br><span class="line">              .<span class="built_in">map</span>(operations=hwc2chw_op, input_columns=<span class="string">&quot;image&quot;</span>,</span><br><span class="line">                   num_parallel_workers=num_parallel_workers)</span><br><span class="line">              .<span class="built_in">map</span>(operations=<span class="keyword">lambda</span> x: (x, np.random.randn(noise_dim).astype(<span class="string">&#x27;float32&#x27;</span>)),</span><br><span class="line">                   input_columns=<span class="string">&quot;image&quot;</span>,</span><br><span class="line">                   output_columns=[<span class="string">&quot;image&quot;</span>, <span class="string">&quot;noise&quot;</span>],</span><br><span class="line">                   columns_order=[<span class="string">&quot;image&quot;</span>, <span class="string">&quot;noise&quot;</span>],</span><br><span class="line">                   num_parallel_workers=num_parallel_workers))</span><br><span class="line">  <span class="comment"># apply DatasetOps</span></span><br><span class="line">  buffer_size = <span class="number">60000</span></span><br><span class="line">  mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)  <span class="comment"># 10000 as in LeNet train script</span></span><br><span class="line">  mnist_ds = mnist_ds.batch(batch_size, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  mnist_ds: ds.MindDataset = mnist_ds.repeat(repeat_size)</span><br><span class="line">  <span class="comment"># print(mnist_ds.output_())</span></span><br><span class="line">  <span class="comment"># print(mnist_ds.output_types())</span></span><br><span class="line">  <span class="keyword">return</span> mnist_ds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(<span class="title class_ inherited__">Cell</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, shape: <span class="built_in">list</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.shape = shape</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="keyword">return</span> F.reshape(x, self.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_generator_model</span>(<span class="params">noise_dim</span>):</span><br><span class="line">  model = ml.SequentialCell(</span><br><span class="line">      ml.Dense(noise_dim, <span class="number">7</span> * <span class="number">7</span> * <span class="number">256</span>, has_bias=<span class="literal">False</span>),</span><br><span class="line">      Reshape((-<span class="number">1</span>, <span class="number">256</span>, <span class="number">7</span>, <span class="number">7</span>)),</span><br><span class="line">      ml.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">      ml.LeakyReLU(),</span><br><span class="line">      <span class="comment"># assert model.output_shape == (None, 7, 7, 256)  # 注意：batch size 没有限制</span></span><br><span class="line">      ml.Conv2dTranspose(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), pad_mode=<span class="string">&#x27;same&#x27;</span>, has_bias=<span class="literal">False</span>),</span><br><span class="line">      <span class="comment"># assert model.output_shape == (None, 7, 7, 128)</span></span><br><span class="line">      ml.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">      ml.LeakyReLU(),</span><br><span class="line">      ml.Conv2dTranspose(<span class="number">128</span>, <span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), pad_mode=<span class="string">&#x27;same&#x27;</span>, has_bias=<span class="literal">False</span>),</span><br><span class="line">      <span class="comment"># assert model.output_shape == (None, 14, 14, 64)</span></span><br><span class="line">      ml.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">      ml.LeakyReLU(),</span><br><span class="line">      ml.Conv2dTranspose(<span class="number">64</span>, <span class="number">1</span>, (<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                         pad_mode=<span class="string">&#x27;same&#x27;</span>, has_bias=<span class="literal">False</span>),</span><br><span class="line">      ml.Tanh()</span><br><span class="line">      <span class="comment"># assert model.output_shape == (None, 28, 28, 1)</span></span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_discriminator_model</span>():</span><br><span class="line">  model = ml.SequentialCell(</span><br><span class="line">      ml.Conv2d(<span class="number">1</span>, <span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), pad_mode=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">      ml.LeakyReLU(),</span><br><span class="line">      ml.Dropout(<span class="number">0.3</span>),</span><br><span class="line">      ml.Conv2d(<span class="number">64</span>, <span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), pad_mode=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">      ml.LeakyReLU(),</span><br><span class="line">      ml.Dropout(<span class="number">0.3</span>),</span><br><span class="line">      ml.Flatten(),</span><br><span class="line">      ml.Dense(<span class="number">128</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">      ml.Sigmoid()</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANBaseNet</span>(<span class="title class_ inherited__">Cell</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_dim</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__(auto_prefix=<span class="literal">True</span>)</span><br><span class="line">    self.generator = make_generator_model(noise_dim)</span><br><span class="line">    self.discriminator = make_discriminator_model()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, images, noise</span>):</span><br><span class="line">    generated_images = self.generator(noise)</span><br><span class="line">    real_output = self.discriminator(images)</span><br><span class="line">    fake_output = self.discriminator(generated_images)</span><br><span class="line">    <span class="keyword">return</span> real_output, fake_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANWithLoss</span>(<span class="title class_ inherited__">Cell</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_net: GANBaseNet</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__(auto_prefix=<span class="literal">True</span>)</span><br><span class="line">    self.base_net = base_net</span><br><span class="line">    self.cross_entropy = P.BinaryCrossEntropy()  <span class="comment"># 是否需要sigmoid是个问题</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">discriminator_loss</span>(<span class="params">self, real_output, fake_output, weight</span>):</span><br><span class="line">    real_loss = self.cross_entropy(real_output, F.ones_like(real_output), weight)</span><br><span class="line">    fake_loss = self.cross_entropy(fake_output, F.zeros_like(fake_output), weight)</span><br><span class="line">    total_loss = real_loss + fake_loss</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">generator_loss</span>(<span class="params">self, fake_output, weight</span>):</span><br><span class="line">    <span class="keyword">return</span> self.cross_entropy(fake_output, F.ones_like(fake_output), weight)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, images, noise</span>):</span><br><span class="line">    real_output, fake_output = self.base_net(images, noise)</span><br><span class="line">    weight = F.ones_like(real_output)</span><br><span class="line">    gen_loss = self.generator_loss(fake_output, weight)</span><br><span class="line">    disc_loss = self.discriminator_loss(real_output, fake_output, weight)</span><br><span class="line">    <span class="keyword">return</span> gen_loss, disc_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IthOutputCell</span>(<span class="title class_ inherited__">Cell</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot; 显式指定反向传播图 &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, network, output_index</span>):</span><br><span class="line">    <span class="built_in">super</span>(IthOutputCell, self).__init__()</span><br><span class="line">    self.network = network</span><br><span class="line">    self.output_index = output_index</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, image, noise</span>):</span><br><span class="line">    predict = self.network(image, noise)[self.output_index]</span><br><span class="line">    <span class="keyword">return</span> predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TrainStepWrap</span>(<span class="title class_ inherited__">Cell</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, network: GANWithLoss, g_optimizer: moptim.Optimizer, d_optimizer: moptim.Optimizer, sens=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="comment"># NOTE 这里必须要设置auto_prefix，否则两个优化器的参数将冲突</span></span><br><span class="line">    <span class="built_in">super</span>(TrainStepWrap, self).__init__(auto_prefix=<span class="literal">True</span>)</span><br><span class="line">    self.network = network</span><br><span class="line">    self.network.set_grad()</span><br><span class="line">    self.network.add_flags(defer_inline=<span class="literal">True</span>)</span><br><span class="line">    self.g_weights = g_optimizer.parameters</span><br><span class="line">    self.g_optimizer = g_optimizer</span><br><span class="line">    self.d_weights = d_optimizer.parameters</span><br><span class="line">    self.d_optimizer = d_optimizer</span><br><span class="line">    self.g_grad = C.GradOperation(<span class="string">&#x27;g_grad&#x27;</span>, get_by_list=<span class="literal">True</span>, sens_param=<span class="literal">True</span>)</span><br><span class="line">    self.d_grad = C.GradOperation(<span class="string">&#x27;d_grad&#x27;</span>, get_by_list=<span class="literal">True</span>, sens_param=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    self.g_loss_net = IthOutputCell(network, output_index=<span class="number">0</span>)</span><br><span class="line">    self.d_loss_net = IthOutputCell(network, output_index=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    self.sens = sens</span><br><span class="line">    self.reducer_flag = <span class="literal">False</span></span><br><span class="line">    self.grad_reducer = <span class="literal">None</span></span><br><span class="line">    parallel_mode = _get_parallel_mode()</span><br><span class="line">    <span class="keyword">if</span> parallel_mode <span class="keyword">in</span> (ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL):</span><br><span class="line">      self.reducer_flag = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> self.reducer_flag:</span><br><span class="line">      mean = _get_mirror_mean()</span><br><span class="line">      degree = _get_device_num()</span><br><span class="line">      self.g_grad_reducer = DistributedGradReducer(g_optimizer.parameters, mean, degree)</span><br><span class="line">      self.d_grad_reducer = DistributedGradReducer(d_optimizer.parameters, mean, degree)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">update_model</span>(<span class="params">self, image, noise, loss, loss_net, grad, optimizer, weights, grad_reducer</span>):</span><br><span class="line">    sens = F.fill(F.dtype(loss), F.shape(loss), self.sens)</span><br><span class="line">    grads = grad(loss_net, weights)(image, noise, sens)</span><br><span class="line">    <span class="keyword">if</span> self.reducer_flag:</span><br><span class="line">      <span class="comment"># apply grad reducer on grads</span></span><br><span class="line">      grads = grad_reducer(grads)</span><br><span class="line">    <span class="keyword">return</span> F.depend(loss, optimizer(grads))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, image, noise</span>):</span><br><span class="line">    g_loss, d_loss = self.network(image, noise)</span><br><span class="line">    g_out = self.update_model(image, noise, g_loss, self.g_loss_net, self.g_grad,</span><br><span class="line">                              self.g_optimizer, self.g_weights, self.g_grad_reducer)</span><br><span class="line">    d_out = self.update_model(image, noise, d_loss, self.d_loss_net, self.d_grad,</span><br><span class="line">                              self.d_optimizer, self.d_weights, self.d_grad_reducer)</span><br><span class="line">    <span class="keyword">return</span> g_out, d_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANLossMonitor</span>(callback.LossMonitor):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step_end</span>(<span class="params">self, run_context</span>):</span><br><span class="line">    cb_params = run_context.original_args()</span><br><span class="line">    g_loss, d_loss = cb_params.net_outputs</span><br><span class="line">    g_loss: ms.Tensor</span><br><span class="line"></span><br><span class="line">    g_loss = np.mean(g_loss.asnumpy())</span><br><span class="line">    d_loss = np.mean(d_loss.asnumpy())</span><br><span class="line"></span><br><span class="line">    cur_step_in_epoch = (cb_params.cur_step_num - <span class="number">1</span>) % cb_params.batch_num + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(g_loss, <span class="built_in">float</span>) <span class="keyword">and</span> (np.isnan(g_loss) <span class="keyword">or</span> np.isinf(g_loss)):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&quot;epoch: &#123;&#125; step: &#123;&#125;. Invalid loss, terminating training.&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">          cb_params.cur_epoch_num, cur_step_in_epoch))</span><br><span class="line">    <span class="keyword">if</span> self._per_print_times != <span class="number">0</span> <span class="keyword">and</span> cb_params.cur_step_num % self._per_print_times == <span class="number">0</span>:</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&quot;epoch: %s step: %s, g_loss %s d_loss %s&quot;</span> %</span><br><span class="line">            (cb_params.cur_epoch_num, cur_step_in_epoch, g_loss, d_loss), flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANImageSave</span>(callback.Callback):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, generator: Cell, noise_dim</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.generator = generator</span><br><span class="line">    self.seed = ms.Tensor(np.random.randn(<span class="number">16</span>, noise_dim), ms.float32)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./log&#x27;</span>):</span><br><span class="line">      os.mkdir(<span class="string">&#x27;./log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">epoch_end</span>(<span class="params">self, run_context</span>):</span><br><span class="line">    cb_params = run_context.original_args()</span><br><span class="line">    <span class="comment"># self.generator.set_train(False) NOTE 暂时不知道是否需要设置</span></span><br><span class="line">    predictions: ms.Tensor = self.generator(self.seed)</span><br><span class="line">    predictions = predictions.asnumpy()</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(predictions.shape[<span class="number">0</span>]):</span><br><span class="line">      plt.subplot(<span class="number">4</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">      plt.imshow(predictions[i, <span class="number">0</span>, :, :] * <span class="number">127.5</span> + <span class="number">127.5</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">      plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.savefig(<span class="string">&#x27;./log/image_at_epoch_&#123;:04d&#125;.png&#x27;</span>.<span class="built_in">format</span>(cb_params.cur_epoch_num))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>(callback.Callback):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">epoch_begin</span>(<span class="params">self, run_context</span>):</span><br><span class="line">    self.start = time.time()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">epoch_end</span>(<span class="params">self, run_context</span>):</span><br><span class="line">    cb_params = run_context.original_args()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Time for epoch &#123;&#125; is &#123;&#125; sec&#x27;</span>.<span class="built_in">format</span>(cb_params.cur_epoch_num, time.time() - self.start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  EPOCHS = <span class="number">50</span></span><br><span class="line">  NOISE_DIM = <span class="number">100</span></span><br><span class="line">  BATCH_SIZE = <span class="number">256</span></span><br><span class="line">  num_examples_to_generate = <span class="number">16</span></span><br><span class="line">  context.set_context(mode=context.GRAPH_MODE, device_target=<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line">  sink_mode = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot; set dataset ~ &quot;&quot;&quot;</span></span><br><span class="line">  download_dataset()</span><br><span class="line">  mnist_path = <span class="string">&quot;./MNIST_Data&quot;</span></span><br><span class="line">  ds_train = create_dataset(os.path.join(mnist_path, <span class="string">&quot;train&quot;</span>), NOISE_DIM,</span><br><span class="line">                            BATCH_SIZE, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot; define model ~ &quot;&quot;&quot;</span></span><br><span class="line">  net = GANBaseNet(NOISE_DIM)</span><br><span class="line">  net_loss = GANWithLoss(net)</span><br><span class="line">  generator_optimizer = moptim.Adam(net.generator.trainable_params(), <span class="number">1e-4</span>)</span><br><span class="line">  discriminator_optimizer = moptim.Adam(net.discriminator.trainable_params(), <span class="number">1e-4</span>)</span><br><span class="line">  net_train_step = TrainStepWrap(net_loss, generator_optimizer, discriminator_optimizer)</span><br><span class="line">  model = ms.train.Model(net_train_step, amp_level=<span class="string">&#x27;O2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot; trianing ~ &quot;&quot;&quot;</span></span><br><span class="line">  model.train(EPOCHS, ds_train,</span><br><span class="line">              callbacks=[Timer(), GANImageSave(net.generator, NOISE_DIM)],</span><br><span class="line">              dataset_sink_mode=sink_mode)</span><br><span class="line">  <span class="string">&quot;&quot;&quot; make gif ~ &quot;&quot;&quot;</span></span><br><span class="line">  anim_file = <span class="string">&#x27;dcgan.gif&#x27;</span></span><br><span class="line">  <span class="keyword">import</span> imageio</span><br><span class="line">  <span class="keyword">import</span> glob</span><br><span class="line">  <span class="keyword">with</span> imageio.get_writer(anim_file, mode=<span class="string">&#x27;I&#x27;</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    filenames = glob.glob(<span class="string">&#x27;./log/image*.png&#x27;</span>)</span><br><span class="line">    filenames = <span class="built_in">sorted</span>(filenames)</span><br><span class="line">    last = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(filenames):</span><br><span class="line">      frame = <span class="number">2</span> * (i**<span class="number">0.5</span>)</span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">round</span>(frame) &gt; <span class="built_in">round</span>(last):</span><br><span class="line">        last = frame</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      image = imageio.imread(filename)</span><br><span class="line">      writer.append_data(image)</span><br><span class="line">    image = imageio.imread(filename)</span><br><span class="line">    writer.append_data(image)</span><br><span class="line"><span class="string">&quot;&quot;&quot; 14.3 sec/epoch , GPU mem 1544Mb &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Time <span class="keyword">for</span> epoch 1 is 14.746528148651123 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 2 is 13.69857907295227 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 3 is 13.860252380371094 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 4 is 13.879372358322144 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 5 is 13.845653057098389 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 6 is 13.994170665740967 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 7 is 13.880078554153442 sec</span><br></pre></td></tr></table></figure></p>
<h4 id="tensorflow版"><code>tensorflow</code>版</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">physical_devices = tf.config.experimental.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(physical_devices) &gt; <span class="number">0</span>, <span class="string">&quot;Not enough GPU hardware devices available&quot;</span></span><br><span class="line">tf.config.experimental.set_memory_growth(physical_devices[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_images = train_images.reshape(train_images.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">train_images = (train_images - <span class="number">127.5</span>) / <span class="number">127.5</span>  <span class="comment"># 将图片标准化到 [-1, 1] 区间内</span></span><br><span class="line">BUFFER_SIZE = <span class="number">60000</span></span><br><span class="line">BATCH_SIZE = <span class="number">256</span></span><br><span class="line"><span class="comment"># 批量化和打乱数据</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_generator_model</span>():</span><br><span class="line">  model = tf.keras.Sequential()</span><br><span class="line">  model.add(layers.Dense(<span class="number">7</span> * <span class="number">7</span> * <span class="number">256</span>, use_bias=<span class="literal">False</span>, input_shape=(<span class="number">100</span>,)))</span><br><span class="line">  model.add(layers.BatchNormalization())</span><br><span class="line">  model.add(layers.LeakyReLU())</span><br><span class="line"></span><br><span class="line">  model.add(layers.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">256</span>)))</span><br><span class="line">  <span class="keyword">assert</span> model.output_shape == (<span class="literal">None</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">256</span>)  <span class="comment"># 注意：batch size 没有限制</span></span><br><span class="line"></span><br><span class="line">  model.add(layers.Conv2DTranspose(<span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>))</span><br><span class="line">  <span class="keyword">assert</span> model.output_shape == (<span class="literal">None</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">128</span>)</span><br><span class="line">  model.add(layers.BatchNormalization())</span><br><span class="line">  model.add(layers.LeakyReLU())</span><br><span class="line"></span><br><span class="line">  model.add(layers.Conv2DTranspose(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>))</span><br><span class="line">  <span class="keyword">assert</span> model.output_shape == (<span class="literal">None</span>, <span class="number">14</span>, <span class="number">14</span>, <span class="number">64</span>)</span><br><span class="line">  model.add(layers.BatchNormalization())</span><br><span class="line">  model.add(layers.LeakyReLU())</span><br><span class="line"></span><br><span class="line">  model.add(layers.Conv2DTranspose(<span class="number">1</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">  <span class="keyword">assert</span> model.output_shape == (<span class="literal">None</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_discriminator_model</span>():</span><br><span class="line">  model = tf.keras.Sequential()</span><br><span class="line">  model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                          input_shape=[<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]))</span><br><span class="line">  model.add(layers.LeakyReLU())</span><br><span class="line">  model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">  model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">  model.add(layers.LeakyReLU())</span><br><span class="line">  model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">  model.add(layers.Flatten())</span><br><span class="line">  model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator = make_generator_model()</span><br><span class="line">discriminator = make_discriminator_model()</span><br><span class="line"><span class="comment"># 该方法返回计算交叉熵损失的辅助函数</span></span><br><span class="line">cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">discriminator_loss</span>(<span class="params">real_output, fake_output</span>):</span><br><span class="line">  real_loss = cross_entropy(tf.ones_like(real_output), real_output)</span><br><span class="line">  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)</span><br><span class="line">  total_loss = real_loss + fake_loss</span><br><span class="line">  <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generator_loss</span>(<span class="params">fake_output</span>):</span><br><span class="line">  <span class="keyword">return</span> cross_entropy(tf.ones_like(fake_output), fake_output)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator_optimizer = tf.keras.optimizers.Adam(<span class="number">1e-4</span>)</span><br><span class="line">discriminator_optimizer = tf.keras.optimizers.Adam(<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">50</span></span><br><span class="line">noise_dim = <span class="number">100</span></span><br><span class="line">num_examples_to_generate = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们将重复使用该种子（因此在动画 GIF 中更容易可视化进度）</span></span><br><span class="line">seed = tf.random.normal([num_examples_to_generate, noise_dim])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意 `tf.function` 的使用</span></span><br><span class="line"><span class="comment"># 该注解使函数被“编译”</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">images</span>):</span><br><span class="line">  noise = tf.random.normal([BATCH_SIZE, noise_dim])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> gen_tape, tf.GradientTape() <span class="keyword">as</span> disc_tape:</span><br><span class="line">    generated_images = generator(noise, training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    real_output = discriminator(images, training=<span class="literal">True</span>)</span><br><span class="line">    fake_output = discriminator(generated_images, training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    gen_loss = generator_loss(fake_output)</span><br><span class="line">    disc_loss = discriminator_loss(real_output, fake_output)</span><br><span class="line"></span><br><span class="line">  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)</span><br><span class="line">  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)</span><br><span class="line"></span><br><span class="line">  generator_optimizer.apply_gradients(<span class="built_in">zip</span>(gradients_of_generator, generator.trainable_variables))</span><br><span class="line">  discriminator_optimizer.apply_gradients(</span><br><span class="line">      <span class="built_in">zip</span>(gradients_of_discriminator, discriminator.trainable_variables))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_and_save_images</span>(<span class="params">model, epoch, test_input</span>):</span><br><span class="line">  <span class="comment"># 注意 training` 设定为 False</span></span><br><span class="line">  <span class="comment"># 因此，所有层都在推理模式下运行（batchnorm）。</span></span><br><span class="line">  predictions = model(test_input, training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(predictions.shape[<span class="number">0</span>]):</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(predictions[i, :, :, <span class="number">0</span>] * <span class="number">127.5</span> + <span class="number">127.5</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  plt.savefig(<span class="string">&#x27;/tmp/image_at_epoch_&#123;:04d&#125;.png&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">dataset, epochs</span>):</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image_batch <span class="keyword">in</span> dataset:</span><br><span class="line">      train_step(image_batch)</span><br><span class="line"></span><br><span class="line">    generate_and_save_images(generator,</span><br><span class="line">                             epoch + <span class="number">1</span>,</span><br><span class="line">                             seed)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Time for epoch &#123;&#125; is &#123;&#125; sec&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, time.time() - start))</span><br><span class="line"></span><br><span class="line">  generate_and_save_images(generator,</span><br><span class="line">                           epochs,</span><br><span class="line">                           seed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train(train_dataset, EPOCHS)</span><br><span class="line">anim_file = <span class="string">&#x27;dcgan.gif&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> imageio.get_writer(anim_file, mode=<span class="string">&#x27;I&#x27;</span>) <span class="keyword">as</span> writer:</span><br><span class="line">  filenames = glob.glob(<span class="string">&#x27;/tmp/image_at_epoch_*.png&#x27;</span>)</span><br><span class="line">  filenames = <span class="built_in">sorted</span>(filenames)</span><br><span class="line">  last = -<span class="number">1</span></span><br><span class="line">  <span class="keyword">for</span> i, filename <span class="keyword">in</span> <span class="built_in">enumerate</span>(filenames):</span><br><span class="line">    frame = <span class="number">2</span> * (i**<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">round</span>(frame) &gt; <span class="built_in">round</span>(last):</span><br><span class="line">      last = frame</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    image = imageio.imread(filename)</span><br><span class="line">    writer.append_data(image)</span><br><span class="line">  image = imageio.imread(filename)</span><br><span class="line">  writer.append_data(image)</span><br><span class="line"><span class="string">&quot;&quot;&quot; 7.74 sec/epoch, total 183.87s, GPU mem 2655Mb &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Time <span class="keyword">for</span> epoch 1 is 10.126373767852783 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 2 is 7.418195009231567 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 3 is 7.2069251537323 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 4 is 7.063368797302246 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 5 is 7.035956144332886 sec</span><br></pre></td></tr></table></figure></p>
<h4 id="megengine版"><code>megengine</code>版</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> megengine <span class="keyword">as</span> mge</span><br><span class="line"><span class="keyword">import</span> megengine.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> megengine.module <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> megengine.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> megengine.data.dataset <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> megengine.data <span class="keyword">import</span> SequentialSampler</span><br><span class="line"><span class="keyword">from</span> megengine.data.transform <span class="keyword">import</span> Normalize, ToMode, Compose, VisionTransform</span><br><span class="line"><span class="keyword">from</span> megengine.jit <span class="keyword">import</span> trace</span><br><span class="line"><span class="keyword">from</span> megengine <span class="keyword">import</span> optimizer <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> megengine.core.tensor_factory <span class="keyword">import</span> ones</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ones_like</span>(<span class="params">inp</span>):</span><br><span class="line">  <span class="keyword">return</span> ones(inp.shapeof()).astype(inp.dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Noise</span>(<span class="title class_ inherited__">VisionTransform</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_dim=<span class="number">100</span>, *, order=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__(order)</span><br><span class="line">    self.noise_dim = noise_dim</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">_apply_image</span>(<span class="params">self, image</span>):</span><br><span class="line">    <span class="keyword">return</span> image, np.random.randn(self.noise_dim).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mnist_train_dataset = MNIST(root=<span class="string">&quot;./MNIST&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">False</span>)</span><br><span class="line">sequential_sampler = SequentialSampler(dataset=mnist_train_dataset, batch_size=batch_size)</span><br><span class="line">mnist_train_dataloader = DataLoader(dataset=mnist_train_dataset,</span><br><span class="line">                                    sampler=sequential_sampler,</span><br><span class="line">                                    transform=Compose([</span><br><span class="line">                                        Normalize(<span class="number">127.5</span>, <span class="number">127.5</span>),</span><br><span class="line">                                        ToMode(<span class="string">&#x27;CHW&#x27;</span>),</span><br><span class="line">                                        Noise()]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(M.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, shape: <span class="built_in">tuple</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.shape = shape</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">    <span class="keyword">return</span> F.reshape(inputs, self.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator = M.Sequential(</span><br><span class="line">    M.Linear(<span class="number">100</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">256</span>, bias=<span class="literal">False</span>),</span><br><span class="line">    Reshape((-<span class="number">1</span>, <span class="number">256</span>, <span class="number">7</span>, <span class="number">7</span>)),</span><br><span class="line">    M.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">    M.LeakyReLU(),</span><br><span class="line">    M.ConvTranspose2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>, bias=<span class="literal">False</span>),</span><br><span class="line">    M.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">    M.LeakyReLU(),</span><br><span class="line">    M.ConvTranspose2d(<span class="number">128</span>, <span class="number">64</span>, <span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">    M.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    M.LeakyReLU(),</span><br><span class="line">    M.ConvTranspose2d(<span class="number">64</span>, <span class="number">1</span>, <span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">    M.Elemwise(<span class="string">&#x27;TANH&#x27;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">discriminator = M.Sequential(</span><br><span class="line">    M.Conv2d(<span class="number">1</span>, <span class="number">64</span>, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    M.LeakyReLU(),</span><br><span class="line">    M.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    M.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    M.LeakyReLU(),</span><br><span class="line">    M.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    Reshape((-<span class="number">1</span>, <span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>)),</span><br><span class="line">    M.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">1</span>),</span><br><span class="line">    M.Sigmoid()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># iters = iter(mnist_train_dataloader)</span></span><br><span class="line"><span class="comment"># (img, noise), _ = next(iters)</span></span><br><span class="line"><span class="comment"># discriminator(img).shape</span></span><br><span class="line"><span class="comment"># # 4608</span></span><br><span class="line"><span class="comment"># 128*6*6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">discriminator_loss</span>(<span class="params">real_output, fake_output</span>):</span><br><span class="line">  real_loss = F.binary_cross_entropy(real_output, ones_like(real_output))</span><br><span class="line">  fake_loss = F.binary_cross_entropy(fake_output, F.zeros_like(fake_output))</span><br><span class="line">  total_loss = real_loss + fake_loss</span><br><span class="line">  <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generator_loss</span>(<span class="params">fake_output</span>):</span><br><span class="line">  <span class="keyword">return</span> F.binary_cross_entropy(fake_output, ones_like(fake_output))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@trace(<span class="params">symbolic=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">images, noise, *, g_opt, d_opt, g_net, d_net</span>):</span><br><span class="line">  generator_optimizer.zero_grad()</span><br><span class="line">  discriminator_optimizer.zero_grad()</span><br><span class="line">  generated_images = g_net(noise)</span><br><span class="line"></span><br><span class="line">  real_output = d_net(images)</span><br><span class="line">  fake_output = d_net(generated_images)</span><br><span class="line"></span><br><span class="line">  gen_loss = generator_loss(fake_output)</span><br><span class="line">  disc_loss = discriminator_loss(real_output, fake_output)</span><br><span class="line">  g_opt.backward(gen_loss)</span><br><span class="line">  d_opt.backward(disc_loss)</span><br><span class="line">  <span class="keyword">return</span> gen_loss, disc_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator_optimizer = optim.Adam(generator.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line">discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trace.enabled = <span class="literal">True</span>  <span class="comment"># 开启trace，使用静态图模式</span></span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator.train()</span><br><span class="line">discriminator.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">  start = time.time()</span><br><span class="line">  <span class="keyword">for</span> (imgs, noise), _ <span class="keyword">in</span> mnist_train_dataloader:</span><br><span class="line"></span><br><span class="line">    gen_loss, disc_loss = train_step(imgs, noise, g_opt=generator_optimizer,</span><br><span class="line">                                     d_opt=discriminator_optimizer,</span><br><span class="line">                                     g_net=generator, d_net=discriminator)</span><br><span class="line">  <span class="comment"># generate_and_save_images(generator,</span></span><br><span class="line">  <span class="comment">#                          epoch + 1,</span></span><br><span class="line">  <span class="comment">#                          seed)</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Time for epoch &#123;&#125; is &#123;&#125; sec&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, time.time() - start))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; 8.47 sec/epoch, GPU mem 1299Mb &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出: <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">21 21:17:30 process the raw files of train <span class="built_in">set</span>...</span><br><span class="line">100%|██████████████████████████████████| 60000/60000 [00:02&lt;00:00, 21099.52it/s]</span><br><span class="line">100%|████████████████████████████████| 60000/60000 [00:00&lt;00:00, 1832574.11it/s]</span><br><span class="line">Time <span class="keyword">for</span> epoch 1 is 8.129057168960571 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 2 is 7.941509008407593 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 3 is 7.948836326599121 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 4 is 7.97221827507019 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 5 is 7.969634771347046 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 6 is 7.968409776687622 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 7 is 7.994731187820435 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 8 is 8.000129699707031 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 9 is 8.010562181472778 sec</span><br><span class="line">Time <span class="keyword">for</span> epoch 10 is 8.037590265274048 sec</span><br></pre></td></tr></table></figure></p>
<h4 id="总结">总结</h4>
<ol type="1">
<li><code>tensorflow</code>占显存为<code>2655Mb</code>，转静态图之后的速度真的还是非常快的。虽然我吐槽<code>tf</code>，但强还是强的啊。</li>
<li><code>mindspore</code>虽然占显存为<code>1544Mb</code>，但是明明是静态图运行，速度居然比<code>tf</code>慢一倍，这个真的让人难以接受，并且我还是开启了他的自动半精度，并没有什么用处。此外我还尝试了扩大数据载入的线程，然而4线程的时候一个周期反而需要<code>55s</code>，这是让我没想到的。</li>
<li><code>megengine</code>是我之前最不看好的，因为我感觉就像全抄<code>pytorch</code>的一样，肯定不会快很多。没想到结果还挺香，显存只需要<code>1299Mb</code>，速度还挺快.</li>
</ol>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mindspore/" rel="tag">mindspore</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/10/03/maml/">Model-Agnostic Meta-Learning</a><a class="next" href="/2020/09/19/mindspore-detail/">关于mindspore</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx_en/">Explore AMX instructions: Unlock the performance of Apple Silicon</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/13/macos-bundle/">macos中bundle的使用</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>