<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Uncertainty Weight Loss | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Uncertainty Weight Loss</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Uncertainty Weight Loss</h1><div class="post-meta">2020-09-14<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.9k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%BC%E7%84%B6%E5%AE%9A%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text">似然定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6"><span class="toc-number">2.</span> <span class="toc-text">最大似然</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E6%96%BD"><span class="toc-number">3.</span> <span class="toc-text">实施</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%8E%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">4.</span> <span class="toc-text">代码与实验结果</span></a></li></ol></div></div><div class="post-content"><p>这是对论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.07115">Multi Task
Learning with Homoscedastic Uncertainty</a>的一个学习。</p>
<span id="more"></span>
<h3 id="似然定义">似然定义</h3>
<p>设置<span
class="math inline">\(\mathbf{f}^{\mathbf{W}}(\mathbf{x})\)</span>表示为输入<span
class="math inline">\(x\)</span>通过权重<span
class="math inline">\(\boldsymbol{W}\)</span>的输出特征向量。本文将回归问题和分类问题分开考虑他们的概率表示：</p>
<ol type="1">
<li><p>回归问题：<span
class="math inline">\(p(\mathbf{y}|\mathbf{f}^{\mathbf{W}}(\mathbf{x}))=\mathcal{N}(\mathbf{f}^{\mathbf{W}}(\mathbf{x}),\sigma^2)\)</span>,即另模型输出作为均值，额外用一个参数表示方差，建模为高斯分布。</p></li>
<li><p>分类问题：<span
class="math inline">\(p(\mathbf{y}|\mathbf{f}^{\mathbf{W}}(\mathbf{x}))=\text{Softmax}(\mathbf{f}^{\mathbf{W}}(\mathbf{x}))\)</span>,分类时经过<span
class="math inline">\(\text{Softmax}\)</span>即为概率分布。</p></li>
</ol>
<p>接下来对于多任务结合的概率表示，简单讲就是概率乘积： <span
class="math display">\[
\begin{aligned}  
p\left(\mathbf{y}_{1}, \ldots, \mathbf{y}_{K} \mid
\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)=p\left(\mathbf{y}_{1} \mid
\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \ldots p\left(\mathbf{y}_{K}
\mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)
\end{aligned}
\]</span></p>
<h3 id="最大似然">最大似然</h3>
<p>为了最大化似然，先构造对数似然：</p>
<ol type="1">
<li><p>回归问题： <span class="math inline">\(\log p\left(\mathbf{y}
\mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \propto-\frac{1}{2
\sigma^{2}}\left\|\mathbf{y}-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right\|^{2}-\log
\sigma\)</span>，这里<span
class="math inline">\(\mathbf{y}\)</span>就是标准数据，<span
class="math inline">\(\mathbf{f}^{\mathbf{W}}(\mathbf{x})\)</span>为均值，后面的<span
class="math inline">\(-\log
\sigma\)</span>其实是他在对数化的时候把系数给省略了。</p></li>
<li><p>分类问题：<span class="math inline">\(p\left(\mathbf{y} \mid
\mathbf{f}^{\mathbf{W}}(\mathbf{x}),
\sigma\right)=\operatorname{Softmax}\left(\frac{1}{\sigma^{2}}
\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)\)</span>，这里为了添加一个可学习的系数，他构造<span
class="math inline">\(sigma\)</span>作为输出特征向量的温度系数，用来调整<span
class="math inline">\(\text{Softmax}\)</span>后的熵，比如特征向量被缩放的越厉害，那么输出分布会变得均匀，那么不确定性程度就加深了。<strong>NOTE：</strong>
因为我们的分类标签是带类别的，因此对应类别的对数似然公式如下(其中<span
class="math inline">\(c^{\prime}\)</span>表示不为<span
class="math inline">\(c\)</span>的其他类别)：</p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\log p\left(\mathbf{y}=c \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x}),
\sigma\right) &amp;=\frac{1}{\sigma^{2}} f_{c}^{\mathbf{W}}(\mathbf{x})
-\log \sum_{c^{\prime}} \exp \left(\frac{1}{\sigma^{2}}
f_{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right)
\end{aligned}
\]</span></p>
<p>接下来就是多个任务联合的对数似然并进行最大化后验概率，我们最小化负的对数似然：</p>
<p><span class="math display">\[
\begin{array}{l}
=-\log p\left(\mathbf{y}_{1}, \mathbf{y}_{2}=c \mid
\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \\
=-\log \mathcal{N}\left(\mathbf{y}_{1} ;
\mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_{1}^{2}\right) \cdot
\operatorname{Softmax}\left(\mathbf{y}_{2}=c ;
\mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_{2}\right) \\
=\frac{1}{2
\sigma_{1}^{2}}\left\|\mathbf{y}_{1}-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right\|^{2}+\log
\sigma_{1}-\log p\left(\mathbf{y}_{2}=c \mid
\mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_{2}\right)\\
=\frac{1}{2 \sigma_{1}^{2}}
\mathcal{L}_{1}(\mathbf{W})+\frac{1}{\sigma_{2}^{2}}
\mathcal{L}_{2}(\mathbf{W})+\log \sigma_{1} +\log
\frac{\sum_{c^{\prime}} \exp \left(\frac{1}{\sigma_{2}^{2}}
f_{c^{\prime}}^{\mathrm{W}}(\mathrm{x})\right)}{\left(\sum_{c^{\prime}}
\exp
\left(f_{c^{\prime}}^{\mathrm{W}}(\mathbf{x})\right)\right)^{\frac{1}{\sigma_{2}^{2}}}}\\
\approx \frac{1}{2
\sigma_{1}^{2}}\mathcal{L}_{1}(\mathbf{W})+\frac{1}{\sigma_{2}^{2}}
\mathcal{L}_{2}(\mathbf{W})+\log \sigma_{1}+\log \sigma_{2}
\end{array}
\]</span></p>
<p>以上的<span
class="math inline">\(\mathcal{L}_{1}(\mathbf{W})=\left\|\mathbf{y}_{1}-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right\|^{2}\)</span>即为回归损失，<span
class="math inline">\(\mathcal{L}_{2}(\mathbf{W})=-\log
\operatorname{Softmax}\left(\mathbf{y}_{2},
\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)\)</span>为分类误差。</p>
<p>上面公式转换的时候我觉得他为了简化而简化一下，他假设<span
class="math inline">\(\sigma_2\rightarrow1\)</span>,那么转换公式中<span
class="math inline">\(\log \frac{\sum_{c^{\prime}} \exp
\left(\frac{1}{\sigma_{2}^{2}}
f_{c^{\prime}}^{\mathrm{W}}(\mathrm{x})\right)}{\left(\sum_{c^{\prime}}
\exp
\left(f_{c^{\prime}}^{\mathrm{W}}(\mathbf{x})\right)\right)^{\frac{1}{\sigma_{2}^{2}}}}\)</span>上下两项将消除，<span
class="math inline">\(\log1\)</span>就消除了。但是消除之后不能保证<span
class="math inline">\(\sigma_2\rightarrow1\)</span>了，他又添加了<span
class="math inline">\(\log
\sigma_{2}\)</span>作为约束，保证他将趋向于1.</p>
<h3 id="实施">实施</h3>
<p>那么根据作者的写法，不论回归还是分类损失其实都是用相同的计算公式，然后最后组合即可：
<span class="math display">\[
loss_{w}=\frac{1}{2\sigma^2}loss+\log \sigma
\]</span></p>
<p>当然为了避免出现<span class="math inline">\(\log
\sigma\)</span>数值溢出的问题，采用<span class="math inline">\(s:=\log
\sigma^2\)</span>的方法来代替：</p>
<p><span class="math display">\[
loss_{w}=\frac{1}{2}\cdot \exp(-s) \cdot loss+\frac{1}{2}s
\]</span></p>
<h3 id="代码与实验结果">代码与实验结果</h3>
<p>代码如下，<code>tf2.x</code>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras <span class="keyword">as</span> k</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.layers <span class="keyword">as</span> kl</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.losses <span class="keyword">as</span> kls</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classifier</span>(<span class="params">num_class: <span class="built_in">int</span></span>):</span><br><span class="line">  <span class="keyword">return</span> k.Sequential([kl.Flatten(),</span><br><span class="line">                       kl.Dense(<span class="number">32</span>),</span><br><span class="line">                       kl.ReLU(),</span><br><span class="line">                       kl.Dense(num_class),</span><br><span class="line">                       kl.Softmax()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_model</span>():</span><br><span class="line">  inputs = k.Input((<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">  encoder = k.Sequential([kl.Conv2D(<span class="number">16</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                          kl.ReLU(),</span><br><span class="line">                          kl.Conv2D(<span class="number">16</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                          kl.ReLU(),</span><br><span class="line">                          kl.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          kl.Conv2D(<span class="number">16</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                          kl.ReLU(),</span><br><span class="line">                          kl.Conv2D(<span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                          kl.ReLU(),</span><br><span class="line">                          kl.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          kl.Conv2D(<span class="number">8</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                          kl.ReLU(),</span><br><span class="line">                          kl.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>)])</span><br><span class="line">  classifier1 = classifier(<span class="number">3</span>)</span><br><span class="line">  classifier2 = classifier(<span class="number">10</span>)</span><br><span class="line">  reconstructor = k.Sequential([kl.Conv2DTranspose(<span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>),</span><br><span class="line">                                kl.ReLU(),</span><br><span class="line">                                kl.Conv2DTranspose(<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">                                kl.ReLU(),</span><br><span class="line">                                kl.Conv2DTranspose(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="string">&#x27;valid&#x27;</span>),</span><br><span class="line">                                kl.ReLU(),</span><br><span class="line">                                kl.Conv2DTranspose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>),</span><br><span class="line">                                kl.Activation(<span class="string">&#x27;tanh&#x27;</span>), ])</span><br><span class="line">  x = encoder(inputs)</span><br><span class="line">  x1 = classifier1(x)</span><br><span class="line">  x2 = classifier2(x)</span><br><span class="line">  x3 = reconstructor(x)</span><br><span class="line">  model = k.Model(inputs, [x1, x2, x3])</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">uncertaint_weight</span>(<span class="params">loss, weight</span>):</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0.5</span> * tf.exp(-weight) * loss + <span class="number">0.5</span> * weight</span><br><span class="line">  <span class="comment"># return 1 / (2 * weight * weight) * loss + tf.math.log(weight)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  USE_LEARNABLE = <span class="literal">True</span> <span class="keyword">if</span> sys.argv[<span class="number">1</span>] == <span class="string">&#x27;True&#x27;</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">  USE_RECONSTRUCT = <span class="literal">True</span> <span class="keyword">if</span> sys.argv[<span class="number">2</span>] == <span class="string">&#x27;True&#x27;</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  physical_devices = tf.config.experimental.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line">  <span class="keyword">assert</span> <span class="built_in">len</span>(physical_devices) &gt; <span class="number">0</span>, <span class="string">&quot;Not enough GPU hardware devices available&quot;</span></span><br><span class="line">  tf.config.experimental.set_memory_growth(physical_devices[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  model: k.Model = build_model()</span><br><span class="line">  sub_dir = datetime.strftime(datetime.now(), <span class="string">r&#x27;%Y%m%d-%H%M%S&#x27;</span>)</span><br><span class="line">  root_dir = <span class="string">&#x27;tmp/&#x27;</span></span><br><span class="line">  s1 = <span class="string">&#x27;use_learnable&#x27;</span> <span class="keyword">if</span> USE_LEARNABLE <span class="keyword">else</span> <span class="string">&#x27;use_fixed&#x27;</span></span><br><span class="line">  s2 = <span class="string">&#x27;use_recon&#x27;</span> <span class="keyword">if</span> USE_RECONSTRUCT <span class="keyword">else</span> <span class="string">&#x27;no_recon&#x27;</span></span><br><span class="line">  sub_dir = s1 + <span class="string">&#x27;_&#x27;</span> + s2 + <span class="string">&#x27;/&#x27;</span> + sub_dir</span><br><span class="line"></span><br><span class="line">  writer = tf.summary.create_file_writer(root_dir + sub_dir)</span><br><span class="line">  initer = k.initializers.RandomUniform(<span class="number">0.2</span>, <span class="number">1.0</span>)</span><br><span class="line">  weights: <span class="type">List</span>[tf.Variable] = [tf.Variable(</span><br><span class="line">      initer([], tf.float32), trainable=USE_LEARNABLE) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line">  optimizer = k.optimizers.Adam(<span class="number">0.0001</span>)</span><br><span class="line">  ce_fn1 = kls.CategoricalCrossentropy()</span><br><span class="line">  ce_fn2 = kls.CategoricalCrossentropy()</span><br><span class="line">  mse_fn = kls.MeanSquaredError()</span><br><span class="line">  ceacc_fn1 = k.metrics.CategoricalAccuracy()</span><br><span class="line">  ceacc_fn2 = k.metrics.CategoricalAccuracy()</span><br><span class="line">  batch_size = <span class="number">256</span></span><br><span class="line">  epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @tf.function</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">x, y1, y2, y3</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      p1, p2, p3 = model(x, training=<span class="literal">True</span>)</span><br><span class="line">      l1 = ce_fn1(y1, p1)</span><br><span class="line">      ceacc_fn1.update_state(y1, p1)</span><br><span class="line">      l1_w = uncertaint_weight(l1, weights[<span class="number">0</span>])</span><br><span class="line">      l2 = ce_fn2(y2, p2)</span><br><span class="line">      ceacc_fn2.update_state(y2, p2)</span><br><span class="line">      l2_w = uncertaint_weight(l2, weights[<span class="number">1</span>])</span><br><span class="line">      l3 = mse_fn(y3, p3)</span><br><span class="line">      l3_w = uncertaint_weight(l3, weights[<span class="number">2</span>])</span><br><span class="line">      l = (l1_w + l2_w + l3_w) <span class="keyword">if</span> USE_RECONSTRUCT <span class="keyword">else</span> (l1_w + l2_w)</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> USE_LEARNABLE:</span><br><span class="line">        l = (l1 + l2 + l3) <span class="keyword">if</span> USE_RECONSTRUCT <span class="keyword">else</span> (l1 + l2)</span><br><span class="line"></span><br><span class="line">    grads = tape.gradient(l, model.trainable_variables + weights)</span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables + weights))</span><br><span class="line">    <span class="keyword">if</span> USE_LEARNABLE:</span><br><span class="line">      <span class="keyword">return</span> l, l1_w, l2_w, l3_w</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> l, l1, l2, l3</span><br><span class="line"></span><br><span class="line">  (x_train, y_train), (x_test, y_test) = k.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">  x_train = ((x_train / <span class="number">255.</span>)[..., <span class="literal">None</span>] - <span class="number">0.5</span>) / <span class="number">0.5</span></span><br><span class="line">  x_test = ((x_test / <span class="number">255.</span>)[..., <span class="literal">None</span>] - <span class="number">0.5</span>) / <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将3与7设为2种，其他设为1种</span></span><br><span class="line">  y_train_1 = np.ones_like(y_train) * <span class="number">2</span></span><br><span class="line">  y_train_1[y_train == <span class="number">2</span>] = <span class="number">0</span></span><br><span class="line">  y_train_1[y_train == <span class="number">6</span>] = <span class="number">1</span></span><br><span class="line">  y_train_1 = k.utils.to_categorical(y_train_1, <span class="number">3</span>)</span><br><span class="line">  y_train_2 = k.utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">  y_train_3 = x_train.copy()</span><br><span class="line"></span><br><span class="line">  y_test_1 = np.ones_like(y_test) * <span class="number">2</span></span><br><span class="line">  y_test_1[y_test == <span class="number">2</span>] = <span class="number">0</span></span><br><span class="line">  y_test_1[y_test == <span class="number">6</span>] = <span class="number">1</span></span><br><span class="line">  y_test_1 = k.utils.to_categorical(y_test_1, <span class="number">3</span>)</span><br><span class="line">  y_test_2 = k.utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line">  y_test_3 = x_test.copy()</span><br><span class="line"></span><br><span class="line">  train_ds = (tf.data.Dataset.from_tensor_slices(</span><br><span class="line">      ((x_train), (y_train_1, y_train_2, y_train_3))).</span><br><span class="line">      shuffle(batch_size * <span class="number">100</span>).</span><br><span class="line">      batch(batch_size, drop_remainder=<span class="literal">False</span>).</span><br><span class="line">      prefetch(<span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line">  test_ds = (tf.data.Dataset.from_tensor_slices(</span><br><span class="line">      ((x_test), (y_test_1, y_test_2, y_test_3))).</span><br><span class="line">      shuffle(batch_size * <span class="number">100</span>).</span><br><span class="line">      batch(batch_size, drop_remainder=<span class="literal">False</span>).</span><br><span class="line">      prefetch(<span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (in_x, (in_y1, in_y2, in_y3)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_ds):</span><br><span class="line">      l, l1, l2, l3 = step(in_x, in_y1, in_y2, in_y3)</span><br><span class="line">      cur_step = optimizer.iterations.numpy()</span><br><span class="line">      <span class="keyword">with</span> writer.as_default():</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/loss&#x27;</span>, l.numpy(), step=cur_step)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/loss_classify_1&#x27;</span>, l1.numpy(), step=cur_step)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/loss_classify_2&#x27;</span>, l2.numpy(), step=cur_step)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/acc_classify_1&#x27;</span>, ceacc_fn1.result().numpy(), step=cur_step)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/acc_classify_2&#x27;</span>, ceacc_fn2.result().numpy(), step=cur_step)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;train/loss_mse&#x27;</span>, l3.numpy(), step=cur_step)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">          tf.summary.scalar(<span class="string">f&#x27;train/weight_<span class="subst">&#123;_&#125;</span>&#x27;</span>, weights[_].numpy(), step=cur_step)</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot; eval &quot;&quot;&quot;</span></span><br><span class="line">  ceacc_fn1 = k.metrics.CategoricalAccuracy()</span><br><span class="line">  ceacc_fn2 = k.metrics.CategoricalAccuracy()</span><br><span class="line">  <span class="keyword">for</span> i, (in_x, (in_y1, in_y2, in_y3)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_ds):</span><br><span class="line">    l, l1, l2, l3 = step(in_x, in_y1, in_y2, in_y3)</span><br><span class="line">    p1, p2, p3 = model(in_x, training=<span class="literal">False</span>)</span><br><span class="line">    ceacc_fn1.update_state(in_y1, p1)</span><br><span class="line">    ceacc_fn2.update_state(in_y2, p2)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;learnable&#x27;</span>, USE_LEARNABLE, <span class="string">&#x27;Reconstruct&#x27;</span>, USE_RECONSTRUCT)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;3 classify  :&#x27;</span>, ceacc_fn1.result().numpy())</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;10 classify :&#x27;</span>, ceacc_fn2.result().numpy())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># python ./source/_posts/Uncertainty-Weigh-Loss/demo.py True True</span></span><br><span class="line"><span class="comment"># python ./source/_posts/Uncertainty-Weigh-Loss/demo.py False True</span></span><br><span class="line"><span class="comment"># python ./source/_posts/Uncertainty-Weigh-Loss/demo.py True False</span></span><br><span class="line"><span class="comment"># python ./source/_posts/Uncertainty-Weigh-Loss/demo.py False False</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">learnable True Reconstruct True</span><br><span class="line">3 classify  : 0.96688336</span><br><span class="line">10 classify : 0.8987667</span><br><span class="line"></span><br><span class="line">learnable False Reconstruct True</span><br><span class="line">3 classify  : 0.96745</span><br><span class="line">10 classify : 0.89035</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">learnable True Reconstruct False</span><br><span class="line">3 classify  : 0.9734667</span><br><span class="line">10 classify : 0.88518333</span><br><span class="line"></span><br><span class="line">learnable False Reconstruct False</span><br><span class="line">3 classify  : 0.96508336</span><br><span class="line">10 classify : 0.8900333</span><br></pre></td></tr></table></figure>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" rel="tag">概率论</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/09/19/mindspore-detail/">关于mindspore</a><a class="next" href="/2020/09/14/ai-matting/">基于Qt的抠图工具</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/">推理框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a> <a href="/tags/vllm/" style="font-size: 15px;">vllm</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/02/14/vllm/">推理框架调研</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/04/distal/">DISTAL: The Distributed Tensor Algebra Compiler</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>