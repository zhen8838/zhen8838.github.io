<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Proxy Anchor Loss for Deep Metric Learning论文解读 | Zheng's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Proxy Anchor Loss for Deep Metric Learning论文解读</h1><a id="logo" href="/.">Zheng's Notes</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Proxy Anchor Loss for Deep Metric Learning论文解读</h1><div class="post-meta">2020-06-17<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.9k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Epair%E7%9A%84%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.0.1.</span> <span class="toc-text">基于pair的损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Eproxy%E7%9A%84%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.0.2.</span> <span class="toc-text">基于proxy的损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proxy-nca-loss"><span class="toc-number">1.0.3.</span> <span class="toc-text">Proxy-NCA Loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proxy-anchor-loss"><span class="toc-number">1.0.4.</span> <span class="toc-text">Proxy-Anchor Loss</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%9D%E5%A4%96%E5%AE%9E%E9%AA%8C1"><span class="toc-number">1.1.</span> <span class="toc-text">额外实验1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%9D%E5%A4%96%E5%AE%9E%E9%AA%8C2"><span class="toc-number">1.2.</span> <span class="toc-text">额外实验2</span></a></li></ol></li></ol></div></div><div class="post-content"><p>这是<code>CVPR2020</code>的一篇度量学习的论文.来自韩国.我觉得还蛮有意思的,因此学习一番.</p>
<p>他的图画的是真好看,虽然做的事情其实就是把<code>amsoftmax</code>换个皮...</p>
<span id="more"></span>
<h1 id="原理">原理</h1>
<p><img src="/2020/06/17/proxy-anchor/proxy_1.png" /></p>
<p>论文主要提出了一个名为<code>Proxy Anchor</code>的损失函数.他相比于上图中<code>a,b,c,d</code>的方法.同时考虑了间距的大小作为损失的系数,且利用了整个<code>batch</code>中所有的数据,并用<code>anchor</code>作为<code>proxy</code>使得聚类中心更加明确.</p>
<h3 id="基于pair的损失">基于pair的损失</h3>
<p>对于一些没有利用整个<code>batch</code>所有数据的方法,那就需要依赖采样来取得<code>triplet pair</code>,<code>N-pair</code>等等,这样实际上引用了额外的复杂度.因此使用基于<code>proxy</code>的方法,不需要<code>pair</code>采样的方式.</p>
<h3 id="基于proxy的损失">基于proxy的损失</h3>
<p>基于<code>proxy</code>的度量学习是一种相对较新的方法，可以解决基于<code>pair</code>的损失的复杂性问题。<code>proxy</code>表示训练数据子集的代表，并被估计为嵌入网络参数的一部分。此类别中方法的共同思想是推断一小组的<code>proxy</code>，这些<code>proxy</code>捕获嵌入空间的全局结构，并将每个数据点与<code>proxy</code>相关联，而不是训练过程中的其他数据点。由于<code>proxy</code>的数量明显少于训练数据的数量，因此可以大大减少训练的复杂性.</p>
<p>第一个基于<code>proxy</code>的方法为<code>Proxy-NCA</code>,他使用<code>proxies</code>的<code>Neighborhood Component Analysis</code>作为一种近似,首先为每个类别设置一个<code>proxy</code>,将数据点与<code>proxy</code>关联,拉近正类的距离,拉开负类的距离.</p>
<p>使用<code>proxy</code>有助于极大地提高训练的收敛性，但有一个固有的局限性：由于每个数据点仅与<code>proxy</code>相关联，因此基于<code>pair</code>的方法的丰富的数据间关系不再可用。因此提出<code>Proxy Anchor</code>损失可以克服此问题，因为它的梯度可以反映数据的相对联系，这允许它们的嵌入向量在训练过程中相互影响.</p>
<h3 id="proxy-nca-loss">Proxy-NCA Loss</h3>
<p>首先介绍原本的损失.<code>Proxy-NCA</code>损失将<code>proxy</code>分配给每个类别，<code>proxy</code>的数量与类别标签的数量相同。给定一个输入数据点作为<code>anchor</code>，将同一类输入的<code>proxy</code>视为正，其他<code>proxy</code>为负。令<span
class="math inline">\(x\)</span>表示输入的嵌入向量，<span
class="math inline">\(p^+\)</span>为正<code>proxy</code>，<span
class="math inline">\(p^-\)</span>为负<code>proxy</code>。损失则为如下:</p>
<p><span class="math display">\[
\begin{aligned}
\ell(X) &amp;=\sum_{x \in X}-\log \frac{e^{s\left(x,
p^{+}\right)}}{\sum\limits_{p^{-} \in P^{-}} e^{s\left(x, p^{-}\right)}}
\\
&amp;=\sum_{x \in X}\left\{-s\left(x, p^{+}\right)+\underset{p^{-} \in
P^{-}}{\operatorname{LSE}} s\left(x, p^{-}\right)\right\}
\end{aligned}
\]</span></p>
<p>其中<span
class="math inline">\(X\)</span>为整个<code>batch</code>的嵌入向量,<span
class="math inline">\(P^-\)</span>为负<code>proxy</code>的集合,<span
class="math inline">\(s(\cdot,\cdot)\)</span>表示余弦相似度.其中<span
class="math inline">\(\operatorname{LSE}\)</span>为<code>log sum exp</code>.熟悉基于<code>softmax</code>损失的同学应该已经看出来了,这里其实就是交叉熵换了个皮.</p>
<p>对于此损失的梯度如下: <span class="math display">\[
\frac{\partial \ell(X)}{\partial s(x, p)}=\left\{\begin{array}{ll}
-1, &amp; \text { if } p=p^{+} \\
\frac{e^{s(x, p)}}{\sum\limits_{p^{-} \in P^{-}} e^{s\left(x,
p^{-}\right)}}, &amp; \text {otherwise }
\end{array}\right.
\]</span></p>
<p>训练时会使得<span class="math inline">\(x\)</span>与<span
class="math inline">\(p^+\)</span>尽量接近,使得<span
class="math inline">\(x\)</span>与<span
class="math inline">\(p^-\)</span>远离.不过注意到对于正类的梯度是恒定的,对于负类的梯度是有考虑到相似度的.此损失还是比较鲁棒的,但是由于损失仅使每个嵌入向量与<code>proxy</code>相关联，因此它无法利用细粒度的数据间关系。这种缺点限制了通过<code>Proxy-NCA</code>嵌入的能力.</p>
<h3 id="proxy-anchor-loss">Proxy-Anchor Loss</h3>
<p><code>Proxy-Anchor</code>损失旨在克服<code>Proxy-NCA</code>的局限性，同时保持较低的训练复杂性。主要思想是将每个<code>proxy</code>作为锚，并将其与整个数据批关联，以便在训练过程中数据通过<code>proxy anchor</code>彼此交互。此损失先按照<code>Proxy-NCA</code>的标准设置为每个类别分配一个<code>proxy</code>，公式为:</p>
<p><span class="math display">\[
\begin{aligned}
\ell(X)=&amp; \frac{1}{|P+|} \sum_{p \in P^{+}} \log \left(1+\sum_{x \in
X_{p}^{+}} e^{-\alpha(s(x, p)-\delta)}\right) \\
&amp;+\frac{1}{|P|} \sum_{p \in P} \log \left(1+\sum_{x \in X_{p}^{-}}
e^{\alpha(s(x, p)+\delta)}\right)
\end{aligned}
\]</span></p>
<p>这个也是比较老套的设置方法,其中<span
class="math inline">\(\delta\)</span>为<code>margin</code>,<span
class="math inline">\(\alpha\)</span>为尺度系数.将一个<code>batch</code>中所有的嵌入向量<span
class="math inline">\(X\)</span>分成两个子集<span
class="math inline">\(X_p^+,X_p^-\)</span>,其中<span
class="math inline">\(X_p^+\)</span>表示<code>proxy</code><span
class="math inline">\(p\)</span>的正样本嵌入向量,<span
class="math inline">\(X_p^-\)</span>则是剩下的所有向量.</p>
<p>将损失换一个形式: <span class="math display">\[
\begin{aligned}
\ell(X)=&amp; \frac{1}{\left|P^{+}\right|} \sum_{p \in P^{+}}[\text
{Softplus }(\mathop{\operatorname{LSE}}\limits_{x \in X_{p}^{+}}
-\alpha(s(x, p)-\delta))] \\
&amp;+\frac{1}{|P|} \sum_{p \in P}\left[\text {Softplus
}\left(\mathop{\operatorname{LSE}}\limits_{p \in X_{p}^{-}} \alpha(s(x,
p)+\delta)\right)\right]
\end{aligned}
\]</span></p>
<p>这样更加符合<code>circle loss</code>中所提出的统一形式了.其中这里的<span
class="math inline">\(|P^+|\)</span>是正样本的统计数量,<span
class="math inline">\(|P|\)</span>是总类别数.<del>这个系数我觉得不加也没关系</del>...</p>
<p><strong>NOTE</strong>
我看了下他官方的代码,实际上什么基于<code>proxy</code>的方法就是额外再加一个可训练的聚类中心...我之前的各种损失函数的实现是直接把最后一层作为聚类中心(也就是他们所说的<code>proxy</code>),这么看来把<code>circle loss</code>拉到度量学习的标准任务里肯定也是很能打的.</p>
<h2 id="额外实验1">额外实验1</h2>
<p>我做的cifar10分类实现，实际上<code>batchsize</code>改成500之后<span
class="math inline">\(|P^+|\)</span>有99.99的概率为10，<span
class="math inline">\(|P|\)</span>为10。我训练结果只和<code>circle loss</code>差0.8个点。然后我认为删除这个系数没有关系，但结果立马打脸了，差7个点了。其实这个问题还是在于<span
class="math inline">\(\alpha\)</span>系数上面，对于<code>proxy anchor loss</code>和<code>amsoftmax loss</code>来说没有像<code>circle loss</code>中的<code>自适应pace</code>，优化到后期可以说学习率太大也可以说是梯度太大，模型参数波动性会较大。这个实验佐证了<code>自适应pace</code>的重要性。</p>
<h2 id="额外实验2">额外实验2</h2>
<p>后面我又做了一下关于<span
class="math inline">\(margin\)</span>的实验，实际上我们考虑<code>softmax</code>分类的过程，要使他分类难度增强应该是降低正确类别的数值，因此应该是<span
class="math inline">\(s_p=cos(\theta_{y_i})-m\)</span>，这样才会强制正确类别的向量夹角更小。那么对于不正确的的分类类别，应该是加大他的数值，<span
class="math inline">\(s_n=cos(\theta_{j\neq
y_i})+m\)</span>,这样会强制降低向量更加接近垂直。</p>
<p>这里留个小坑，对于<code>circle loss</code>里面的<span
class="math inline">\(margin\)</span>设置我还是得重新仔细看看。</p>
<p><strong>NOTE</strong>
2020-6-23日更新，因为<code>circle loss</code>设置了<code>自定义pace</code>，因此他计算决策面的时候将<span
class="math inline">\(\alpha\)</span>考虑进去了，所以他得到的<span
class="math inline">\(margin\)</span>和我之前设想的不一样。然后我又做了一下他的间距分布图，其实这个损失还是可以继续改进的，大家可以看到当<span
class="math inline">\(\cos(\theta_p)=0，\cos(\theta_n)\in(\pi,\frac{\pi}{2})\)</span>时，对于负<code>pair</code>的损失是较小的。他所说的<code>circle</code>区域实际上是在<span
class="math inline">\(\cos(\theta_p)=0，\cos(\theta_n)=\frac{\pi}{2}\)</span>有一个更小的凹槽，这里是我们的<code>ideal</code>区域。</p>
<p>接下来如果有老哥可以把<span
class="math inline">\(\cos(\theta_p)=0，\cos(\theta_n)\in(\pi,\frac{\pi}{2})\)</span>这块区域的损失重新设计一下，应该可以得到更好的收敛效果。</p>
<p>等等。。这样判断太武断了，应该还需要分析一下梯度的变化。我这里就不继续深入了。</p>
<p><img src="/2020/06/17/proxy-anchor/proxy_2.png" /></p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li></ul></div><div class="post-nav"><a class="pre" href="/2020/06/19/RealMix-EnAET/">半监督学习：RealMix与EnAET</a><a class="next" href="/2020/06/16/statis-learn-cp11/">统计学习方法:聚类方法</a></div><script src="https://utteranc.es/client.js" repo="zhen8838/zhen8838.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://zhen8838.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.png"/></a><p>A Believing Heart Is Your Magic</p><a class="info-icon" href="mailto:597323109@qq.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/zhen8838" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">体系结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">工具使用</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 15px;">树莓派</a> <a href="/tags/%E8%93%9D%E7%89%99/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 15px;">遗传算法</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">半监督学习</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E9%A6%99%E6%A9%99%E6%B4%BE/" style="font-size: 15px;">香橙派</a> <a href="/tags/%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/" style="font-size: 15px;">踩坑经验</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E5%A4%9A%E9%9D%A2%E4%BD%93%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">多面体模型</a> <a href="/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">后端优化</a> <a href="/tags/Ampl/" style="font-size: 15px;">Ampl</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 15px;">图像处理</a> <a href="/tags/K210/" style="font-size: 15px;">K210</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 15px;">二分法</a> <a href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" style="font-size: 15px;">科学上网</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/cmake/" style="font-size: 15px;">cmake</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/Conan/" style="font-size: 15px;">Conan</a> <a href="/tags/OrTools/" style="font-size: 15px;">OrTools</a> <a href="/tags/CSharp/" style="font-size: 15px;">CSharp</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 15px;">数据增强</a> <a href="/tags/VAE/" style="font-size: 15px;">VAE</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" style="font-size: 15px;">聚类方法</a> <a href="/tags/CostModel/" style="font-size: 15px;">CostModel</a> <a href="/tags/Vscode/" style="font-size: 15px;">Vscode</a> <a href="/tags/%E5%A3%B0%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 15px;">声音信号处理</a> <a href="/tags/TVM/" style="font-size: 15px;">TVM</a> <a href="/tags/%E5%8A%A8%E6%80%81shape/" style="font-size: 15px;">动态shape</a> <a href="/tags/%E4%B8%AD%E7%AB%AF%E4%BC%98%E5%8C%96/" style="font-size: 15px;">中端优化</a> <a href="/tags/Equality-Saturation/" style="font-size: 15px;">Equality Saturation</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Halide/" style="font-size: 15px;">Halide</a> <a href="/tags/DSL/" style="font-size: 15px;">DSL</a> <a href="/tags/%E5%A0%86%E6%A0%88/" style="font-size: 15px;">堆栈</a> <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">大语言模型</a> <a href="/tags/llama/" style="font-size: 15px;">llama</a> <a href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 15px;">归一化</a> <a href="/tags/Makefile/" style="font-size: 15px;">Makefile</a> <a href="/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">元学习</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">模板元编程</a> <a href="/tags/mindspore/" style="font-size: 15px;">mindspore</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/tvm/" style="font-size: 15px;">tvm</a> <a href="/tags/mlir/" style="font-size: 15px;">mlir</a> <a href="/tags/%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1/" style="font-size: 15px;">性能建模</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/Nand2Tetris/" style="font-size: 15px;">Nand2Tetris</a> <a href="/tags/ncnn/" style="font-size: 15px;">ncnn</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/PCB/" style="font-size: 15px;">PCB</a> <a href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">姿态估计</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">人脸检测</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/" style="font-size: 15px;">神经网络量化</a> <a href="/tags/Yolo/" style="font-size: 15px;">Yolo</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/NB-IOT/" style="font-size: 15px;">NB-IOT</a> <a href="/tags/Retinaface/" style="font-size: 15px;">Retinaface</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/" style="font-size: 15px;">指令集</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 15px;">人脸识别</a> <a href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" style="font-size: 15px;">优化器</a> <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B/" style="font-size: 15px;">吴恩达课程</a> <a href="/tags/WordCloud/" style="font-size: 15px;">WordCloud</a> <a href="/tags/Zhihu/" style="font-size: 15px;">Zhihu</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/%E5%9B%9B%E8%BD%B4%E9%A3%9E%E8%A1%8C%E5%99%A8/" style="font-size: 15px;">四轴飞行器</a> <a href="/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/" style="font-size: 15px;">资源汇总</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">无监督学习</a> <a href="/tags/Apple/" style="font-size: 15px;">Apple</a> <a href="/tags/Jittor/" style="font-size: 15px;">Jittor</a> <a href="/tags/Tiramisu/" style="font-size: 15px;">Tiramisu</a> <a href="/tags/Triton/" style="font-size: 15px;">Triton</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/12/04/triton-cpu-lesson-1/">triton-cpu初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/mesh-matmul/">分布式存储架构下的矩阵乘与编译器</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/mlc-tutorial/">机器学习编译概念科普</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/08/08/benchmark-notes/">benchmark的经验与技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/06/14/ampl-learn/">Ampl学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/08/constraints-solver-internals/">Constraints Solver Internals</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/30/model-driven-optimization/">Model Driven Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx/">探索AMX: 解锁Apple Silicon隐藏性能</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/23/mac-amx_en/">Explore AMX instructions: Unlock the performance of Apple Silicon</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/13/macos-bundle/">macos中bundle的使用</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Zheng's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>